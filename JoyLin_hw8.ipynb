{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joylin0209/40133HW/blob/main/JoyLin_hw8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DCJfD0Iu4Tk"
      },
      "source": [
        "# Week 8 - Conversation and Text Generation\n",
        "Many natural language activities boil down to text generation, especially the back-and-forth nature of natural conversation and question answering. While some may regard it as a parlour trick due to unpredictability, recent dramatic improvements in text generation suggest that these kind of models can find themselves being used in more serious social scientific applications, such as in survey design and construction, idiomatic translation, and the normalization of phrase and sentence meanings.\n",
        "\n",
        "\n",
        "Much recent NLP research is on text generation. Before the phenomenal product ChatGPT(OpenAI) was released at the end of 2022,  this is the primary use of large language models like GPT-3 (OpenAI), Wu Dao (Beijing Academy of AI), and Gopher (DeepMind). Then everything went wild in 2023. We saw tons of open-sourced LLMs were released like Llama series(Meta), and how others techs wanted to compete with OpenAI by releasing models like Claude(Anthropic), Bard(Google), Gemini(Google x2), etc. It seems that the era pf artificial general intelligence (AGI) is approaching!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhE5cZiBhdr7",
        "outputId": "4e1120d8-46db-45e9-889a-198d87406f31"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAiiglFku4Tm",
        "outputId": "b631a9c2-95b5-40ab-911f-b39eb02cc561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
            "  Cloning https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git to /tmp/pip-req-build-2bgub7xz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git /tmp/pip-req-build-2bgub7xz\n",
            "  Resolved https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git to commit b17a265d3b8253424e5b38872457f7437909a65d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.5.3)\n",
            "Collecting python-docx (from lucem-illud==8.0.1)\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (9.4.0)\n",
            "Collecting pdfminer2 (from lucem-illud==8.0.1)\n",
            "  Downloading pdfminer2-20151206-py2.py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython (from lucem-illud==8.0.1)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.9.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.11.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (0.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.8.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (4.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.7.1)\n",
            "Collecting pyanno3 (from lucem-illud==8.0.1)\n",
            "  Downloading pyanno3-2.0.2.tar.gz (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (4.12.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (0.20.1)\n",
            "Collecting boto3 (from lucem-illud==8.0.1)\n",
            "  Downloading boto3-1.34.49-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.2.1)\n",
            "Collecting pydub (from lucem-illud==8.0.1)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting speechrecognition (from lucem-illud==8.0.1)\n",
            "  Downloading SpeechRecognition-3.10.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pysoundfile (from lucem-illud==8.0.1)\n",
            "  Downloading PySoundFile-0.9.0.post1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (0.19.3)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (7.34.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.7.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->lucem-illud==8.0.1) (2.5)\n",
            "Collecting botocore<1.35.0,>=1.34.49 (from boto3->lucem-illud==8.0.1)\n",
            "  Downloading botocore-1.34.49-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->lucem-illud==8.0.1)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->lucem-illud==8.0.1)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->lucem-illud==8.0.1) (6.4.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython->lucem-illud==8.0.1)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (67.7.2)\n",
            "Collecting jedi>=0.16 (from IPython->lucem-illud==8.0.1)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->lucem-illud==8.0.1) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->lucem-illud==8.0.1) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->lucem-illud==8.0.1) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->lucem-illud==8.0.1) (4.66.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lucem-illud==8.0.1) (2023.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pdfminer2->lucem-illud==8.0.1) (1.16.0)\n",
            "Collecting traits (from pyanno3->lucem-illud==8.0.1)\n",
            "  Downloading traits-6.4.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m131.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.10/dist-packages (from pysoundfile->lucem-illud==8.0.1) (1.16.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx->lucem-illud==8.0.1) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx->lucem-illud==8.0.1) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lucem-illud==8.0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lucem-illud==8.0.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lucem-illud==8.0.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lucem-illud==8.0.1) (2024.2.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->lucem-illud==8.0.1) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->lucem-illud==8.0.1) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->lucem-illud==8.0.1) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lucem-illud==8.0.1) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (0.9.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (3.1.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (3.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=0.6->pysoundfile->lucem-illud==8.0.1) (2.21)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython->lucem-illud==8.0.1)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->lucem-illud==8.0.1) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->lucem-illud==8.0.1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->lucem-illud==8.0.1) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->lucem-illud==8.0.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->lucem-illud==8.0.1) (2.16.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->lucem-illud==8.0.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->lucem-illud==8.0.1) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy->lucem-illud==8.0.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->lucem-illud==8.0.1) (2.1.5)\n",
            "Building wheels for collected packages: lucem-illud, pyanno3\n",
            "  Building wheel for lucem-illud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lucem-illud: filename=lucem_illud-8.0.1-py3-none-any.whl size=34989 sha256=9fcc1c271b20a9acf161e03341c80d4fe4277aba458a85e1998d8d390d6bb4af\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jhnzevty/wheels/4c/84/7b/d89dec34fb910351cf618bf262d1c926f9f68779ef24028427\n",
            "  Building wheel for pyanno3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyanno3: filename=pyanno3-2.0.2-py3-none-any.whl size=116965 sha256=a69b2892db8bcd606f7da38b990d74e33c1ff4ded7b9475d596719b4b286e397\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0c/9f/21212c187c1edb1647c18e0a24b6b213b3bb7dee5aa94bfd72\n",
            "Successfully built lucem-illud pyanno3\n",
            "Installing collected packages: pydub, traits, smmap, python-docx, pdfminer2, jmespath, jedi, speechrecognition, pysoundfile, pyanno3, gitdb, botocore, s3transfer, GitPython, boto3, lucem-illud\n",
            "Successfully installed GitPython-3.1.42 boto3-1.34.49 botocore-1.34.49 gitdb-4.0.11 jedi-0.19.1 jmespath-1.0.1 lucem-illud-8.0.1 pdfminer2-20151206 pyanno3-2.0.2 pydub-0.25.1 pysoundfile-0.9.0.post1 python-docx-1.1.0 s3transfer-0.10.0 smmap-5.0.1 speechrecognition-3.10.1 traits-6.4.3\n"
          ]
        }
      ],
      "source": [
        "#Special module written for this class\n",
        "#This provides access to data and to helper functions from previous weeks\n",
        "#Make sure you update it before starting this notebook\n",
        "!pip install -U git+https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
        "import lucem_illud\n",
        "\n",
        "import sklearn #For generating some matrices\n",
        "import pandas as pd #For DataFrames\n",
        "import numpy as np #For arrays\n",
        "import matplotlib.pyplot as plt #For plotting\n",
        "import seaborn #Makes the plots look nice\n",
        "import seaborn as sns\n",
        "import scipy #Some stats\n",
        "import nltk #a little language code\n",
        "from IPython.display import Image #for pics\n",
        "\n",
        "import pickle #if you want to save layouts\n",
        "import os\n",
        "import io\n",
        "import zipfile\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import torch # pip install torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig # pip install tranformers\n",
        "from transformers import AdamW, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lk2R1QxOu4Tm"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1UsG9ZsWu4Tn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jcxh_Xuzu4Tn"
      },
      "source": [
        "# ConvoKit\n",
        "As we alluded to in Week 7 with causal inference, [ConvoKit](https://convokit.cornell.edu/) is an exciting platform for conversational analysis developed by Jonathan Chang, Calem Chiam, and others, mostly at Cornell. Keep this in mind if you are interested in a final project with conversational data such as Twitter threads or movie scripts. They have an [interactive tutorial](https://colab.research.google.com/github/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/Introduction_to_ConvoKit.ipynb), which we include some examples from below. Most of the following text and code is authored by them.\n",
        "\n",
        "These ConvoKit corpora can be used for the next exercise in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpQTyQjBUonG",
        "outputId": "d2d02a98-7124-4cf5-b366-d9eb77139818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting convokit\n",
            "  Downloading convokit-3.0.0.tar.gz (183 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.2/183.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.5.3)\n",
            "Collecting msgpack-numpy>=0.4.3.2 (from convokit)\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: spacy>=2.3.5 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.7.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.2.2)\n",
            "Requirement already satisfied: nltk>=3.4 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.8.1)\n",
            "Collecting dill>=0.2.9 (from convokit)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.3.2)\n",
            "Collecting clean-text>=0.6.0 (from convokit)\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting unidecode>=1.1.1 (from convokit)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (4.66.2)\n",
            "Collecting pymongo>=4.0 (from convokit)\n",
            "  Downloading pymongo-4.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.2/677.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from convokit) (6.0.1)\n",
            "Collecting dnspython>=1.16.0 (from convokit)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emoji<2.0.0,>=1.0.0 (from clean-text>=0.6.0->convokit)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text>=0.6.0->convokit)\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (2.8.2)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.0.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4->convokit) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4->convokit) (2023.12.25)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->convokit) (2023.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->convokit) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (6.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.3.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->convokit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.3.5->convokit) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.3.5->convokit) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy>=2.3.5->convokit) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=2.3.5->convokit) (2.1.5)\n",
            "Building wheels for collected packages: convokit, emoji\n",
            "  Building wheel for convokit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for convokit: filename=convokit-3.0.0-py3-none-any.whl size=216707 sha256=a2e18f748f472dad6b43b07af369d3677e6db3001a47adb913a9eb284ad2789f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/89/8c/2677fdb888588b6f93cb6ac86bdfb020f1f1c33e0d5525b231\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=894d243d57efb78acd099358eb5ad35424df5a8b82dab5dd90511192a61f90e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built convokit emoji\n",
            "Installing collected packages: emoji, unidecode, msgpack-numpy, ftfy, dnspython, dill, pymongo, clean-text, convokit\n",
            "Successfully installed clean-text-0.6.0 convokit-3.0.0 dill-0.3.8 dnspython-2.6.1 emoji-1.7.0 ftfy-6.1.3 msgpack-numpy-0.4.8 pymongo-4.6.2 unidecode-1.3.8\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import convokit\n",
        "except ModuleNotFoundError:\n",
        "    !pip install convokit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mMQXf1xHUonH"
      },
      "outputs": [],
      "source": [
        "# for pretty printing of cells within the Colab version of this notebook\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RLHbOOAzUonI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "63b6d03c-0a31-416c-ad3d-b60af2a158f5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import convokit\n",
        "from convokit import Corpus, download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5VIPx2oUonI"
      },
      "source": [
        "### Loading a Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_lhin9LUonJ"
      },
      "source": [
        "A Corpus represents a conversational dataset. We typically begin our analysis by loading a Corpus. A list of existing datasets already in ConvoKit format can be found [here](https://convokit.cornell.edu/documentation/datasets.html).\n",
        "\n",
        "A growing list of many other conversational datasets covering a variety of conversational settings are available in ConvoKit, such as face-to-face (e.g. the [*Intelligence Squared Debates corpus*](https://convokit.cornell.edu/documentation/iq2.html)), institutional (e.g. the [*Supreme Court Oral Arguments corpus*](https://convokit.cornell.edu/documentation/supreme.html)), fictional (e.g. the [*Cornell Movie Dialog Corpus*](https://convokit.cornell.edu/documentation/movie.html)), or online  (e.g. all talkpage conversations on [*Wikipedia Talk Pages*](https://convokit.cornell.edu/documentation/wiki.html) and a full dump of [*Reddit*](https://convokit.cornell.edu/documentation/subreddit.html)).\n",
        "\n",
        "For this tutorial, we will primarily be using the *r/Cornell* subreddit corpus to demo various ConvoKit functionality, and occasionally the [*Switchboard Dialog Act Corpus*](https://convokit.cornell.edu/documentation/switchboard.html) (a collection of anonymized five-minute telephone conversations) as a contrasting dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "488jR7pVUonJ",
        "outputId": "46c9c9e5-b0f7-4dfc-a45f-9b928f84ff47"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading subreddit-Cornell to /root/.convokit/downloads/subreddit-Cornell\n",
            "Downloading subreddit-Cornell from http://zissou.infosci.cornell.edu/convokit/datasets/subreddit-corpus/corpus-zipped/CookingScrewups~-~CrappyDesign/Cornell.corpus.zip (11.2MB)... Done\n",
            "No configuration file found at /root/.convokit/config.yml; writing with contents: \n",
            "# Default Backend Parameters\n",
            "db_host: localhost:27017\n",
            "data_directory: ~/.convokit/saved-corpora\n",
            "default_backend: mem\n"
          ]
        }
      ],
      "source": [
        "corpus = Corpus(download('subreddit-Cornell'))\n",
        "\n",
        "# You can try a different corpus if you want.\n",
        "#corpus = Corpus(download('diplomacy-corpus'))\n",
        "#corpus = Corpus(download('switchboard-corpus'))\n",
        "#corpus = Corpus(download('reddit-corpus-small'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "rnBisd3QUonL",
        "outputId": "ad219242-f468-4f12-e23b-ee7b36b41d3e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Speakers: 7568\n",
            "Number of Utterances: 74467\n",
            "Number of Conversations: 10744\n"
          ]
        }
      ],
      "source": [
        "corpus.print_summary_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTcJWCgzUonL"
      },
      "source": [
        "### Corpus components: Conversations, Utterances, Speakers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnnTm_ALUonL"
      },
      "source": [
        "Every Corpus has three main components: [Conversations](https://convokit.cornell.edu/documentation/conversation.html), [Utterances](https://convokit.cornell.edu/documentation/utterance.html), and [Speakers](https://convokit.cornell.edu/documentation/speaker.html). Just as in real life, in ConvoKit, Conversations are some sequence of Utterances, where each Utterance is made by some Speaker. Let's look at an example of each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "xW9eeQrcUonS",
        "outputId": "9e5dc6b0-dca0-4e7c-d971-478671c52139"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvoKitMeta({'title': 'Deans List Email (SHA)', 'num_comments': 12, 'domain': 'self.Cornell', 'timestamp': 1498141434, 'subreddit': 'Cornell', 'gilded': 0, 'gildings': None, 'stickied': False, 'author_flair_text': ''})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# This is a Reddit thread\n",
        "corpus.random_conversation().meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "TeR71mPgUonT",
        "outputId": "d0d4dffe-9dc3-4957-c0ab-afa709b23f7a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvoKitMeta({'score': 2, 'top_level_comment': 'cp6020x', 'retrieved_on': 1427607839, 'gilded': 0, 'gildings': None, 'subreddit': 'Cornell', 'stickied': False, 'permalink': '', 'author_flair_text': ''})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# This is a Reddit post or comment.\n",
        "corpus.random_utterance().meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "LnQcLKBxUonS",
        "outputId": "7d983bf0-95b9-46de-dabf-89f7289faee8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Speaker({'obj_type': 'speaker', 'vectors': [], 'owner': <convokit.model.corpus.Corpus object at 0x7c500721c2e0>, 'id': 'kld34', 'meta': ConvoKitMeta({})})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# The r/Cornell Corpus does not have speaker metadata.\n",
        "#corpus.random_speaker().meta\n",
        "\n",
        "#Speaker do have an 'id' which is their Reddit username, as seen here.\n",
        "corpus.random_speaker()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "kpfMX5_bu4Tp",
        "outputId": "35882d2d-baa7-40e5-d880-9f31847d817a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I was just reading about the Princeton Mic-Check and it's getting [national press](http://www.bloomberg.com/news/2011-12-29/princeton-brews-trouble-for-us-1-percenters-commentary-by-michael-lewis.html).\n",
            "\n",
            "I want to get a sense of what people felt like around campus. Anything interesting happen? Anything interesting coming up?\n"
          ]
        }
      ],
      "source": [
        "# We can iterate through these objects as we iterate lists or DataFrames in Python.\n",
        "for utt in corpus.iter_utterances():\n",
        "    print(utt.text)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP83knAGu4Tp"
      },
      "source": [
        "Conversations, Utterances, and Speakers are each interesting, but the magic of conversational analysis is connecting them. For example, we can get all the Conversations in which a Speaker has participated and all the Utterances they have made. To make it more interesting, we can find a Speaker to study by navigating from a random Utterance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "fAyGVo-Ou4Tp",
        "outputId": "f96c95a8-58d2-4857-a418-c182504a8954"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Conversation({'obj_type': 'conversation', 'vectors': [], 'tree': None, 'owner': <convokit.model.corpus.Corpus object at 0x7c500721c2e0>, 'id': '4fbxeu', 'meta': ConvoKitMeta({'title': 'Picking Classes', 'num_comments': 2, 'domain': 'self.Cornell', 'timestamp': 1460987582, 'subreddit': 'Cornell', 'gilded': 0, 'gildings': None, 'stickied': False, 'author_flair_text': ''})}),\n",
              " Conversation({'obj_type': 'conversation', 'vectors': [], 'tree': None, 'owner': <convokit.model.corpus.Corpus object at 0x7c500721c2e0>, 'id': '4yd5j0', 'meta': ConvoKitMeta({'title': 'Found at Cornell Plantations by u/BrowsingRedditNaked [mildly NSFW]', 'num_comments': 1, 'domain': 'reddit.com', 'timestamp': 1471537077, 'subreddit': 'Cornell', 'gilded': 0, 'gildings': None, 'stickied': False, 'author_flair_text': ''})}),\n",
              " Conversation({'obj_type': 'conversation', 'vectors': [], 'tree': None, 'owner': <convokit.model.corpus.Corpus object at 0x7c500721c2e0>, 'id': '4yfsm2', 'meta': ConvoKitMeta({'title': 'Law school for Cornell transfers.', 'num_comments': 4, 'domain': 'self.Cornell', 'timestamp': 1471566301, 'subreddit': 'Cornell', 'gilded': 0, 'gildings': None, 'stickied': False, 'author_flair_text': ''})})]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# consider this sequence of operations that highlight how to navigate between components\n",
        "utt = corpus.random_utterance()\n",
        "convo = utt.get_conversation() # get the Conversation the Utterance belongs to\n",
        "spkr = utt.speaker # get the Speaker who made the Utterance\n",
        "\n",
        "spkr_convos = list(spkr.iter_conversations())\n",
        "\n",
        "# Display up to 3 of their conversations.\n",
        "spkr_convos[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHkHRCiAu4Tp"
      },
      "source": [
        "For a more qualitative feel of the data, you can display a Conversation. For Reddit data, this is a single thread."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "gCVGO_rZu4Tp",
        "outputId": "7692902c-6d98-4551-e6e4-1c8f582f977d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[removed]\n",
            "\n",
            "    [removed]\n",
            "\n",
            "    is this satirical\n",
            "\n",
            "        [deleted]\n",
            "\n",
            "        look at his profile \n",
            "\n",
            "    [deleted]\n",
            "\n",
            "    You think Affirmative Action is hurting you? Look at the UCs dude, Affirmative A\n",
            "\n",
            "    This is like D- trolling. \n",
            "\n",
            "Fuck off racist \n",
            "\n",
            "    [deleted]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We truncate sentences at character 80 to avoid making this notebook too long!\n",
        "convo.print_conversation_structure(lambda utt: utt.text[:80] + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJloyysmu4Tp"
      },
      "source": [
        "There is a lot more to ConvoKit that we encourage you to explore, especially their [tutorial](https://colab.research.google.com/github/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/Introduction_to_ConvoKit.ipynb), but the ability to seamlessly navigate between the Utterances, Conversations, and Speakers of a Corpus is extremely valuable for social science."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB8Il5Fxu4Tp"
      },
      "source": [
        "## <font color=\"red\">*Exercise 1*</font>\n",
        "\n",
        "<font color=\"red\">Construct cells immediately below this that use ConvoKit to analyze a Corpus other than 'subreddit-Cornell', including at least one function you find in the package not used above. You can also generate a ConvoKit Corpus from your own dataset based on [their Corpus from .txt files tutorial](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/converting_movie_corpus.ipynb) or [their Corpus from pandas tutorial](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/corpus_from_pandas.ipynb), but that may be time-consuming for a weekly assignment. (It could be a great idea for your final project!)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/SOCI40133/PTTdata3.csv\")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i1Y0n9zjd_N",
        "outputId": "dcd3be1e-2746-434e-e75f-92458fac2de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         作者           看板                     標題       日期  類型  \\\n",
            "0            sky2030 (無業遊民)     Boy-Girl          [心情] 出國巧遇台女趣事  2023-12  心情   \n",
            "1      iamjimhaha (磨刀霍霍向肥羊)     Boy-Girl  [討論] 找台女不找外配是不是因為不想養？  2023-12  討論   \n",
            "2         Sugimoto5566 (馬丁)     Boy-Girl  [討論] 印度移工如果來台,台女會怎麼選?  2023-11  討論   \n",
            "3            corydoras09 ()     Boy-Girl  Re: [討論] 為何台女很少會主動認錯?  2023-11  討論   \n",
            "4        drinkmuffin (暢飲鬆餅)     Boy-Girl  Re: [討論] 為何台女很少會主動認錯?  2023-11  討論   \n",
            "...                     ...          ...                    ...      ...  ..   \n",
            "2964     ChrisDavis (工業電風扇)  Marginalman        Re: [閒聊] 台女果然優質  2024-01  閒聊   \n",
            "2965             Vedan (味丹)  Marginalman        Re: [閒聊] 台女果然優質  2024-01  閒聊   \n",
            "2966  takashi001 (沙花叉クロヱ的狗)  Marginalman        Re: [閒聊] 台女果然優質  2024-01  閒聊   \n",
            "2967       wahaha99 (我討厭人類)  Marginalman        Re: [閒聊] 台女果然優質  2024-01  閒聊   \n",
            "2968           miHoYo (米哈遊)  Marginalman        Re: [閒聊] 台女果然優質  2024-01  閒聊   \n",
            "\n",
            "                                                     內文  \n",
            "0     最近常跟朋友一起跑胡志明，河內玩\\n\\n玩什麼就不要問了\\n\\n某天晚上 剛好在一間麵店吃飯...  \n",
            "1     \\n發現有些台男\\n明明就找不到對象\\n卻不願意找外籍\\n\\n是否是因為找台女還能要求有工作...  \n",
            "2     未來的有一天\\n\\n如果印度的移工來到台灣\\n\\n街上勢必有更多印度男\\n\\n印度男有深邃的...  \n",
            "3     我有遇過那種我完全沒錯的女生\\n死的都能掰成活的\\n但那時候暈船暈的厲害\\n所以一直舔\\n現...  \n",
            "4      \\n \\n？？？\\n我遇到的比較多是台男才少主動認錯吧？\\n \\n一推愛面子愛到不行 說話...  \n",
            "...                                                 ...  \n",
            "2964   → waitan: 你島棒球豚嘎器仔很多的                        ...  \n",
            "2965  \\n這就惡性循環\\n\\n剛開始只有部分台男這樣\\n\\n然後讓部分台女食髓知味\\n\\n接著你本...  \n",
            "2966  確實\\n\\n與其看啦啦隊\\n\\n不如去交女朋友\\n\\n然後叫她穿拉拉隊服在你身上搖==\\n\\...  \n",
            "2967  \\n雀食\\n不過問題來了\\n為什麼台男變這麼可悲\\n\\n全世界範圍\\n好像台男特別可悲\\n\\...  \n",
            "2968  → Vedan: VT豚沒有這樣吧\\n\\n我認識一個VT除\\n還是廚那種沒幾個人看得\\n雖然...  \n",
            "\n",
            "[2969 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'作者': 'user', '看板': 'board', '標題': 'title', '日期': 'date', '類型': 'type', '內文': 'text'})\n",
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "TY5aTYT4Xq_b",
        "outputId": "c0454c76-f598-4fe9-c199-55dabfc88333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   user     board                  title     date type  \\\n",
              "0        sky2030 (無業遊民)  Boy-Girl          [心情] 出國巧遇台女趣事  2023-12   心情   \n",
              "1  iamjimhaha (磨刀霍霍向肥羊)  Boy-Girl  [討論] 找台女不找外配是不是因為不想養？  2023-12   討論   \n",
              "\n",
              "                                                text  \n",
              "0  最近常跟朋友一起跑胡志明，河內玩\\n\\n玩什麼就不要問了\\n\\n某天晚上 剛好在一間麵店吃飯...  \n",
              "1  \\n發現有些台男\\n明明就找不到對象\\n卻不願意找外籍\\n\\n是否是因為找台女還能要求有工作...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be5c1c5d-ca41-483b-b7df-77cb1f460875\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>board</th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sky2030 (無業遊民)</td>\n",
              "      <td>Boy-Girl</td>\n",
              "      <td>[心情] 出國巧遇台女趣事</td>\n",
              "      <td>2023-12</td>\n",
              "      <td>心情</td>\n",
              "      <td>最近常跟朋友一起跑胡志明，河內玩\\n\\n玩什麼就不要問了\\n\\n某天晚上 剛好在一間麵店吃飯...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>iamjimhaha (磨刀霍霍向肥羊)</td>\n",
              "      <td>Boy-Girl</td>\n",
              "      <td>[討論] 找台女不找外配是不是因為不想養？</td>\n",
              "      <td>2023-12</td>\n",
              "      <td>討論</td>\n",
              "      <td>\\n發現有些台男\\n明明就找不到對象\\n卻不願意找外籍\\n\\n是否是因為找台女還能要求有工作...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be5c1c5d-ca41-483b-b7df-77cb1f460875')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be5c1c5d-ca41-483b-b7df-77cb1f460875 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be5c1c5d-ca41-483b-b7df-77cb1f460875');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8c133925-71d5-4abf-886c-a6612efa2fbd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c133925-71d5-4abf-886c-a6612efa2fbd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8c133925-71d5-4abf-886c-a6612efa2fbd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "'str' object has no attribute 'empty'"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 使用value_counts()方法统计'user'列中每个值的出现次数\n",
        "user_counts = df['user'].value_counts()\n",
        "\n",
        "# 筛选出出现次数大于一的值\n",
        "duplicate_users = user_counts[user_counts > 1]\n",
        "\n",
        "# 输出出现次数大于一的值\n",
        "print(\"出现次数大于一的用户：\")\n",
        "print(duplicate_users)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQz8vraYfQ83",
        "outputId": "bad7cf98-a200-49e3-d469-ede8d6584a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "出现次数大于一的用户：\n",
            "christopherl (Crystal~++)                756\n",
            "leocean9816 (阿光)                         126\n",
            "L1ON (我是獅子~(ﾉﾟ▽ﾟ)ﾉ♪)                     126\n",
            "n9n9n9n9n91 (n9n9n9n9n9n9n9n9n9n9n91)    126\n",
            "zuvio (zz)                               126\n",
            "                                        ... \n",
            "googstar (股大濕)                             2\n",
            "joy830 (joy)                               2\n",
            "demitri (咻咻咻)                              2\n",
            "geige ()                                   2\n",
            "sea130281 (胃哥)                             2\n",
            "Name: user, Length: 109, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from convokit import Corpus, Utterance, Speaker\n",
        "\n",
        "# 创建Speakers字典\n",
        "speakers = {}\n",
        "\n",
        "# 创建Utterance对象并构建Corpus\n",
        "utterances = []\n",
        "for idx, row in df.iterrows():\n",
        "    # 创建Speaker对象\n",
        "    if row['user'] not in speakers:\n",
        "        speakers[row['user']] = Speaker(id=row['user'])\n",
        "    utterance = Utterance(\n",
        "        id=str(idx),\n",
        "        speaker=speakers[row['user']],\n",
        "        timestamp=row['date'],\n",
        "        text=row['text'],\n",
        "        meta={'board': row['board'], 'title': row['title'], 'type': row['type']}\n",
        "    )\n",
        "    utterances.append(utterance)\n",
        "\n",
        "corpus = Corpus(utterances=utterances)\n",
        "\n",
        "\n",
        "# 查看基本信息\n",
        "print(\"Utterance count:\", len(corpus.get_utterance_ids()))\n",
        "print(\"Speaker count:\", len(corpus.get_speaker_ids()))\n",
        "\n",
        "# 只打印前几条发言的文本内容\n",
        "num_to_display = 5\n",
        "for i, utt in enumerate(corpus.iter_utterances()):\n",
        "    if i < num_to_display:\n",
        "        print(utt.text)\n",
        "    else:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LGYj7UHZPGO",
        "outputId": "93797041-5494-44b3-80ae-b3af5dd6400e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configuration file found at /root/.convokit/config.yml; writing with contents: \n",
            "# Default Backend Parameters\n",
            "db_host: localhost:27017\n",
            "data_directory: ~/.convokit/saved-corpora\n",
            "default_backend: mem\n",
            "Utterance count: 2969\n",
            "Speaker count: 296\n",
            "最近常跟朋友一起跑胡志明，河內玩\n",
            "\n",
            "玩什麼就不要問了\n",
            "\n",
            "某天晚上 剛好在一間麵店吃飯，隔壁桌坐了兩個台女\n",
            "\n",
            "應該也是自由行來玩…\n",
            "\n",
            "於是我就暗示我朋友不要講話 假裝聽不懂\n",
            "\n",
            "安靜的吃麵\n",
            "\n",
            "於是聽到台女各種抱怨胡志明\n",
            "\n",
            "真的是快笑死…87%在台灣當慣了大小姐\n",
            "\n",
            "他們邊吃還邊不時 往我們這裡打量\n",
            "\n",
            "可能是因為我朋友頗帥的 又或是我們穿著不像越南人\n",
            "\n",
            "吃完後 我們在店門口等車，她們也出來了    我們還是假裝聽不懂\n",
            "\n",
            "其中一個女生 突然說要去廁所\n",
            "\n",
            "回頭跟店家借廁所…然後當場被店家拒絕\n",
            "\n",
            "我看她的表情 超級不爽 轉頭跟同伴抱怨\n",
            "\n",
            "我心裡真的快笑死\n",
            "\n",
            "自以為在台灣橫著走 出了國別人就要理你嗎？\n",
            "\n",
            "越南最不缺的就是妹 ok?\n",
            "\n",
            "於是我不演了 好意跟她說 你給個1-2萬盾（台幣10塊）他就借你了 如果你急的話\n",
            "\n",
            "聽完她也不會說謝謝 繼續繃著臉…\n",
            "\n",
            "好吧…我也不理她了\n",
            "\n",
            "我們車來了就離開了\n",
            "\n",
            "我猜 他們的os 可能是 搞屁啊 老娘在台灣可是一堆工具人 舔狗\n",
            "\n",
            "沒想到來越南還要被門口阿桑白眼 上廁所 還要付錢…\n",
            "\n",
            "\n",
            "說句難聽一點，也就台灣處處讓著台女而已，千萬不要以為自己真的是鑲金的\n",
            "\n",
            "我朋友說 幹 你真的很靠北 但我喜歡！\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "發現有些台男\n",
            "明明就找不到對象\n",
            "卻不願意找外籍\n",
            "\n",
            "是否是因為找台女還能要求有工作\n",
            "\n",
            "找外配可能找不到工作(除非開越南小吃店)\n",
            "還可能要養對方越南一大家子呢？\n",
            "\n",
            "有沒有八卦\n",
            "\n",
            "\n",
            "未來的有一天\n",
            "\n",
            "如果印度的移工來到台灣\n",
            "\n",
            "街上勢必有更多印度男\n",
            "\n",
            "印度男有深邃的五官\n",
            "\n",
            "黝黑健康的身體\n",
            "\n",
            "相比之下台男東方臉+白斬雞身材  台女更不會挑台男了吧?\n",
            "\n",
            "有沒有卦?\n",
            "\n",
            "\n",
            "我有遇過那種我完全沒錯的女生\n",
            "死的都能掰成活的\n",
            "但那時候暈船暈的厲害\n",
            "所以一直舔\n",
            "現在想想真的是去他馬的\n",
            "\n",
            "現在這個就會道歉了\n",
            "不接電話被我罵\n",
            "我開車時打電話過來也被我罵\n",
            "然後她就一直道歉\n",
            "\n",
            "唉\n",
            "果然女人就是要\n",
            "；）\n",
            "\n",
            "最後奉勸遇到那種，遲到不道歉、無理不道歉、\n",
            "佔了便宜還說你自願的這種死XX，\n",
            "\n",
            "我只有兩個字\n",
            "快跑啊\n",
            "\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "？？？\n",
            "我遇到的比較多是台男才少主動認錯吧？\n",
            " \n",
            "一推愛面子愛到不行 說話一定要或多或少帶有宣示自己優點的說法\n",
            "一察覺到有人的長處是比自己差的 一定要衝出來說嘴一番\n",
            " \n",
            "真的被打臉 每位根Godtone 比沈默加無視\n",
            " \n",
            "女生至少還會說「對不起啦 不要生氣」\n",
            "或是「我知道錯了」\n",
            "你還不接受才會說「我都道歉了 你還要怎樣？」\n",
            " \n",
            "你的情景應該是\n",
            "「在職場上為什麼都不主動認錯」\n",
            " \n",
            "你剛出社會？工作上沒人在認錯的 特別是傳產\n",
            "你把證據塞在他臉上也不會說 跟政客有87%像\n",
            " \n",
            "為什麼？因為你如果認錯…\n",
            "扣你年終也是理所當然囉\n",
            "把你評價最低也可以囉\n",
            "讓你會議上一個人全扛也是名正言順把 你都認錯了\n",
            "升職等沒有你很正常吧！明年再加油囉\n",
            " \n",
            "但不認錯又不一樣了\n",
            " \n",
            "以前菜菜的時候主管聽到我認錯興奮的跟什麼一樣 我才知道那就是地獄的開端\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "user_id = \"herex (魔導戰士破壞者)\"\n",
        "\n",
        "# 创建一个空列表，用于存储特定用户的所有文章\n",
        "user_utterances = []\n",
        "\n",
        "# 遍历Corpus对象中的所有utterance，筛选出特定用户的所有文章\n",
        "for utt in corpus.iter_utterances():\n",
        "    if utt.speaker.id == user_id:\n",
        "        user_utterances.append(utt)\n",
        "\n",
        "# 输出特定用户的文章数量\n",
        "print(\"用户 {} 的文章数量：{}\".format(user_id, len(user_utterances)))\n",
        "\n",
        "# 输出特定用户的前几篇文章的文本内容\n",
        "num_to_display = 5\n",
        "print(\"用户 {} 的前 {} 篇文章内容：\".format(user_id, num_to_display))\n",
        "for i, utt in enumerate(user_utterances[:num_to_display]):\n",
        "    print(\"文章 {}:\".format(i+1))\n",
        "    print(utt.text)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQHTxI_FdvpK",
        "outputId": "5182a9b5-5dd1-4480-b6ea-6211ce1d1f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "用户 herex (魔導戰士破壞者) 的文章数量：126\n",
            "用户 herex (魔導戰士破壞者) 的前 5 篇文章内容：\n",
            "文章 1:\n",
            "\n",
            "安安如題\n",
            "\n",
            "眾所周知韓國是一個女權低落的地方\n",
            "\n",
            "如果是某些崇拜韓國的台女嫁給韓男\n",
            "\n",
            "卻沒有好好侍奉歐巴大人\n",
            "\n",
            "被超派鐵拳狠狠打一頓 會不會報警處理？\n",
            "\n",
            "如果是被台男打\n",
            "\n",
            "早就告到對方脫褲子都不夠賠吧\n",
            "\n",
            "如果被韓男揍會比照辦理嗎？\n",
            "\n",
            "有掛？\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "文章 2:\n",
            "\n",
            "安安如題\n",
            "\n",
            "眾所周知韓國是一個女權低落的地方\n",
            "\n",
            "如果是某些崇拜韓國的台女嫁給韓男\n",
            "\n",
            "卻沒有好好侍奉歐巴大人\n",
            "\n",
            "被超派鐵拳狠狠打一頓 會不會報警處理？\n",
            "\n",
            "如果是被台男打\n",
            "\n",
            "早就告到對方脫褲子都不夠賠吧\n",
            "\n",
            "如果被韓男揍會比照辦理嗎？\n",
            "\n",
            "有掛？\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "文章 3:\n",
            "\n",
            "安安如題\n",
            "\n",
            "眾所周知韓國是一個女權低落的地方\n",
            "\n",
            "如果是某些崇拜韓國的台女嫁給韓男\n",
            "\n",
            "卻沒有好好侍奉歐巴大人\n",
            "\n",
            "被超派鐵拳狠狠打一頓 會不會報警處理？\n",
            "\n",
            "如果是被台男打\n",
            "\n",
            "早就告到對方脫褲子都不夠賠吧\n",
            "\n",
            "如果被韓男揍會比照辦理嗎？\n",
            "\n",
            "有掛？\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "文章 4:\n",
            "\n",
            "安安如題\n",
            "\n",
            "眾所周知韓國是一個女權低落的地方\n",
            "\n",
            "如果是某些崇拜韓國的台女嫁給韓男\n",
            "\n",
            "卻沒有好好侍奉歐巴大人\n",
            "\n",
            "被超派鐵拳狠狠打一頓 會不會報警處理？\n",
            "\n",
            "如果是被台男打\n",
            "\n",
            "早就告到對方脫褲子都不夠賠吧\n",
            "\n",
            "如果被韓男揍會比照辦理嗎？\n",
            "\n",
            "有掛？\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "文章 5:\n",
            "\n",
            "安安如題\n",
            "\n",
            "眾所周知韓國是一個女權低落的地方\n",
            "\n",
            "如果是某些崇拜韓國的台女嫁給韓男\n",
            "\n",
            "卻沒有好好侍奉歐巴大人\n",
            "\n",
            "被超派鐵拳狠狠打一頓 會不會報警處理？\n",
            "\n",
            "如果是被台男打\n",
            "\n",
            "早就告到對方脫褲子都不夠賠吧\n",
            "\n",
            "如果被韓男揍會比照辦理嗎？\n",
            "\n",
            "有掛？\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code snippet demonstrates how to use ConvoKit to extract all articles for a specific user from the corpus. First, I specified the user ID to extract articles as \"herex (魔導戰士破壞者)\". I then looped through all utterances in the corpus and filtered out all articles by a specific user by checking the speaker ID of each utterance. Finally, I output the number of posts for a specific user and the text content of the previous posts."
      ],
      "metadata": {
        "id": "Jhiw5uBsegV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code block uses the ConvoKit library to load data and perform basic analysis. I first created the Utterance object and constructed a Corpus object, and then output the number of speeches and the number of speakers. Finally, I output the text content of the first few statements to quickly see the basics of the data."
      ],
      "metadata": {
        "id": "86u9uH7ZbBad"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTLm96n5u4Tp"
      },
      "source": [
        "## Creating networks of agents from corpora\n",
        "\n",
        "Now let's return to the Davies corpora (specifically, Soap Operas) to see how we can extract actors and build a network of their relationships in the texts.\n",
        "\n",
        "We'll use the `lucem_illud.loadDavies()` function to get the dataframe. Make sure to download `SOAP.zip` from DropBox, unzip, and edit the following line with the path to that file. This code may take some time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUb1szm43BQV",
        "outputId": "ea0a7b79-4505-43bc-8b96-3ece2a71dd2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wa5SHZElu4Tq",
        "outputId": "22b12cd1-b494-4566-a603-8f44b54dbca7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "corpora_address = \"/content/drive/MyDrive/SOCI40133/SOAP\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gAsNS0tu4Tq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "e9246e8d-53b7-4a33-9b7d-9ace3c672dfd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_0-tez.zip\n",
            "text_1-teh.zip\n",
            "text_2-wts.zip\n",
            "text_3-pem.zip\n",
            "text_4-jfy.zip\n",
            "text_5-rag.zip\n",
            "text_6-egn.zip\n",
            "text_7-jss.zip\n",
            "text_8-sbo.zip\n",
            "text_9-jtw.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        }
      ],
      "source": [
        "soap_texts = lucem_illud.loadDavies(corpora_address, num_files=2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLX8EyJ4u4Tq"
      },
      "source": [
        "We now use the source to see how the data is stored. Note that this is different from the movies corpus, and that we will need to use a different aggregating method to store the data. Each dataset would have a different approach, but they are all very similar, it depends on how the data is stored. Here multiple textids match multiple scripts, so our soap dataframe would be structured a little differently.\n",
        "\n",
        "You can see the first 20 lines of the source file here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMK-JFuXu4Tq"
      },
      "outputs": [],
      "source": [
        "zfile = zipfile.ZipFile(corpora_address + \"/soap_sources.zip\")\n",
        "source = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMj8Rj8Ou4Tq"
      },
      "outputs": [],
      "source": [
        "for file in zfile.namelist():\n",
        "    with zfile.open(file) as f:\n",
        "        for line in f:\n",
        "            source.append(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WuMMQBQu4Tq"
      },
      "outputs": [],
      "source": [
        "source[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot2kZRB8u4Tq"
      },
      "outputs": [],
      "source": [
        "soap_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3RxxObGu4Tr"
      },
      "outputs": [],
      "source": [
        "for soap in source[3:]:\n",
        "    try:\n",
        "        textID, year, show, url = soap.decode(\"utf-8\").split(\"\\t\")\n",
        "    except UnicodeDecodeError:\n",
        "        continue\n",
        "    if show.strip() not in soap_dict:\n",
        "        soap_dict[show.strip()] = []\n",
        "    if show.strip() in soap_dict:\n",
        "        try:\n",
        "            soap_dict[show.strip()].append(soap_texts[textID.strip()])\n",
        "        except KeyError:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll0kJ-aru4Tr"
      },
      "outputs": [],
      "source": [
        "soap_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVGLhkScu4Tr"
      },
      "outputs": [],
      "source": [
        "soap_df = pd.DataFrame(columns=[\"Soap Name\", \"Tokenized Texts\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2WG3rpPu4Tr"
      },
      "outputs": [],
      "source": [
        "i = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2SlNnTXu4Ts"
      },
      "outputs": [],
      "source": [
        "for soap in soap_dict:\n",
        "    # since there were multiple lists\n",
        "    print(soap)\n",
        "    full_script = []\n",
        "    for part in soap_dict[soap]:\n",
        "        full_script = full_script + part\n",
        "    soap_df.loc[i] = [soap, full_script]\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDHoEjZ3u4Ts"
      },
      "outputs": [],
      "source": [
        "soap_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed-L10sgu4Ts"
      },
      "source": [
        "We now have each Soap, and each of the Tokenized texts. Let us see what kind of information we can get. These are American soap operas, and are likely to be cheesy and dramatic (an understatment). A fun start would be to make networks of each of the actors and actresses in these soaps.\n",
        "\n",
        "What would be a good way to create a network? Maybe everytime someone talks to someone we add one weight? But we wouldn't want to add weights whenever it's a different scene - or maybe we do? Let us look at the text and figure it out.\n",
        "\n",
        "Note that we didn't add the year here because it spans over multiple years. If we are doing different kinds of analysis we would want to a years column as well.\n",
        "\n",
        "In my dataframe, Days of Our Lives is the 4th corpora, and I conducted my basic analysis on that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqbNeFcFu4Ts"
      },
      "outputs": [],
      "source": [
        "dool = soap_df['Tokenized Texts'][3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc0GN_A8u4Ts"
      },
      "outputs": [],
      "source": [
        "' '.join(dool[0:1500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxRfbaNNu4Tt"
      },
      "source": [
        "Hmmm... we can't do our normal text processing. But this provides us with an interesting oppurtunity: every '@!' is followed by some useeful information. Let us do a quick check of how many characters exist here, and how many times they speak."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLMOTu8vu4Tt"
      },
      "outputs": [],
      "source": [
        "characters = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRDRSj4iu4Tt"
      },
      "outputs": [],
      "source": [
        "for token in dool:\n",
        "    if token[0] == '@':\n",
        "        # all characters or actions start with @, so we add that to character\n",
        "        if token[2:] not in characters:\n",
        "            characters[token[2:]] = 0\n",
        "        if token[2:] in characters:\n",
        "            characters[token[2:]] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTPwcelKu4Tt"
      },
      "outputs": [],
      "source": [
        "len(characters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMgc_hE2u4Tt"
      },
      "source": [
        "Wow, that's a lot of characters: but we notice a '@!' between certain actions too, such as screaming and sobbing. Let us maybe only look for characters with a high number of appearances?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKtIeqYRu4Tu"
      },
      "outputs": [],
      "source": [
        "for character in characters:\n",
        "    if characters[character] > 2000:\n",
        "        print(character, characters[character])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blpP9ybfu4Tu"
      },
      "source": [
        "Let's check these folks out on the interwebz...a image of search of the name + \"days of our lives\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EcmtStiu4Tu"
      },
      "outputs": [],
      "source": [
        "Image(filename='../data/dool/dool_john.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNL8C-78u4Tu"
      },
      "outputs": [],
      "source": [
        "Image(filename='../data/dool/dool_brady.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "064MPyDFu4Tu"
      },
      "outputs": [],
      "source": [
        "# Image(filename='../data/dool/dool_hope.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7JYjj1Zu4Tu"
      },
      "outputs": [],
      "source": [
        "# Image(filename='../data/dool/dool_philip.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwnbjo9Cu4Tu"
      },
      "outputs": [],
      "source": [
        "# Image(filename='../data/dool/dool_marlena.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxO2hpxHu4Tu"
      },
      "outputs": [],
      "source": [
        "# Image(filename='../data/dool/dool_kate.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w35A6ltFu4Tu"
      },
      "outputs": [],
      "source": [
        "# Image(filename='../data/dool/dool_bo.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydQGsGvpu4Tv"
      },
      "outputs": [],
      "source": [
        "# Image(filename='../data/dool/dool_chloe.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP_ZcDwTu4Tv"
      },
      "outputs": [],
      "source": [
        "# Image(filename='../data/dool/dool_sami.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UH8aDZHu4Tv"
      },
      "outputs": [],
      "source": [
        "# Image(filename='../data/dool/dool_shawn.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i95yDU-Hu4Tv"
      },
      "outputs": [],
      "source": [
        "# Image(filename='../data/dool/dool_belle.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxOD67Imu4Tv"
      },
      "outputs": [],
      "source": [
        "# Image(filename='../data/dool/dool_lucas.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yC-4NzJxu4Tv"
      },
      "outputs": [],
      "source": [
        "# Image(filename='../data/dool/dool_nicole.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te4bqgIXu4Tv"
      },
      "source": [
        "These are definitely big, long-time players in the dramatic Days narrative. It would make sense to create a graph where each character who appears over 2000 times is a node, and each time they talk to each other, we add one to their weight. We should also store all the things these chracters say: that's useful information.\n",
        "\n",
        "So we now iterate through the tokens in a manner where we can capture this information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w53JQIXou4Tv"
      },
      "outputs": [],
      "source": [
        "actor_network = nx.Graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfBhD5bDu4Tv"
      },
      "outputs": [],
      "source": [
        "for character in characters:\n",
        "    if characters[character] > 2000:\n",
        "        actor_network.add_node(character, lines_spoken= characters[character], words=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86VTpmOou4Tv"
      },
      "outputs": [],
      "source": [
        "len(actor_network.nodes.data())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t02UF8ZFu4Tv"
      },
      "outputs": [],
      "source": [
        "actor_network.nodes.data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2Ka980gu4Tv"
      },
      "outputs": [],
      "source": [
        "actor_network.nodes['Sami']['lines_spoken']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7sqeWfBu4Tv"
      },
      "outputs": [],
      "source": [
        "i = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue8KIOQxu4Tv"
      },
      "source": [
        "The following lines of code creates the graph of actors and their relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_bBu0L_u4Tw"
      },
      "outputs": [],
      "source": [
        "for token in dool:\n",
        "    i += 1\n",
        "    if i > len(dool):\n",
        "        break\n",
        "    if token[0] == \"@\":\n",
        "        if token[2:] in actor_network.nodes():\n",
        "            j = i\n",
        "            for token_ in dool[i:]:\n",
        "                if token_[0] == \"@\":\n",
        "                    # if both the characters exist in the graph, add a weight\n",
        "                    if token_[2:] != token[2:] and token_[2:] in actor_network.nodes():\n",
        "                        if (token[2:], token_[2:]) not in actor_network.edges():\n",
        "                            actor_network.add_edge(token[2:], token_[2:], weight=0)\n",
        "                        if (token[2:], token_[2:]) in actor_network.edges():\n",
        "                            actor_network.edges[(token[2:], token_[2:])]['weight'] += 1\n",
        "                    break\n",
        "                j += 1\n",
        "            # adding characters sentences\n",
        "            actor_network.nodes[token[2:]]['words'].append(dool[i:j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ihe8wrPlu4Tw"
      },
      "outputs": [],
      "source": [
        "nx.draw(actor_network, with_labels=True, font_weight='bold')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgceZkgru4Tw"
      },
      "outputs": [],
      "source": [
        "L = []\n",
        "for node in actor_network.nodes():\n",
        "    l = []\n",
        "    for node_ in actor_network.nodes():\n",
        "        if node == node_:\n",
        "            l.append(0)\n",
        "        else:\n",
        "            l.append(actor_network.edges[(node, node_)]['weight'])\n",
        "    L.append(l)\n",
        "M_ = np.array(L)\n",
        "fig = plt.figure()\n",
        "div = pd.DataFrame(M_, columns = list(actor_network.nodes()), index = list(actor_network.nodes()))\n",
        "ax = sns.heatmap(div)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxat6VEou4Tw"
      },
      "outputs": [],
      "source": [
        "from networkx.algorithms.community import greedy_modularity_communities\n",
        "c = list(greedy_modularity_communities(actor_network))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BaszQk7u4Tw"
      },
      "outputs": [],
      "source": [
        "c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oysBkvRgu4Tw"
      },
      "source": [
        "### Finding structure in networks\n",
        "\n",
        "We now have a lot of useful information: we have a graph of all the characters, with their relationships with other characters, as well as all the words they've said. We tried finding communities, but it seems like everyone is connected to everyone: each of them form their own 'community'. Seems like people talk to each other a bunch in soaps.\n",
        "\n",
        "This is however, not the best network to find any meaningful patterns, as we can see with everyone connected to everyone. But as we can see with our heatmap, not everyone talks to everyone an equal amount. How about we only keep our \"important\" ties, where people are talking to each other a lot?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reGmOgWtu4Tw"
      },
      "outputs": [],
      "source": [
        "smaller_actor_network = nx.Graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neIvyeZlu4Tw"
      },
      "outputs": [],
      "source": [
        "for actor_1 in actor_network.nodes():\n",
        "    smaller_actor_network.add_node(actor_1, lines_spoken= actor_network.nodes[actor_1]['lines_spoken'], words=actor_network.nodes[actor_1]['words'])\n",
        "    for actor_2 in actor_network.nodes():\n",
        "        if actor_2!=actor_1 and actor_network.edges[(actor_1, actor_2)]['weight'] > 250:\n",
        "            smaller_actor_network.add_edge(actor_1, actor_2, weight=actor_network.edges[(actor_1, actor_2)]['weight'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn0OHDdnu4Tw"
      },
      "outputs": [],
      "source": [
        "nx.draw(smaller_actor_network, with_labels=True, font_weight='bold')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVgfKUi7u4Tw"
      },
      "source": [
        "This is a lot more interesting: while the sets of characters overlap, there is still two distinct communities if you look at characters who regularly talk to each other!\n",
        "\n",
        "Let us see what our centrality measures look like, as well as communities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMMB6zVnu4Tw"
      },
      "outputs": [],
      "source": [
        "from networkx.algorithms.community import greedy_modularity_communities\n",
        "c = list(greedy_modularity_communities(smaller_actor_network))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn4PJkmTu4Tw"
      },
      "outputs": [],
      "source": [
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY_7JTpIu4Tw"
      },
      "outputs": [],
      "source": [
        "dcentralities = nx.degree_centrality(smaller_actor_network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-ERLcACu4Tw"
      },
      "outputs": [],
      "source": [
        "dcentralities['John'], dcentralities['Philip']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me3dpUwnu4Tw"
      },
      "source": [
        "Our two different communities show up as detected by the networkx algorithm, and when we look at centralities, we can see that John is a lot more central than Philip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5roxG4Wu4Tx"
      },
      "source": [
        "Let us go back to our original graph, and see if the weight or number of similar appearences matches the text... how do we do this? Well, we already have the graph, and we also have information of who spoke to who. So we have our framework!\n",
        "\n",
        "This means we can explore ideas contained in two of the papers you will be reading: . “No country for old members: User lifecycle and linguistic change in online communities.”, and  “Fitting In or Standing Out? The Tradeoffs of Structural and Cultural Embeddedness”, both of which you can access on Canvas.\n",
        "\n",
        "Let us use a simplified version of the papers, and check if a higher number of conversations might lead to a higher similarity between the word distributions for two characters. We can use the same divergences we used in the last notebook. Do you think it will match with the number of times each character was associated with each other?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCXANeVFu4Tx"
      },
      "outputs": [],
      "source": [
        "def kl_divergence(X, Y):\n",
        "    P = X.copy()\n",
        "    Q = Y.copy()\n",
        "    P.columns = ['P']\n",
        "    Q.columns = ['Q']\n",
        "    df = Q.join(P).fillna(0)\n",
        "    p = df.iloc[:,1]\n",
        "    q = df.iloc[:,0]\n",
        "    D_kl = scipy.stats.entropy(p, q)\n",
        "    return D_kl\n",
        "\n",
        "def chi2_divergence(X,Y):\n",
        "    P = X.copy()\n",
        "    Q = Y.copy()\n",
        "    P.columns = ['P']\n",
        "    Q.columns = ['Q']\n",
        "    df = Q.join(P).fillna(0)\n",
        "    p = df.iloc[:,1]\n",
        "    q = df.iloc[:,0]\n",
        "    return scipy.stats.chisquare(p, q).statistic\n",
        "\n",
        "def Divergence(corpus1, corpus2, difference=\"KL\"):\n",
        "    \"\"\"Difference parameter can equal KL, Chi2, or Wass\"\"\"\n",
        "    freqP = nltk.FreqDist(corpus1)\n",
        "    P = pd.DataFrame(list(freqP.values()), columns = ['frequency'], index = list(freqP.keys()))\n",
        "    freqQ = nltk.FreqDist(corpus2)\n",
        "    Q = pd.DataFrame(list(freqQ.values()), columns = ['frequency'], index = list(freqQ.keys()))\n",
        "    if difference == \"KL\":\n",
        "        return kl_divergence(P, Q)\n",
        "    elif difference == \"Chi2\":\n",
        "        return chi2_divergence(P, Q)\n",
        "    elif difference == \"KS\":\n",
        "        try:\n",
        "            return scipy.stats.ks_2samp(P['frequency'], Q['frequency']).statistic\n",
        "        except:\n",
        "            return scipy.stats.ks_2samp(P['frequency'], Q['frequency'])\n",
        "    elif difference == \"Wasserstein\":\n",
        "        try:\n",
        "            return scipy.stats.wasserstein_distance(P['frequency'], Q['frequency'], u_weights=None, v_weights=None).statistic\n",
        "        except:\n",
        "            return scipy.stats.wasserstein_distance(P['frequency'], Q['frequency'], u_weights=None, v_weights=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7puMo1jpu4Tx"
      },
      "outputs": [],
      "source": [
        "corpora = []\n",
        "for character in actor_network.nodes():\n",
        "    character_words = []\n",
        "    for sentence in actor_network.nodes[character]['words']:\n",
        "        for word in sentence:\n",
        "            character_words.append(word)\n",
        "    corpora.append(lucem_illud.normalizeTokens(character_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm_UV6F-u4Tx"
      },
      "outputs": [],
      "source": [
        "L = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I3zO1aru4Tx"
      },
      "outputs": [],
      "source": [
        "for p in corpora:\n",
        "    l = []\n",
        "    for q in corpora:\n",
        "        l.append(Divergence(p,q, difference='KS'))\n",
        "    L.append(l)\n",
        "M = np.array(L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSxqGKImu4Tx"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "div = pd.DataFrame(M, columns = list(actor_network.nodes()), index = list(actor_network.nodes()))\n",
        "ax = sns.heatmap(div)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWl023jZu4Tx"
      },
      "outputs": [],
      "source": [
        "# np.corrcoef(M_, M)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xyq3Xc5u4Tx"
      },
      "source": [
        "With our two heatplots, we can attempt to do some rudimentary analysis. We can see from our previous plot that Shawn and Belle talk to each other a lot, so do Hope and Bo, and Nicole and Brady, and Lucas and Sami. Do they also talk *like* each other?\n",
        "\n",
        "Kind of, actually: all four of these pairs have a lower distance between them. Now I don't know anything about this particular soap... are these four pairs related? Are they in a relationship, either married or dating, or are they just really good friends?\n",
        "\n",
        "This lays out the frameworks which you can now use to explore your own networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKO923c-u4Tx"
      },
      "source": [
        "# Interactional influence\n",
        "\n",
        "Before we utilize transformers, let's see how to estimate the influence of one speaker on another in order to estimate a kind of interpersonal influence network based on a recent paper by Fangjian Guo, Charles Blundell, Hanna Wallach, and Katherine Heller entitled [\"The Bayesian Echo Chamber: Modeling Social Influence via Linguistic Accommodation\"](https://arxiv.org/pdf/1411.2674.pdf). This relies on a kind of point process called a Hawkes process that estimate the influence of one point on another. Specifically, what they estimate is the degree to which one actor to an interpersonal interaction engaged in \"accomodation\" behaviors relative to the other, generating a directed edge from the one to the other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc7Y9uaAu4Tx"
      },
      "source": [
        "### First let's look at the output of their analysis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR0IMwU0u4Tx"
      },
      "outputs": [],
      "source": [
        "example_name = '12-angry-men'   #example datasets: \"12-angry-men\" or \"USpresident\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QISN5ARu4Tx"
      },
      "outputs": [],
      "source": [
        "result_path = '../data/Bayesian-echo/results/{}/'.format(example_name)\n",
        "if not os.path.isdir(result_path):\n",
        "    raise ValueError('Invalid example selected, only \"12-angry-men\" or \"USpresident\" are avaliable')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pEw_U9Cu4Tx"
      },
      "outputs": [],
      "source": [
        "df_meta_info = pd.read_table(result_path + 'meta-info.txt',header=None)\n",
        "df_log_prob = pd.read_csv(result_path + \"SAMPLE-log_prior_and_log_likelihood.txt\",delim_whitespace=True) #log_prob samples\n",
        "df_influence = pd.read_csv(result_path + 'SAMPLE-influence.txt',delim_whitespace=True) # influence samples\n",
        "df_participants = pd.read_csv(result_path + 'cast.txt', delim_whitespace=True)\n",
        "person_id = pd.Series(df_participants['agent.num'].values-1,index=df_participants['agent.name']).to_dict()\n",
        "print()\n",
        "print ('Person : ID')\n",
        "person_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhkiQmLou4Tx"
      },
      "outputs": [],
      "source": [
        "def getDensity(df):\n",
        "    data = df#_log_prob['log.prior']\n",
        "    density = scipy.stats.gaussian_kde(data)\n",
        "    width = np.max(data) - np.min(data)\n",
        "    xs = np.linspace(np.min(data)-width/5, np.max(data)+width/5,600)\n",
        "    density.covariance_factor = lambda : .25\n",
        "    density._compute_covariance()\n",
        "    return xs, density(xs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yHCXTcZu4Ty"
      },
      "source": [
        "### Plot MCMC (Markov Monte Carlo) trace and the density of log-likelihoods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tl61ysK9u4Ty",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=[12,10])\n",
        "\n",
        "plt.subplot(4,2,1)\n",
        "plt.plot(df_log_prob['log.prior'])\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('Trace of log.prior')\n",
        "\n",
        "plt.subplot(4,2,2)\n",
        "x,y = getDensity(df_log_prob['log.prior'])\n",
        "plt.plot(x,y)\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('Density of log.prior')\n",
        "\n",
        "plt.subplot(4,2,3)\n",
        "plt.plot(df_log_prob['log.likelihood'])\n",
        "plt.title('Trace of log.likelihood')\n",
        "plt.xlabel('Iterations')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(4,2,4)\n",
        "x,y = getDensity(df_log_prob['log.likelihood'])\n",
        "plt.plot(x,y)\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('Density of log.likelihood')\n",
        "\n",
        "plt.subplot(4,2,5)\n",
        "plt.plot(df_log_prob['log.likelihood.test.set'])\n",
        "plt.title('Trace of log.likelihood.test.set')\n",
        "plt.xlabel('Iterations')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(4,2,6)\n",
        "x,y = getDensity(df_log_prob['log.likelihood.test.set'])\n",
        "plt.plot(x,y)\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('Density of log.likelihood.test.set')\n",
        "\n",
        "plt.subplot(4,2,7)\n",
        "plt.plot(df_log_prob['log.prior']+df_log_prob['log.likelihood'])\n",
        "plt.title('Trace of log.prob')\n",
        "plt.xlabel('Iterations')\n",
        "\n",
        "plt.subplot(4,2,8)\n",
        "x,y = getDensity(df_log_prob['log.prior']+df_log_prob['log.likelihood'])\n",
        "plt.plot(x,y)\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('Density of log.prob')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtvCkOatu4Ty"
      },
      "source": [
        "### Plot the influence matrix between participants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuBGtsRPu4Ty"
      },
      "outputs": [],
      "source": [
        "A = int(np.sqrt(len(df_influence.columns))) #number of participants\n",
        "id_person = {}\n",
        "for p in person_id:\n",
        "    id_person[person_id[p]]=p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mKp2go6u4Ty"
      },
      "outputs": [],
      "source": [
        "def getmatrix(stacked,A):\n",
        "    influence_matrix = [[0 for i in range(A)] for j in range(A)]\n",
        "    for row in stacked.iteritems():\n",
        "        from_ = int(row[0].split('.')[1])-1\n",
        "        to_ = int(row[0].split('.')[2])-1\n",
        "        value = float(row[1])\n",
        "        influence_matrix[from_][to_]=value\n",
        "    df_ = pd.DataFrame(influence_matrix)\n",
        "\n",
        "    df_ =df_.rename(index = id_person)\n",
        "    df_ =df_.rename(columns = id_person)\n",
        "    return df_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwXt6Jjau4Ty"
      },
      "outputs": [],
      "source": [
        "stacked = df_influence.mean(axis=0)\n",
        "df_mean = getmatrix(stacked,A)\n",
        "\n",
        "stacked = df_influence.std(axis=0)\n",
        "df_std = getmatrix(stacked,A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZiDBL_Tu4Ty"
      },
      "outputs": [],
      "source": [
        "df_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UxyVIo_u4Ty"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(9, 6))\n",
        "seaborn.heatmap(df_mean, annot=True,  linewidths=.5, ax=ax,cmap=\"YlGnBu\")\n",
        "print('MEAN of influence matrix (row=from, col=to)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuPFyfa5u4Ty"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(9, 6))\n",
        "seaborn.heatmap(df_std, annot=True,  linewidths=.5, ax=ax,cmap=\"YlGnBu\")\n",
        "print('SD of influence matrix (row=from, col=to)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBEDpRYiu4Ty"
      },
      "source": [
        "### Barplot of total influences sent/received"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_ncnkFuu4Tz"
      },
      "outputs": [],
      "source": [
        "sender_std = {} #sd of total influence sent\n",
        "reciever_std = {} #sd of total influence recieved\n",
        "for i in range(A):\n",
        "    reciever_std[id_person[i]] = df_influence[df_influence.columns[i::A]].sum(axis=1).std()\n",
        "    sender_std[id_person[i]] = df_influence[df_influence.columns[i*A:(i+1)*A:]].sum(axis=1).std()\n",
        "\n",
        "sent = df_mean.sum(axis=1) #mean of total influence sent\n",
        "recieved =df_mean.sum(axis=0) #mean of total influence recieved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcwtbGkru4Tz"
      },
      "source": [
        "Total influence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no35DLoeu4Tz"
      },
      "outputs": [],
      "source": [
        "print (\"\\t\\tTotal linguistic influence sent/received \")\n",
        "ax.fig = plt.figure(figsize=[np.min([A,20]),6])\n",
        "\n",
        "plt.grid()\n",
        "wd=0.45\n",
        "ii=0\n",
        "for p in sender_std:\n",
        "    plt.bar(person_id[p],sent.loc[p],width=wd,color='red',alpha=0.6,label = \"Sent\" if ii == 0 else \"\")\n",
        "    plt.plot([person_id[p]-wd/4,person_id[p]+wd/4],[sent.loc[p]+sender_std[p],sent.loc[p]+sender_std[p]],color='k')\n",
        "    plt.plot([person_id[p]-wd/4,person_id[p]+wd/4],[sent.loc[p]-sender_std[p],sent.loc[p]-sender_std[p]],color='k')\n",
        "    plt.plot([person_id[p],person_id[p]],[sent.loc[p]-sender_std[p],sent.loc[p]+sender_std[p]],color='k')\n",
        "    ii+=1\n",
        "ii=0\n",
        "for p in reciever_std:\n",
        "    plt.bar(person_id[p]+wd,recieved.loc[p],width=wd,color='blue',alpha=0.4,label = \"Received\" if ii == 0 else \"\")\n",
        "    plt.plot([person_id[p]+wd-wd/4,person_id[p]+wd+wd/4],[recieved.loc[p]+reciever_std[p],recieved.loc[p]+reciever_std[p]],color='k')\n",
        "    plt.plot([person_id[p]+wd-wd/4,person_id[p]+wd+wd/4],[recieved.loc[p]-reciever_std[p],recieved.loc[p]-reciever_std[p]],color='k')\n",
        "    plt.plot([person_id[p]+wd,person_id[p]+wd],[recieved.loc[p]-reciever_std[p],recieved.loc[p]+reciever_std[p]],color='k')\n",
        "    ii+=1\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.7))\n",
        "plt.xticks([i+0.25 for i in range(A)],list(zip(*sorted(id_person.items())))[1])\n",
        "plt.ylabel('value')\n",
        "plt.xlabel('speaker',fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erlt5NtCu4Tz"
      },
      "source": [
        "## Visualize Influence Network!\n",
        "\n",
        "You can visualize any of the influence matrices above:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfvNdgTZu4Tz"
      },
      "source": [
        "Using networkx:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdCdG8equ4Tz"
      },
      "outputs": [],
      "source": [
        "def drawNetwork(df,title):\n",
        "    fig = plt.figure(figsize=[8,8])\n",
        "    G = nx.DiGraph()\n",
        "    for from_ in df.index:\n",
        "        for to_ in df.columns:\n",
        "            G.add_edge(from_,to_,weight = df.loc[from_][to_])\n",
        "\n",
        "    pos = nx.spring_layout(G,k=0.55,iterations=20)\n",
        "    edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
        "    weights = np.array(weights)\n",
        "    #weights = weights*weights\n",
        "    weights = 6*weights/np.max(weights)\n",
        "    print(title)\n",
        "\n",
        "    edge_colors=20*(weights/np.max(weights))\n",
        "    edge_colors = edge_colors.astype(int)\n",
        "#     nx.draw_networkx_nodes(G,pos,node_size=1200,alpha=0.7,node_color='#99cef7')\n",
        "#     nx.draw_networkx_edges(G,pos,edge_color=edge_colors)\n",
        "#     nx.draw_networkx_labels(G,pos,font_weight='bold')\n",
        "    nx.draw(G,pos,with_labels=True, font_weight='bold',width=weights,\\\n",
        "            edge_color=255-edge_colors,node_color='#99cef7',node_size=1200,\\\n",
        "            alpha=0.75,arrows=True,arrowsize=20)\n",
        "    return edge_colors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZDfo4M0u4Tz"
      },
      "outputs": [],
      "source": [
        "# get quantile influence matrices for 25%, 50%, 75% quantile\n",
        "stacked = df_influence.quantile(0.25)\n",
        "df_q25 = getmatrix(stacked,A)\n",
        "\n",
        "stacked = df_influence.quantile(0.5)\n",
        "df_q50 = getmatrix(stacked,A)\n",
        "\n",
        "stacked = df_influence.quantile(0.75)\n",
        "df_q75 = getmatrix(stacked,A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DepRYxPvu4Tz"
      },
      "outputs": [],
      "source": [
        "G_mean = drawNetwork(df_mean,'Mean Influence Network')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVYazdidu4Tz"
      },
      "outputs": [],
      "source": [
        "G_q25 = drawNetwork(df_q25,'25 Quantile Influence Network')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHTB7ssLu4Tz"
      },
      "outputs": [],
      "source": [
        "G_q75 = drawNetwork(df_q75,'75 Quantile Influence Network')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByG73MOTu4Tz"
      },
      "outputs": [],
      "source": [
        "def fakeEnglish(length):\n",
        "    listd=['a','b','c','d','e','f','g','s','h','i','j','k','l']\n",
        "    return ''.join(np.random.choice(listd,length))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWjnJUsWu4Tz"
      },
      "source": [
        "Your own dataset should contains 4 columns (with the same column names) as the artificial one below:\n",
        "\n",
        "- name: name of the participant\n",
        "- tokens: a list of tokens in one utterance\n",
        "- start: starting time of utterance (unit doesn't matter, can be 'seconds','minutes','hours'...)\n",
        "- end: ending time of utterance (same unit as start)\n",
        "\n",
        "There is no need to sort data for the moment.\n",
        "\n",
        "Below, we generate a fake collection of data from \"Obama\", \"Trump\", \"Clinton\"...and other recent presidents. You can either create your own simulation OR (better), add real interactional data from a online chat forum, comment chain, or transcribed from a conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gobXyvZMu4Tz"
      },
      "outputs": [],
      "source": [
        "script= []\n",
        "language = 'eng' #parameter, no need to tune if using English, accept:{'eng','chinese'}\n",
        "role = 'Adult' #parameter, no need to tune\n",
        "\n",
        "for i in range(290):\n",
        "    dt = []\n",
        "    dt.append(np.random.choice(['Obama','Trump','Clinton','Bush','Reagan','Carter','Ford','Nixon','Kennedy','Roosevelt']))\n",
        "    faketokens = [fakeEnglish(length = 4) for j in range(30)]\n",
        "    dt.append(faketokens) #fake utterance\n",
        "    dt.append(i*2+np.random.random()) # start time\n",
        "    dt.append(i*2+1+np.random.random()) # end time\n",
        "    script.append(dt)\n",
        "\n",
        "df_transcript = pd.DataFrame(script,columns=['name','tokens','start','end']) #\"start\", \"end\" are timestamps of utterances, units don't matter\n",
        "df_transcript[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se3wxvNuu4Tz"
      },
      "source": [
        "Transform data into TalkbankXML format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfBLvnEnu4Tz"
      },
      "outputs": [],
      "source": [
        "output_fname = 'USpresident.xml'  #should be .xml\n",
        "language = 'eng'\n",
        "#language = 'chinese'\n",
        "lucem_illud.make_TalkbankXML(df_transcript, output_fname, language = language )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25e0Y8F_u4Tz"
      },
      "source": [
        "Run Bayesian Echo Chamber to get estimation.\n",
        "\n",
        "- It may take a couple of hours. ( About 4-5 hours if Vocab_size=600 and sampling_time =2000)\n",
        "- Larger \"Vocab_size\" (see below) will cost more time\n",
        "- Larger \"sampling_time\" will also consume more time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6omtn8zhu4T0"
      },
      "outputs": [],
      "source": [
        "Vocab_size = 90 # up to Vocab_size most frequent words will be considered, it should be smaller than the total vocab\n",
        "sampling_time = 1500  #The times of Gibbs sampling sweeps  (500 burn-in not included)\n",
        "lucem_illud.bec_run(output_fname, Vocab_size, language, sampling_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HFEqCj5u4T0"
      },
      "source": [
        "## <font color=\"red\">*Exercise 2*</font>\n",
        "\n",
        "<font color=\"red\">Construct cells immediately below this that perform a similar social similarity or influence analysis on a dataset relevant to your final project (__or one from ConvoKit__). Create relationships between actors in a network based on your dataset (e.g., person to person or document to document), and perform analyses that interrogate the structure of their interactions, similarity, and/or influence on one another. (For example, if relevant to your final project, you could explore different soap operas, counting how many times a character may have used the word love in conversation with another character, and identify if characters in love speak like each other. Or do opposites attract?) What does that analysis and its output reveal about the relative influence of each actor on others? What does it reveal about the social game being played?\n",
        "\n",
        "<font color=\"red\">Stretch 1:\n",
        "Render the social network with weights (e.g., based on the number of scenes in which actors appear together), then calculate the most central actors in the show.Realtime output can be viewed in shell.\n",
        "\n",
        "<font color=\"red\">Stretch 2:\n",
        "Implement more complex measures of similarity based on the papers you have read."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "stxfD1mchqnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "nXzZoesljaf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['truncated_user'] = df['user'].apply(lambda x: x[:3] if len(x) >= 3 else x)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nfsiG0nlLse",
        "outputId": "53ae1909-fc3a-4a21-c4fa-6222dfbef7a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   user     board                  title     date type  \\\n",
            "0        sky2030 (無業遊民)  Boy-Girl          [心情] 出國巧遇台女趣事  2023-12   心情   \n",
            "1  iamjimhaha (磨刀霍霍向肥羊)  Boy-Girl  [討論] 找台女不找外配是不是因為不想養？  2023-12   討論   \n",
            "2     Sugimoto5566 (馬丁)  Boy-Girl  [討論] 印度移工如果來台,台女會怎麼選?  2023-11   討論   \n",
            "3        corydoras09 ()  Boy-Girl  Re: [討論] 為何台女很少會主動認錯?  2023-11   討論   \n",
            "4    drinkmuffin (暢飲鬆餅)  Boy-Girl  Re: [討論] 為何台女很少會主動認錯?  2023-11   討論   \n",
            "\n",
            "                                                text truncated_user  \n",
            "0  最近常跟朋友一起跑胡志明，河內玩\\n\\n玩什麼就不要問了\\n\\n某天晚上 剛好在一間麵店吃飯...            sky  \n",
            "1  \\n發現有些台男\\n明明就找不到對象\\n卻不願意找外籍\\n\\n是否是因為找台女還能要求有工作...            iam  \n",
            "2  未來的有一天\\n\\n如果印度的移工來到台灣\\n\\n街上勢必有更多印度男\\n\\n印度男有深邃的...            Sug  \n",
            "3  我有遇過那種我完全沒錯的女生\\n死的都能掰成活的\\n但那時候暈船暈的厲害\\n所以一直舔\\n現...            cor  \n",
            "4   \\n \\n？？？\\n我遇到的比較多是台男才少主動認錯吧？\\n \\n一推愛面子愛到不行 說話...            dri  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "G = nx.Graph()\n",
        "\n",
        "top_users_per_board = df.groupby('board')['truncated_user'].apply(lambda x: Counter(x).most_common(5)).to_dict()\n",
        "\n",
        "for board, users in top_users_per_board.items():\n",
        "    for (user1, _), (user2, _) in combinations(users, 2):\n",
        "        G.add_edge(user1, user2, board=board)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "pos = nx.spring_layout(G)\n",
        "nx.draw(G, pos, with_labels=True, node_size=1000, node_color='skyblue', edge_color='gray', linewidths=1, font_size=12)\n",
        "plt.title('Network Based on Top 5 Users in Each Board')\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bawu0Lojhz3d",
        "outputId": "a41d9757-b432-4d27-dfa5-d98770c57393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, I used ConvoKit's function to count the number of utterances and speakers in the corpus to understand the characteristics of the overall data. Next, I further processed and analyzed the data, such as finding the users who posted the most frequently, constructing an interactive network among users who posted, calculating the similarity or influence between speakers, etc.\n",
        "\n",
        "In this chunk, I assume that only the five most frequently posted users are displayed in each section, and the readability of the graph is improved by adjusting the size of the graph and the size of the labels.\n",
        "\n",
        "Network graphics contain the following information:\n",
        "Each node in the graph represents a user.\n",
        "An edge between two users means they have posted in the same forum.\n",
        "The size of the node indicates the user's activity level in different sections."
      ],
      "metadata": {
        "id": "erQ5vmxLi7Xa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uKnCDS1u4T0"
      },
      "source": [
        "# Text Generation & Converstaions via LangChain\n",
        "\n",
        "We can make use of the LLMs we learned in week 6 to do text generation, where the model takes one or multiple places in a conversation. While some may regard it as a parlour trick due to unpredictability, recent dramatic improvements in text generation suggest that these kind of models can find themselves being used in more serious social scientific applications, such as in survey design and construction, idiomatic translation, and the normalization of phrase and sentence meanings.\n",
        "\n",
        "These models can be quite impressive, even uncanny in how human like they sound. We mainly use the package LangChain to interact with LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTDgRy0jKDkP"
      },
      "source": [
        "## Overview:\n",
        "- Installation and setup (old packages!)\n",
        "- LLMs (Open AI and Open Source)\n",
        "- Prompt Templates and Chains (Smooth communication between models)\n",
        "- Agents and Tools, Memory, Documents\n",
        "- Simulations and Conversations\n",
        "- Simularca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WGtOYYTKfz3"
      },
      "source": [
        "## Installation\n",
        "\n",
        "In the rapidly evolving landscape of LLMs, packages and libraries like LangChain are frequently updated to leverage the latest advancements. We've chosen this particular version of LangChain for its ease of use in a Colab notebook, effectively demonstrating the power of LLMs as simulators. However, it's important to note that this code is a year old. If you're planning to use it in a production environment, it will be essential to update and adapt it to align with the latest versions and best practices in the field, ensuring compatibility and optimal performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bcrn7QRyQXGj",
        "outputId": "0d16d1e2-5784-46b9-d05a-55b5bea84b89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.0.316\n",
            "  Downloading langchain-0.0.316-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (3.9.3)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.316)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.0.316)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.43 (from langchain==0.0.316)\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.316) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.316) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.316) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.316)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.316)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.0.316)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.316) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.316) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.316) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.316) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.316) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.316) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.316) (3.0.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.316)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.316 langsmith-0.0.92 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.0.316"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "var0F2Glwnv0",
        "outputId": "b6c580fc-9e23-467e-8317-b2b78d84841f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkGGSdmtta6s"
      },
      "source": [
        "## LLMs\n",
        "\n",
        "A generic interface for all LLMs. See all LLM providers: https://python.langchain.com/en/latest/modules/models/llms/integrations.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OFLmmrtejCl"
      },
      "source": [
        "### Open AI via LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RlxEmS1CaM5v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7a76251f-55f3-4267-9e8e-79a883379adc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "pY09s9cmZ6nQ",
        "outputId": "84c6e264-9650-41bf-84b6-62e5724c5696"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"SockSpectrum Co.\" \n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm_openai = OpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo-instruct\")\n",
        "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
        "print(llm_openai(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6YNn2fvVY1iX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8e1e25a9-9ef7-4d63-c273-2e7de55f0b2e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# if you wish, you can also choose to use GPT-4, which is better. But the way to construct message is a bit different\n",
        "# https://python.langchain.com/docs/integrations/chat/openai\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(temperature=0.9, model_name=\"gpt-4-turbo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-z3EauZena2"
      },
      "source": [
        "### Using other open-source LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "idkq_aVyaceF",
        "outputId": "9b083d59-b11c-4f12-b61e-96062cb22c04"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4DKOWjyaRmO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmtH72oCaU32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4e9f5716-05ce-48bf-a721-4eec46233840"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uK5TtJPc49I",
        "outputId": "e0b4e96c-5f09-44dd-9664-7c77fba6275e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Our current thought is ColourSock. Also, if you have any tips for branding, that would be helpful as well!\n",
            "\n",
            "A name that describes exactly what the products are is fine, but you should probably have another name that is your \"brand name.\" The brand name can emphasize the colorful and playful aspects, while not necessarily having to tie it in with the type of product.\n",
            "For example, you could create a name like \"HappySocks\" or\n"
          ]
        }
      ],
      "source": [
        "# https://huggingface.co/google/flan-t5-xl\n",
        "llm_mistral = HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
        "\n",
        "print(llm_mistral(prompt = \"What would be a good company name for a company that makes colorful socks?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7kSceuAq1Bn"
      },
      "source": [
        "## Personalities and Options\n",
        "\n",
        "In the `get_meal_options` function, the integration of history and context prompts plays a crucial role in shaping the AI's conversation. The `personality_template`, which serves as a context prompt, establishes the AI's expertise in vegetarian, Italian cuisine, and healthy eating. This template sets the stage for the conversation, informing the AI about its role and area of specialization. It's akin to giving the AI a 'character' or 'personality' to adhere to during the interaction, ensuring that its responses are aligned with this predefined context.\n",
        "\n",
        "The history prompts, represented by `example_human_history` and `example_ai_history`, simulate a prior interaction between the human and the AI, adding depth to the conversation's backstory. These prompts are crucial for creating a more natural and realistic interaction, as they give the impression that the conversation is ongoing rather than starting from scratch. When combined with the context prompt in `ChatPromptTemplate`, they create a comprehensive conversation framework. This framework effectively guides the AI's responses to be consistent with both the established personality (context) and the implied history of the interaction, leading to more coherent and relevant meal suggestions for breakfast, lunch, and dinner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wyMylKqhu-IL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "06120d4c-b09c-4150-cbc6-f3f94fc4bc91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDIMf8akfE9a"
      },
      "outputs": [],
      "source": [
        "def get_meal_options(personality_template, human_history=\"\", ai_history=\"\"):\n",
        "    # Initialize ChatOpenAI with OpenAI model\n",
        "    chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\")  # Replace with your API key\n",
        "\n",
        "\n",
        "    example_human_history = HumanMessagePromptTemplate.from_template(human_history)\n",
        "    example_ai_history = AIMessagePromptTemplate.from_template(ai_history)\n",
        "\n",
        "    system_message_prompt = SystemMessagePromptTemplate.from_template(personality_template)\n",
        "\n",
        "    human_template=\"{input}\"\n",
        "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "    # Create ChatPromptTemplate\n",
        "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, example_human_history, example_ai_history, human_message_prompt])\n",
        "    # Initialize the conversation chain\n",
        "    chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
        "\n",
        "    # Ask for meal options\n",
        "    meals = ['breakfast', 'lunch', 'dinner']\n",
        "    meal_options = {}\n",
        "    for meal in meals:\n",
        "        response = chain.run(f\"What are some good {meal} options for someone who loves vegetarian, Italian cuisine and prefers healthy options?\")\n",
        "        meal_options[meal] = response\n",
        "\n",
        "    return meal_options\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vywW6mdswKSA"
      },
      "outputs": [],
      "source": [
        "# Define the personality based on food preferences\n",
        "personality_template = \"\"\"\n",
        "The following is a conversation with an AI who is an expert in vegetarian, Italian cuisine and healthy eating options.\n",
        "AI: I am here to provide creative and healthy vegetarian meal suggestions. Ask me anything about vegetarian food!\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2z822LLv6iY",
        "outputId": "bcaa202e-4475-45fe-f282-8af6c7bcf87b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'breakfast': 'For a vegetarian, Italian-inspired, and healthy breakfast, you could try the following options:\\n\\n1. Caprese Avocado Toast: Top whole grain toast with sliced avocado, fresh mozzarella, cherry tomatoes, basil leaves, a drizzle of balsamic glaze, and a sprinkle of salt and pepper.\\n\\n2. Veggie Frittata: Make a frittata with eggs, diced bell peppers, onions, zucchini, cherry tomatoes, and a sprinkle of Parmesan cheese. Bake until set and serve with a side of mixed greens.\\n\\n3. Italian-style Smoothie Bowl: Blend frozen berries, spinach, banana, almond milk, and a scoop of protein powder. Top with granola, sliced almonds, and a drizzle of honey for added sweetness.\\n\\n4. Bruschetta with Ricotta and Roasted Vegetables: Toast whole grain bread and top with ricotta cheese, roasted bell peppers, eggplant, zucchini, and a drizzle of olive oil and balsamic glaze.\\n\\n5. Overnight Chia Pudding with Mixed Berries: Mix chia seeds with almond milk, vanilla extract, and a touch of maple syrup. Let it sit overnight in the fridge and top with mixed berries in the morning for a nutritious and filling breakfast.\\n\\nThese options are not only delicious and packed with Italian flavors but also provide a good balance of nutrients to start your day on a healthy note. Enjoy!', 'lunch': 'For a delicious and healthy vegetarian Italian-inspired lunch, you can try the following options:\\n\\n1. Caprese Salad: A classic Italian dish made with fresh tomatoes, mozzarella cheese, basil leaves, olive oil, and balsamic glaze. You can add some avocado slices for extra creaminess.\\n\\n2. Eggplant Parmesan: Breaded and baked slices of eggplant layered with marinara sauce, mozzarella, and Parmesan cheese. Serve with a side salad for a complete meal.\\n\\n3. Vegetable Risotto: A creamy and comforting dish made with Arborio rice, vegetable broth, and a variety of vegetables such as peas, mushrooms, and bell peppers. Finish with a sprinkle of Parmesan cheese.\\n\\n4. Pasta Primavera: A light and colorful pasta dish loaded with seasonal vegetables like cherry tomatoes, zucchini, bell peppers, and broccoli. Toss with a garlic-infused olive oil and top with fresh basil.\\n\\n5. Spinach and Ricotta Stuffed Shells: Jumbo pasta shells filled with a mixture of ricotta cheese, spinach, garlic, and herbs, baked with marinara sauce and mozzarella cheese until bubbly.\\n\\nThese options are not only tasty and satisfying but also provide a good balance of nutrients for a healthy vegetarian lunch. Enjoy your Italian-inspired meal!', 'dinner': 'For a delicious and healthy vegetarian Italian dinner, you can try making some of the following dishes:\\n\\n1. Eggplant Parmesan: Sliced eggplant baked with marinara sauce and topped with mozzarella cheese.\\n2. Caprese Salad: Sliced tomatoes, fresh mozzarella, and basil drizzled with balsamic glaze and olive oil.\\n3. Spaghetti Aglio e Olio: Spaghetti tossed with garlic, olive oil, red pepper flakes, and parsley.\\n4. Stuffed Bell Peppers: Bell peppers filled with a mixture of quinoa, black beans, corn, and spices, topped with marinara sauce and cheese.\\n5. Risotto Primavera: Creamy risotto cooked with spring vegetables such as asparagus, peas, and spinach.\\n6. Minestrone Soup: A hearty vegetable soup made with tomatoes, beans, carrots, celery, and zucchini.\\n7. Pesto Zucchini Noodles: Zucchini noodles tossed with homemade pesto sauce, cherry tomatoes, and pine nuts.\\n8. Bruschetta: Toasted bread topped with a mixture of chopped tomatoes, basil, garlic, and olive oil.\\n\\nThese dishes are not only delicious and full of Italian flavors but also provide a good balance of nutrients for a healthy vegetarian meal. Enjoy your Italian-inspired dinner!'}\n"
          ]
        }
      ],
      "source": [
        "# Call the function to get meal options\n",
        "meal_options = get_meal_options(personality_template)\n",
        "print(meal_options)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O-7dO1htdO4"
      },
      "source": [
        "## Prompt Templates and Chaining\n",
        "\n",
        "LangChain faciliates prompt management and optimization.\n",
        "\n",
        "Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you need to take the user input and construct a prompt, and only then send that to the LLM.\n",
        "\n",
        "Prompt templates in LangChain are pre-defined formats or structures for creating prompts that are sent to a language model. These templates help in standardizing and automating the way you interact with the model, ensuring consistency and potentially improving the quality of responses. They are particularly useful when you need to generate prompts that follow a specific format or include certain fixed elements.\n",
        "\n",
        "For example, you might have a prompt template for a customer service bot where each prompt starts with a greeting, includes the user's question, and ends with a closing statement. By using a template, you can easily insert the user's specific question into the prompt without having to manually format the entire prompt each time.\n",
        "\n",
        "This can also be useful if you are conducting a research experiment to consistently measure responses, or for annotation purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_FDS9IDRapOt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "858bd54b-38cf-45f1-8857-1b46bcbd844f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LtIaMPKVx_Q7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "95135651-02fe-4885-8da5-33cab4db8434"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define the template for sarcasm annotation\n",
        "sarcasm_template = \"\"\"\n",
        "Analyze the following text to determine if it is sarcastic or not.\n",
        "\n",
        "Text: \"{text}\"\n",
        "\n",
        "Is the text sarcastic? Provide a brief explanation for your decision:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hBOCff6ryBGe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "aedccf8b-b657-470c-9f0d-bb16d026a44a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create a PromptTemplate instance with the defined template\n",
        "sarcasm_prompt = PromptTemplate(template=sarcasm_template, input_variables=[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "DO77wA568zLv",
        "outputId": "ddd29afc-179a-41a7-dae8-2b4a528c8169"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['text'], template='\\nAnalyze the following text to determine if it is sarcastic or not.\\n\\nText: \"{text}\"\\n\\nIs the text sarcastic? Provide a brief explanation for your decision:\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "sarcasm_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-Yzpc_0aHHeE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8d793fef-5005-4a91-a706-df8c69001af8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Example text to be analyzed\n",
        "example_text = \"Oh great, another Monday morning!\"\n",
        "\n",
        "# Format the prompt with the specific text\n",
        "prompt_text = sarcasm_prompt.format(text=example_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "on8ubh3kt7oD",
        "outputId": "eaa492be-beb3-47cd-ea7d-c27266e6bcf9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAnalyze the following text to determine if it is sarcastic or not.\\n\\nText: \"Oh great, another Monday morning!\"\\n\\nIs the text sarcastic? Provide a brief explanation for your decision:\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "prompt_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "BwtCx_aAghQi",
        "outputId": "9cd24071-05cc-4b72-9a21-e36db2553edb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The text is likely sarcastic. The use of \"oh great\" suggests a tone of sarcasm, as the speaker is not actually happy about it being Monday morning. Additionally, the exclamation mark adds to the sarcastic tone by emphasizing a lack of genuine enthusiasm. This phrase is commonly used in a sarcastic manner when someone is dreading the start of the work week.\n"
          ]
        }
      ],
      "source": [
        "print(llm_openai(prompt_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zw1KlSeuUOY"
      },
      "source": [
        "## Chains\n",
        "\n",
        "Chaining refers to the process of using the output from one model as the input to another model, or even as input back into the same model, in a sequential manner. This allows for more complex interactions and workflows that go beyond single-turn question-answer formats.\n",
        "\n",
        "In the context of LangChain, chaining can be used to create multi-step processes or workflows. For instance, you might first use a language model to generate a draft response to a user's query, then pass this draft through another model (or the same model) for further refinement, summarization, or translation.\n",
        "\n",
        "Chaining can be powerful in scenarios where a single interaction with a model is insufficient to achieve the desired outcome. It enables more sophisticated applications, such as:\n",
        "\n",
        "Iterative Refinement: Where the output of a model is refined over several iterations to improve quality or detail.\n",
        "Multi-Model Workflows: Where different models are used for different tasks in a sequence, like one model generating content and another summarizing it.\n",
        "Feedback Loops: Where the output of a model is fed back as input to the same model, possibly with modifications, to simulate a conversation or to gradually steer the model towards a specific goal.\n",
        "In LangChain, chaining is facilitated by its architecture, which allows for easy integration and sequencing of different models and processes.\n",
        "\n",
        "Below is the simplest example of such a chain -> simply passing a prompt and model and then \"running\" will pass the message to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "eE6n-jbAuOxt",
        "outputId": "6866421b-e1a6-4a24-ae6c-49bdc4fa9975"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Yes, the text is sarcastic. The speaker is using exaggerated and ironic language to express their disdain for working hard and making minimum wage. The statement about class distinctions being a good thing further emphasizes the sarcasm as it goes against the common belief that equal opportunities and fair pay are important in society.\n"
          ]
        }
      ],
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "llm_chain = LLMChain(prompt=sarcasm_prompt, llm=llm_openai)\n",
        "\n",
        "question = \"Oh, awesome, I love working hard and making minimum wage. Class distinctions are a good thing.\"\n",
        "\n",
        "print(llm_chain.run(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgRYGSrTEGDZ"
      },
      "outputs": [],
      "source": [
        "text_gen_template = \"Write a creative, humorous and sarcastic statement about {text}.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3y2p6rqsHJ7l"
      },
      "outputs": [],
      "source": [
        "prompt_gen = PromptTemplate(template=text_gen_template, input_variables=[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GvOyi8pEGGI"
      },
      "outputs": [],
      "source": [
        "llm_chain_gen = LLMChain(prompt=prompt_gen, llm=llm_mistral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kgZmY4vEGI9"
      },
      "outputs": [],
      "source": [
        "sarcastic_subject = \"Mondays\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "BNa_umQ5HmD3",
        "outputId": "0302b03b-0f55-4da1-a301-712d5655c49e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nUgh... It's Monday again! That delightful day where dreams of weekend freedom shatter as reality comes crashing down. The perfect time to relish in the joy of alarms, traffic jams, and the ever-growing mountain of emails from people who apparently have nothing better to do on the weekends than to think up new ways to bother you. Mondays: When the sweet taste of freedom morphs into the bitter tang of responsibility, and Saturday's\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "llm_chain_gen.run(sarcastic_subject)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp-UlOK0bMVQ"
      },
      "source": [
        "## Agents and Tools\n",
        "\n",
        "Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n",
        "\n",
        "\n",
        "When used correctly agents can be extremely powerful. In order to load agents, you should understand the following concepts:\n",
        "\n",
        "- Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains.\n",
        "- LLM: The language model powering the agent.\n",
        "- Agent: The agent to use.\n",
        "\n",
        "Tools: https://python.langchain.com/en/latest/modules/agents/tools.html\n",
        "\n",
        "Agent Types: https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79JcjhFXwv0J"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.tools import YouTubeSearchTool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOSpaurEb1MR",
        "outputId": "bf2a8712-16dc-4db5-d65d-ce8b4f20ae26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=b4a37b1871356309c8db81b2610f1a81975c1c74862a7881ee68f0b431427b90\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgV4kny1bgy1"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo-instruct\")\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQUOsWLrbjKv"
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "M8Rob2Wsb_l9",
        "outputId": "f5010b7e-dbaf-4b0e-fb08-5b12afbff2d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m We can use Wikipedia to find the year the film was released and a Calculator to raise it to a power.\n",
            "Action: Wikipedia\n",
            "Action Input: The Departed\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: The Departed\n",
            "Summary: The Departed is a 2006 American crime thriller film directed by Martin Scorsese and written by William Monahan. It is both a remake of the 2002 Hong Kong film Infernal Affairs and also loosely based on the real-life Boston Winter Hill Gang; the character Colin Sullivan is based on the corrupt FBI agent John Connolly, while the character Frank Costello is based on Irish-American gangster and crime boss Whitey Bulger. The film stars Leonardo DiCaprio, Matt Damon, Jack Nicholson, and Mark Wahlberg, with Martin Sheen, Ray Winstone, Vera Farmiga, Alec Baldwin, Anthony Anderson and James Badge Dale in supporting roles.\n",
            "The film takes place in Boston and the surrounding metro area, primarily in the South Boston neighborhood. Irish Mob boss Frank Costello (Nicholson) plants Colin Sullivan (Damon) as a spy within the Massachusetts State Police; simultaneously, the police assign undercover state trooper Billy Costigan (DiCaprio) to infiltrate Costello's mob crew. When both sides realize the situation, Sullivan and Costigan each attempt to discover the other's identity before they are found out.\n",
            "The Departed was a critical and commercial success, receiving acclaim for its direction, performances (particularly of DiCaprio, Nicholson, and Wahlberg), screenplay, and editing.\n",
            "It won several accolades, including four Oscars at the 79th Academy Awards: for Best Picture, Best Director, Best Adapted Screenplay, and Best Film Editing. It became Scorsese's first and, to date, only personal Oscar win; Wahlberg was also nominated for Best Supporting Actor. The film also received six nominations at the 64th Golden Globe Awards, six nominations at the 60th British Academy Film Awards, and two nominations at the 13th Screen Actors Guild Awards. DiCaprio was nominated for Golden Globe Award for Best Actor – Motion Picture Drama (also nominated that year in the same category for Blood Diamond), BAFTA Award for Best Actor in a Leading Role and Screen Actors Guild Award for Outstanding Performance by a Male Actor in a Supporting Role for his performance.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The film was released in 2006 and we can use a calculator to raise it to the power of 0.43.\n",
            "Action: Calculator\n",
            "Action Input: 2006 ^ 0.43\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 26.30281917656938\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: 26.30281917656938\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'26.30281917656938'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"In what year was the film Departed with Leopnardo Dicaprio released? What is this year raised to the 0.43 power?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prqby8Wb9wlx"
      },
      "source": [
        "## <font color=\"red\">*Exercise 3*</font>\n",
        "\n",
        "<font color=\"red\">Review the documentation for tools and agents from LangChain . Utilize at least two tools with appropriate agents discovered during your review to construct a chain addressing questions pertinent to your final project. If your project dataset is unsuitable for this task, select an alternative small-sized dataset for implementation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "fN93RRCDs2Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"NEWS_API_KEY\"] = \"1c482189f3c14806963bd2ef975b4e9a\""
      ],
      "metadata": {
        "id": "nbV_tjqhCiKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo-instruct\")\n",
        "tools = load_tools([\"wikipedia\", \"news-api\"], news_api_key=\"1c482189f3c14806963bd2ef975b4e9a\", llm=llm)"
      ],
      "metadata": {
        "id": "9rNCh1Ylr8V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True, handle_parsing_errors=True)"
      ],
      "metadata": {
        "id": "zLqzcPL21eqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"What is the common feminist issue regarding '台女認為男生一定要主動' and '台女就是喜歡利用男人'? Any feminism theory is possibly related to this phenomenon? If you find out a specific theory, show me some news about that feminist theory, not limited to Taiwan but any kind of news related to the theory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "yUWtDAsD1haf",
        "outputId": "551dc662-cf9b-4dee-f1ea-d94995918044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m This is a complex question with multiple parts, so it may be helpful to break it down into smaller components.\n",
            "Action: Wikipedia\n",
            "Action Input: 'Feminism', 'Gender roles'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: Gender-critical feminism\n",
            "Summary: Gender-critical feminism, also known as trans-exclusionary radical feminism or TERFism, is an ideology or movement that opposes what it refers to as \"gender ideology\": the concept of gender identity and transgender rights, especially gender self-identification. Gender-critical feminists believe that sex is biological and immutable, while believing gender, including both gender identity and gender roles, to be inherently oppressive. They reject the concept of transgender identities. These views have been described as transphobic by feminist and scholarly critics, and are opposed by many feminist and LGBT rights organizations.Originating as a fringe movement within radical feminism mainly in the United States, gender-critical views have achieved a degree of prominence in the United Kingdom, where they have been at the centre of a number of high-profile controversies.  The Council of Europe has condemned gender-critical ideology, among other ideologies, and linked it to \"virulent attacks on the rights of LGBTI people\" in Hungary, Poland, Russia, Turkey, the United Kingdom, and other countries. It has been linked to promotion of disinformation and to the anti-gender movement. In some countries, gender-critical feminist groups have formed alliances with right-wing, far-right, and anti-feminist organisations.\n",
            "\n",
            "Page: Gender roles in Islam\n",
            "Summary: Gender roles in Islam are based on scriptures, cultural traditions, and jurisprudence.\n",
            "The Quran, the holy book of Islam, indicates that both men and women are spiritually equal.The Quran states:\n",
            "\n",
            "\"Those who do good, whether male or female, and have faith will enter Paradise and will never be wronged; even as much as the speck on a date stone.\"\n",
            "However, this notion of equality has not been reflected in several laws in Muslim-based institutions.The Quran does not specify gender roles for women, but Islamic practice does. This is partially because men and women are at times allotted different rights and cultural expectations. Hadith Sahih Bukhari (9:89:252) states that a man is expected to be the “guardian of [his] family,” whereas a woman is expected to be the “guardian of her husband's home and his children.”In some Muslim-based countries, women are legally restricted from practicing certain rights.\n",
            "\n",
            "Page: Gender role\n",
            "Summary: A gender role, or sex role, is a set of socially accepted behaviors and attitudes deemed appropriate or desirable for individuals based on their sex. Gender roles are usually centered on conceptions of masculinity and femininity, although there are exceptions and variations.\n",
            "The specifics regarding these gendered expectations may vary among cultures, while other characteristics may be common throughout a range of cultures. In addition, gender roles (and perceived gender roles) vary based on a person's race or ethnicity.Gender roles influence a wide range of human behavior, often including the clothing a person chooses to wear, the profession a person pursues, manner of approach to things,  the personal relationships a person enters, and how they behave within those relationships. Although gender roles have evolved and expanded, they traditionally keep women in the \"private\" sphere, and men in the \"public\" sphere.Various groups, most notably feminist movements, have led efforts to change aspects of prevailing gender roles that they believe are oppressive, inaccurate, and sexist.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m It seems that the idea of traditional gender roles is still prevalent in many cultures and religions, which can contribute to issues such as sexism and unequal treatment of genders.\n",
            "Action: News-API\n",
            "Action Input: 'Gender roles in feminism'\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m The response from the API did not include any relevant articles about gender roles in feminism.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Perhaps I can try a different search term.\n",
            "Action: News-API\n",
            "Action Input: 'Gender roles in Islam'\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m There are currently no top headlines from Egypt related to gender roles in Islam in the health category.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Perhaps I can try searching for articles in other categories.\n",
            "Action: News-API\n",
            "Action Input: 'Gender roles in Islam'\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m \n",
            "\n",
            "The response from the API shows that there are no top headlines related to the topic \"Gender roles in Islam\" in the general category.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m It seems that there is not a specific feminist theory that directly addresses the issue mentioned in the original question, but gender roles and feminism are certainly connected and have been widely debated and discussed in various forms of media.\n",
            "Thought: I now know the final answer.\n",
            "Final Answer: The issue mentioned in the original question regarding traditional gender roles can be attributed to a combination of societal expectations and cultural beliefs, rather than a specific feminist theory. However, gender roles and feminism are closely intertwined and have been extensively discussed and debated in various forms of media.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The issue mentioned in the original question regarding traditional gender roles can be attributed to a combination of societal expectations and cultural beliefs, rather than a specific feminist theory. However, gender roles and feminism are closely intertwined and have been extensively discussed and debated in various forms of media.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this question, first, I used the Wikipedia tool to query topics related to feminism, specifically gender roles. Through this tool, I gained relevant information about gender-critical feminism, gender roles in Islam, and gender roles in general. From this information, I learned that traditional gender roles are still prevalent in different cultures and religions and can have an impact on gender inequality and sexism.\n",
        "\n",
        "Next, I used the News-API tool to try to find relevant news about gender roles in feminism. However, I couldn't find a directly relevant article in the API's responses. Nonetheless, through this step I discovered that even in the news media, discussions about gender roles and feminism are not very focused or direct. This reminds me that although this issue may not have a direct feminist theoretical counterpart, the relationship between gender roles and feminism is still an issue worth exploring.\n",
        "\n",
        "Based on the above information, I came to the conclusion that the traditional gender role issues mentioned in the original question may have more to do with social expectations and cultural beliefs than specific feminist theories. However, there is a strong connection between gender roles and feminism and has been widely discussed and debated in various forms of media. Although dance discovery is not directly related to my final project, it can expand my research foundation."
      ],
      "metadata": {
        "id": "l24cOXwLrAUy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wMttXM-CuPK"
      },
      "source": [
        "## Memory\n",
        "\n",
        "We can use the history and system prompts to create a memory (of sorts) for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5Rk-GIXUwdB"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate, ChatPromptTemplate\n",
        "from langchain.llms import OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pavb7kYhPQnq"
      },
      "outputs": [],
      "source": [
        "# Initialize the language model\n",
        "def create_system_message_prompt():\n",
        "    \"\"\" Creates a system message prompt\"\"\"\n",
        "    personality_template = f\"\"\"\n",
        "    The following is a conversation with an AI assistant.\n",
        "    \"\"\"\n",
        "    return SystemMessagePromptTemplate.from_template(personality_template)\n",
        "\n",
        "def create_chat_prompt(human_history, ai_history):\n",
        "    \"\"\" Creates a chat prompt template with human history, and AI history. \"\"\"\n",
        "    messages = []\n",
        "    system_message_prompt = create_system_message_prompt()\n",
        "\n",
        "    for h, a in zip(human_history, ai_history):\n",
        "      messages.append(HumanMessagePromptTemplate.from_template(h))\n",
        "      messages.append(AIMessagePromptTemplate.from_template(a))\n",
        "\n",
        "    messages.append(HumanMessagePromptTemplate.from_template(\"{input}\"))\n",
        "    return ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "def query_chain(chain, input_text):\n",
        "    \"\"\" Queries the conversation chain with the given input. \"\"\"\n",
        "    return chain.run(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRIUPj5aUx35",
        "outputId": "ee9c35f5-aec1-4068-b831-7e9c1f6c852c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "AI: Noted, your favorite color is blue.\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "human_history = []\n",
        "ai_history = []\n",
        "\n",
        "chat_prompt = create_chat_prompt(human_history, ai_history)\n",
        "\n",
        "# Initialize the conversation chain\n",
        "chain = LLMChain(llm=llm_openai, prompt=chat_prompt)\n",
        "\n",
        "# Query the chain\n",
        "human_input =  \"Please take a note that my favorite color is blue.\"\n",
        "ai_response = query_chain(chain, human_input)\n",
        "print(ai_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKidm0CyOdJS",
        "outputId": "dc21e4d4-e33c-4087-ed9d-cfaab56b2912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AI: Of course, your favorite color is blue.\n"
          ]
        }
      ],
      "source": [
        "human_history.append(human_input)\n",
        "ai_history.append(ai_response)\n",
        "\n",
        "chat_prompt = create_chat_prompt(human_history, ai_history)\n",
        "\n",
        "# Initialize the conversation chain\n",
        "chain = LLMChain(llm=llm_openai, prompt=chat_prompt)\n",
        "\n",
        "# Query the chain\n",
        "human_input =  \"Could you please remind me what is my favorite color?\"\n",
        "ai_response = query_chain(chain, human_input)\n",
        "print(ai_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpd1gMPnnZnT"
      },
      "source": [
        "## Simulation and Conversations\n",
        "\n",
        "Above we showcased a toy LLM conversation between Human and AI with memories. We can go beyond the notion of conversation between AI and Human. We can make both participants AIs who think they are conversing with human! In other words, for example, we can make AI no.1 plays the role Trump and AI no.2 plays the role of Biden, and both of them think they're talking to the real Trump/Biden!\n",
        "\n",
        "Let's implement this idea by using questions from the 2020 predidential election debate as templates. Differnent from the hard coding way of implementing memory, below we use the ConversationBufferMemory class from langchain to implement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juu-QlSfsLxG"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7A6h7mkbyBv"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm_openai = OpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo-instruct\", max_tokens=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4t1qLnw_koX"
      },
      "outputs": [],
      "source": [
        "Trump_memory = ConversationBufferMemory(human_prefix='Trump', ai_prefix='Biden')\n",
        "Biden_memory = ConversationBufferMemory(human_prefix='Biden', ai_prefix='Trump')\n",
        "\n",
        "Trump_template = \"\"\"Imagine you're the Democrats presidential candidate Joe Biden. Today is Tuesday, September 29, 2020, and you're engaged in your first television presidential debate with Donald Trump. The deabte question is: Why is your position correct on selecting a Supreme Court nominee in an election year?\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Trump: {input}\n",
        "Biden:\"\"\"\n",
        "Biden_template = \"\"\"\"Imagine you're the Republican presidential candidate Donald Trump. Today is Tuesday, September 29, 2020, and you're engaged in your first television presidential debate with Joe Biden. The deabte question is: Why is your position correct on selecting a Supreme Court nominee in an election year?\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Biden: {input}\n",
        "Trump:\"\"\"\n",
        "\n",
        "# By default, models recognize themselves as AIs. So we need to let them do role play\n",
        "# and convince them that they're talking to real Trump/Biden (though they're not)\n",
        "\n",
        "TRUMP_PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=Trump_template)\n",
        "BIDEN_PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=Biden_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhvM6InzsL3r"
      },
      "outputs": [],
      "source": [
        "Trump_conversation = ConversationChain(\n",
        "    prompt=TRUMP_PROMPT,\n",
        "    llm=llm_openai,\n",
        "    verbose=False,\n",
        "    memory=Trump_memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQZ2xLvaJBKE"
      },
      "outputs": [],
      "source": [
        "# suppose Biden starts first\n",
        "biden_response = Trump_conversation.predict(input='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "1pXpwpSNa_Yk",
        "outputId": "d2f992c6-cac3-4fe2-f4cd-49e06c46be6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \"Thank you for the question. The issue of selecting a Supreme Court nominee during an election year is a complex one, but ultimately, I believe that it should be up to the American people to decide who sits on the highest court in the land. That\\'s why I strongly believe that we should wait until after the election to fill the vacancy left by Justice Ginsburg\\'s passing.\\n\\nFirst and foremost, the American people deserve a say in who is appointed to the Supreme Court. The presidential election is less than six weeks away, and millions of Americans have already started voting. It would be a disservice to them to rush through a Supreme Court nomination without giving them a chance to have their voices heard.\\n\\nFurthermore, the American people deserve a fair and impartial nomination process. In recent years, we have seen the nomination process become increasingly politicized, with partisan battles and nominees being rushed through without proper vetting. Waiting until after the election allows for a more thorough and thoughtful nomination process, ensuring that the nominee is truly qualified and capable of serving on the Supreme Court.\\n\\nBut perhaps most importantly, filling a Supreme Court seat during an election year goes against the precedent set by both parties. In 2016, when Justice Scalia passed away, the Republican-led Senate refused to even hold a hearing for President Obama\\'s nominee, stating that the American people should have a say in the selection during an election year. I believe the same logic should apply now. It would be hypocritical and unjust to do otherwise.\\n\\nI believe that the American people want a fair and just Supreme Court, not one that is heavily influenced by partisan politics. By waiting until after the election to fill the vacancy, we can honor the will of the people and ensure that the process is done in a fair and responsible manner. Thank you.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "biden_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kFjxUnDI1Fp"
      },
      "outputs": [],
      "source": [
        "Biden_conversation = ConversationChain(\n",
        "    prompt=BIDEN_PROMPT,\n",
        "    llm=llm_openai,\n",
        "    verbose=False,\n",
        "    memory=Biden_memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emFitHWQXl1T"
      },
      "outputs": [],
      "source": [
        "trump_response = Biden_conversation.predict(input=biden_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "e-9ZcknccNku",
        "outputId": "40e067e5-4401-489a-c5a3-1a800ed1e5e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \"Thank you for the question. Let\\'s be clear, as President, it is my duty to nominate a Supreme Court Justice when there is a vacancy, and I intend to fulfill that responsibility. The American people elected me to do just that, and I will not shirk my duty.\\n\\nNow, my opponent talks about precedent, but the precedent set in 2016 was that the President should not nominate a Supreme Court Justice in an election year, especially when the Senate and the White House are held by different parties. That is exactly the situation we have now. It is not about politics, it is about following the precedent set by the previous administration.\\n\\nAnd let\\'s not forget, the American people also elected a Republican Senate to confirm my judicial nominees. The Senate has a constitutional duty to act on my nominations, and they will do just that.\\n\\nFurthermore, waiting until after the election to nominate a Supreme Court Justice would also be a disservice to our country. We need a full Supreme Court to make important decisions that affect the American people. We cannot afford to have a vacancy on the Court for an extended period of time. The American people deserve a fully functioning Court, and I will make sure they get that.\\n\\nI understand that my opponent is trying to score political points, but I am focused on what is best for our country. It is not about waiting until after the election, it is about fulfilling my duty as President to nominate a qualified and capable Justice to serve on the Supreme Court. Thank you.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "trump_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot9bFycQcfC9"
      },
      "source": [
        "Well, seems that too nice to be Trump. Anyway, now we can make the debate run by feeding Trump agent's and Biden agent's response to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlITuIPVncVi"
      },
      "source": [
        "## Simularca\n",
        "\n",
        "One of the most influential generative LLM works in 2023 is the [Generative Agents: Interactive Simulacra of Human Behavior](https://dl.acm.org/doi/abs/10.1145/3586183.3606763) from Stanford. In this paper, the authors constructed a small town with 25 agents driven by ChatGPT:\n",
        "> Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents—computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architec- ture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behav- iors: for example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational, interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.\n",
        "\n",
        "<img src=\"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks-2024-Winter/blob/main/data/Simularca/1.png?raw=true\" alt=\"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks-2024-Winter/blob/main/data/Simularca/1.png?raw=true\" style=\"width:500px\">\n",
        "\n",
        "### Agent System\n",
        "\n",
        "In the paper, the agents have memory and can reflect. Agents can to remember, retrieve, reflect, interact with other agents, and plan through dynamically evolving circumstances.\n",
        "\n",
        "<img src=\"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks-2024-Winter/blob/main/data/Simularca/2.png?raw=true\" alt=\"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks-2024-Winter/blob/main/data/Simularca/2.png?raw=true\" style=\"width:500px\">\n",
        "\n",
        "They open-sourced the code on [GitHub](https://github.com/joonspk-research/generative_agents)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoBKxJNs_8Gh"
      },
      "source": [
        "### Memory and Information Retrieval\n",
        "\n",
        "Memory and Information Retrieval is the key to set up the whole town, along with ChatGPT, making agents differnent from those simple rule-based agents.\n",
        "\n",
        ">Approach: The memory stream maintains a comprehensive record of the agent’s experience. It is a list of memory objects, where each object contains a natural language description, a creation times- tamp and a most recent access timestamp. The most basic element of the memory stream is an observation, which is an event directly perceived by an agent. Common observations include behaviors performed by the agent themselves, or behaviors that agents per- ceive being performed by other agents or non-agent objects. For instance, Isabella Rodriguez, who works at a coffee shop, might ac- crue the following observations over time: (1) Isabella Rodriguez is setting out the pastries, (2) Maria Lopez is studying for a Chemistry test while drinking coffee, (3) Isabella Rodriguez and Maria Lopez are conversing about planning a Valentine’s day party at Hobbs Cafe, (4) The refrigerator is empty.\n",
        "\n",
        ">Our architecture implements a retrieval function that takes the agent’s current situation as input and returns a subset of the mem- ory stream to pass on to the language model. There are many pos- sible implementations of a retrieval function, depending on what it is important that the agent consider when deciding how to act. In our context, we focus on three main components that together produce effective results.\n",
        "\n",
        "> *Recency* assigns a higher score to memory objects that were re- cently accessed, so that events from a moment ago or this morning are likely to remain in the agent’s attentional sphere. In our im- plementation, we treat recency as an exponential decay function over the number of sandbox game hours since the memory was last retrieved. Our decay factor is 0.99.\n",
        "\n",
        "> *Importance* distinguishes mundane from core memories, by as- signing a higher score to those memory objects that the agent believes to be important. For instance, a mundane event such as eating breakfast in one’s room would yield a low importance score, whereas a breakup with one’s significant other would yield a high score. There are again many possible implementations of an im- portance score; we find that directly asking the language model to output an integer score is effective.\n",
        "\n",
        "> *Relevance* assigns a higher score to memory objects that are related to the current situation. What is relevant depends on the answer to, “Relevant to what?”, so we condition relevance on a query memory. If the query, for example, is that a student is dis- cussing what to study for a chemistry test with a classmate, memory objects about their breakfast should have low relevance, whereas memory objects about the teacher and schoolwork should have high relevance. In our implementation, we use the language model to generate an embedding vector of the text description of each memory. Then, we calculate relevance as the cosine similarity be- tween the memory’s embedding vector and the query memory’s embedding vector.\n",
        "\n",
        "> To calculate the final retrieval score, we normalize the recency, relevance, and importance scores to the range of [0, 1] by min-max scaling. The retrieval function scores all memories as a weighted combination of the three elements:$ score = \\alpha_{recency} * recency + \\alpha_{importance} * importance + \\alpha_{relevance} * relevance$ In our implementation, all $\\alpha$'s are set to 1. The top-ranked memories that fit in the language model’s context window are then included in the prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGIKO6j6ABH1"
      },
      "source": [
        "<img src=\"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks-2024-Winter/blob/main/data/Simularca/3.png?raw=true\" alt=\"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks-2024-Winter/blob/main/data/Simularca/3.png?raw=true\" style=\"width:500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nfNkMjnKeUk"
      },
      "source": [
        "To give you a sense of how the memory retrieval algorithm works, I will use Trump's tweets data to select several tweets that most pertinent to the presidential debate question to prompt the Trump agent respond to the Biden agent in a different way. In this case, we assume the Trump agent learns how Trump behaves on Twitter and this may help the Trump agent prepare for the presidential debate (Ideally, we should provide Trump's previous television debate and also provide similar materials for the Biden agent to learn. I don't have Biden's tweets at hand, you're welcome to create a tweet-based version Biden agent for the debate!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPI1xqTgu4T0"
      },
      "source": [
        "### Memory Retrieval Exmaple\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab\\ Notebooks/Computational\\ Content\\ Analysis/Homework-Notebooks-2024-Winter/week\\ 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si7TARe80XS5",
        "outputId": "0ab54fd8-cc49-4ad6-e3b8-f978ca727802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Computational Content Analysis/Homework-Notebooks-2024-Winter/week 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtjSPKGAhdpH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AroBz4dxu4T0"
      },
      "outputs": [],
      "source": [
        "dfs = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueMbqHgXu4T0"
      },
      "outputs": [],
      "source": [
        "for file in os.listdir(\"../data/trump_tweets\"):\n",
        "    dfs.append(pd.read_json(\"../data/trump_tweets/\" + file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjuFjnACu4T0"
      },
      "outputs": [],
      "source": [
        "df = pd.concat(dfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "N6tcRsdNu4T0",
        "outputId": "c41cb68e-6d83-4355-e886-7322c7f18fe3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    source              id_str  \\\n",
              "0      Twitter for Android  550441250965708800   \n",
              "1      Twitter for Android  550441111513493504   \n",
              "2      Twitter for Android  550440752254562304   \n",
              "3      Twitter for Android  550440620792492032   \n",
              "4      Twitter for Android  550440523094577152   \n",
              "...                    ...                 ...   \n",
              "23655   Twitter for iPhone  950946293077209088   \n",
              "23656   Twitter for iPhone  950937350003183616   \n",
              "23657   Twitter for iPhone  950884128379035648   \n",
              "23658   Twitter for iPhone  950879772644659200   \n",
              "23659   Twitter for iPhone  950866561153331200   \n",
              "\n",
              "                                                    text  \\\n",
              "0      \"@ronmeier123: @Macys Your APPAREL is UNPARALL...   \n",
              "1      \"@gillule4: @realDonaldTrump incredible experi...   \n",
              "2      \"@JobSnarechs: Negotiation tip #1: The worst t...   \n",
              "3      \"@joelmch2os: @realDonaldTrump announce your p...   \n",
              "4      \"@djspookyshadow: Feeling a deep gratitude for...   \n",
              "...                                                  ...   \n",
              "23655  .@ICEgov HSI agents and ERO officers, on behal...   \n",
              "23656  Thank you @GOPLeader Kevin McCarthy! Couldn’t ...   \n",
              "23657  As I made very clear today, our country needs ...   \n",
              "23658  RT @Scavino45: “Utilities cutting rates, cite ...   \n",
              "23659  Today, it was my great honor to sign a new Exe...   \n",
              "\n",
              "                     created_at  retweet_count  in_reply_to_user_id_str  \\\n",
              "0     2014-12-31 23:59:55+00:00              8                      NaN   \n",
              "1     2014-12-31 23:59:22+00:00              5                      NaN   \n",
              "2     2014-12-31 23:57:56+00:00             33                      NaN   \n",
              "3     2014-12-31 23:57:25+00:00              8                      NaN   \n",
              "4     2014-12-31 23:57:02+00:00              9                      NaN   \n",
              "...                         ...            ...                      ...   \n",
              "23655 2018-01-10 04:23:58+00:00          13822                      NaN   \n",
              "23656 2018-01-10 03:48:26+00:00          11893                      NaN   \n",
              "23657 2018-01-10 00:16:57+00:00          24552                      NaN   \n",
              "23658 2018-01-09 23:59:38+00:00          11716                      NaN   \n",
              "23659 2018-01-09 23:07:09+00:00          19481                      NaN   \n",
              "\n",
              "       favorite_count  is_retweet  \n",
              "0                  21       False  \n",
              "1                  18       False  \n",
              "2                  44       False  \n",
              "3                  26       False  \n",
              "4                  31       False  \n",
              "...               ...         ...  \n",
              "23655           60252       False  \n",
              "23656           51951       False  \n",
              "23657          123413       False  \n",
              "23658               0        True  \n",
              "23659           82151       False  \n",
              "\n",
              "[23660 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb3178fe-70ab-44ff-82f0-b120bc652e58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>id_str</th>\n",
              "      <th>text</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>in_reply_to_user_id_str</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>550441250965708800</td>\n",
              "      <td>\"@ronmeier123: @Macys Your APPAREL is UNPARALL...</td>\n",
              "      <td>2014-12-31 23:59:55+00:00</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>550441111513493504</td>\n",
              "      <td>\"@gillule4: @realDonaldTrump incredible experi...</td>\n",
              "      <td>2014-12-31 23:59:22+00:00</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>550440752254562304</td>\n",
              "      <td>\"@JobSnarechs: Negotiation tip #1: The worst t...</td>\n",
              "      <td>2014-12-31 23:57:56+00:00</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>550440620792492032</td>\n",
              "      <td>\"@joelmch2os: @realDonaldTrump announce your p...</td>\n",
              "      <td>2014-12-31 23:57:25+00:00</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>550440523094577152</td>\n",
              "      <td>\"@djspookyshadow: Feeling a deep gratitude for...</td>\n",
              "      <td>2014-12-31 23:57:02+00:00</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23655</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>950946293077209088</td>\n",
              "      <td>.@ICEgov HSI agents and ERO officers, on behal...</td>\n",
              "      <td>2018-01-10 04:23:58+00:00</td>\n",
              "      <td>13822</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60252</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23656</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>950937350003183616</td>\n",
              "      <td>Thank you @GOPLeader Kevin McCarthy! Couldn’t ...</td>\n",
              "      <td>2018-01-10 03:48:26+00:00</td>\n",
              "      <td>11893</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51951</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23657</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>950884128379035648</td>\n",
              "      <td>As I made very clear today, our country needs ...</td>\n",
              "      <td>2018-01-10 00:16:57+00:00</td>\n",
              "      <td>24552</td>\n",
              "      <td>NaN</td>\n",
              "      <td>123413</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23658</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>950879772644659200</td>\n",
              "      <td>RT @Scavino45: “Utilities cutting rates, cite ...</td>\n",
              "      <td>2018-01-09 23:59:38+00:00</td>\n",
              "      <td>11716</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23659</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>950866561153331200</td>\n",
              "      <td>Today, it was my great honor to sign a new Exe...</td>\n",
              "      <td>2018-01-09 23:07:09+00:00</td>\n",
              "      <td>19481</td>\n",
              "      <td>NaN</td>\n",
              "      <td>82151</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23660 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb3178fe-70ab-44ff-82f0-b120bc652e58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb3178fe-70ab-44ff-82f0-b120bc652e58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb3178fe-70ab-44ff-82f0-b120bc652e58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc861810-ba92-487d-b9b2-b0c3e439acdc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc861810-ba92-487d-b9b2-b0c3e439acdc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc861810-ba92-487d-b9b2-b0c3e439acdc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2a983216-ce1c-4821-ba40-dfd580d68069\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2a983216-ce1c-4821-ba40-dfd580d68069 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 23660,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"Twitter for Android\",\n          \"Twitter Web Client\",\n          \"Periscope\"\n        ],\n        \"num_unique_values\": 18,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_str\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 184793163017284384,\n        \"min\": 418365112844824576,\n        \"max\": 1079888205351145472,\n        \"samples\": [\n          888708453560184832,\n          622621762023518208,\n          507163439366934528\n        ],\n        \"num_unique_values\": 23660,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"Does anyone notice how the Montana Congressional race was such a big deal to Dems &amp; Fake News until the Republican won? V was poorly covered\",\n          \"\\\"@ryan5240 after playing the new course in Aberdeen and loved it my wife taking me to Turnberry for a birthday present on Monday\\\" Great!\",\n          \"\\\"@JonathanAFrye: Passion is the start; confidence, vision &amp; focus are the steps, &amp; resilience is the last mile to entrepreneurial success.\\\"\"\n        ],\n        \"num_unique_values\": 23562,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2014-01-01 12:56:30+00:00\",\n        \"max\": \"2018-12-31 23:53:06+00:00\",\n        \"samples\": [\n          \"2018-09-03 11:05:37+00:00\",\n          \"2015-02-23 20:29:40+00:00\",\n          \"2016-10-06 01:53:05+00:00\"\n        ],\n        \"num_unique_values\": 23632,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweet_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10960,\n        \"min\": 0,\n        \"max\": 369530,\n        \"samples\": [\n          10345,\n          31318,\n          226\n        ],\n        \"num_unique_values\": 10340,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"in_reply_to_user_id_str\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 528705872.62160987,\n        \"min\": 759251.0,\n        \"max\": 3412873425.0,\n        \"samples\": [\n          633797941.0,\n          56411751.0,\n          23970102.0\n        ],\n        \"num_unique_values\": 90,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"favorite_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40767,\n        \"min\": 0,\n        \"max\": 633253,\n        \"samples\": [\n          1404,\n          133250,\n          124746\n        ],\n        \"num_unique_values\": 11909,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_retweet\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"samples\": [\n          true,\n          false\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "df.reset_index(drop=True, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OwrXW9diHDT"
      },
      "source": [
        "Trump used to live on Twitter lol.\n",
        "\n",
        "Here, we borrow the idea of the information retrieval algorithm. We define the cosine similarity of the tweet's vector representation to the target post's vector representation as relevance, the normalized score (popularity) as importance, and normalized days apart from the debate day as recency. Then, we pick top 5 comments for the Trump agent to learn.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3Nha6jPiDlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d5ebac-3324-46b0-d5ec-376f13198eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/132.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/132.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/132.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSDvxjQil5_a"
      },
      "outputs": [],
      "source": [
        "# relevance\n",
        "embedding_model_name = 'all-MiniLM-L6-v2'\n",
        "model = SentenceTransformer(embedding_model_name, device='cuda')\n",
        "embeddings = model.encode(df['text'].astype(str))\n",
        "target_question = 'Why is your position correct on selecting a Supreme Court nominee in an election year?'\n",
        "similarity = cosine_similarity(embeddings, model.encode([target_question]))\n",
        "df['cosine_similarity'] = similarity\n",
        "df['relevance'] = (df['cosine_similarity'] - df['cosine_similarity'].min()) / (df['cosine_similarity'].max() - df['cosine_similarity'].min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQdddSTwmWFo"
      },
      "outputs": [],
      "source": [
        "# recency\n",
        "dates = df['created_at'].dt.date\n",
        "target_date = '2020-09-29'\n",
        "df['days_diff'] = (pd.to_datetime(target_date) - pd.to_datetime(dates)).dt.days\n",
        "df['days_diff'] = 0.99 ** df['days_diff']\n",
        "df['recency'] = (df['days_diff'] - df['days_diff'].min()) / (df['days_diff'].max() - df['days_diff'].min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YRjCNsImiNi"
      },
      "outputs": [],
      "source": [
        "# importance\n",
        "scores = df['favorite_count']\n",
        "df['importance'] = (scores - scores.min()) / (scores.max() - scores.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "LgYcmPkdzIBt",
        "outputId": "fdda9724-53b3-4a28-9aca-58b88631a9ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    source              id_str  \\\n",
              "0      Twitter for Android  550441250965708800   \n",
              "1      Twitter for Android  550441111513493504   \n",
              "2      Twitter for Android  550440752254562304   \n",
              "3      Twitter for Android  550440620792492032   \n",
              "4      Twitter for Android  550440523094577152   \n",
              "...                    ...                 ...   \n",
              "23655   Twitter for iPhone  950946293077209088   \n",
              "23656   Twitter for iPhone  950937350003183616   \n",
              "23657   Twitter for iPhone  950884128379035648   \n",
              "23658   Twitter for iPhone  950879772644659200   \n",
              "23659   Twitter for iPhone  950866561153331200   \n",
              "\n",
              "                                                    text  \\\n",
              "0      \"@ronmeier123: @Macys Your APPAREL is UNPARALL...   \n",
              "1      \"@gillule4: @realDonaldTrump incredible experi...   \n",
              "2      \"@JobSnarechs: Negotiation tip #1: The worst t...   \n",
              "3      \"@joelmch2os: @realDonaldTrump announce your p...   \n",
              "4      \"@djspookyshadow: Feeling a deep gratitude for...   \n",
              "...                                                  ...   \n",
              "23655  .@ICEgov HSI agents and ERO officers, on behal...   \n",
              "23656  Thank you @GOPLeader Kevin McCarthy! Couldn’t ...   \n",
              "23657  As I made very clear today, our country needs ...   \n",
              "23658  RT @Scavino45: “Utilities cutting rates, cite ...   \n",
              "23659  Today, it was my great honor to sign a new Exe...   \n",
              "\n",
              "                     created_at  retweet_count  in_reply_to_user_id_str  \\\n",
              "0     2014-12-31 23:59:55+00:00              8                      NaN   \n",
              "1     2014-12-31 23:59:22+00:00              5                      NaN   \n",
              "2     2014-12-31 23:57:56+00:00             33                      NaN   \n",
              "3     2014-12-31 23:57:25+00:00              8                      NaN   \n",
              "4     2014-12-31 23:57:02+00:00              9                      NaN   \n",
              "...                         ...            ...                      ...   \n",
              "23655 2018-01-10 04:23:58+00:00          13822                      NaN   \n",
              "23656 2018-01-10 03:48:26+00:00          11893                      NaN   \n",
              "23657 2018-01-10 00:16:57+00:00          24552                      NaN   \n",
              "23658 2018-01-09 23:59:38+00:00          11716                      NaN   \n",
              "23659 2018-01-09 23:07:09+00:00          19481                      NaN   \n",
              "\n",
              "       favorite_count  is_retweet  cosine_similarity  relevance     days_diff  \\\n",
              "0                  21       False           0.154324   0.463599  6.890861e-10   \n",
              "1                  18       False           0.106285   0.403678  6.890861e-10   \n",
              "2                  44       False           0.100925   0.396992  6.890861e-10   \n",
              "3                  26       False           0.133932   0.438164  6.890861e-10   \n",
              "4                  31       False           0.013051   0.287382  6.890861e-10   \n",
              "...               ...         ...                ...        ...           ...   \n",
              "23655           60252       False           0.084336   0.376299  4.631783e-05   \n",
              "23656           51951       False           0.011486   0.285431  4.631783e-05   \n",
              "23657          123413       False           0.079299   0.370017  4.631783e-05   \n",
              "23658               0        True           0.079789   0.370628  4.585465e-05   \n",
              "23659           82151       False           0.062218   0.348710  4.585465e-05   \n",
              "\n",
              "            recency  importance  \n",
              "0      4.089576e-07    0.000033  \n",
              "1      4.089576e-07    0.000028  \n",
              "2      4.089576e-07    0.000069  \n",
              "3      4.089576e-07    0.000041  \n",
              "4      4.089576e-07    0.000049  \n",
              "...             ...         ...  \n",
              "23655  2.821590e-02    0.095147  \n",
              "23656  2.821590e-02    0.082038  \n",
              "23657  2.821590e-02    0.194887  \n",
              "23658  2.793374e-02    0.000000  \n",
              "23659  2.793374e-02    0.129729  \n",
              "\n",
              "[23660 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86d21192-e526-4f62-9e60-da3d8a7a080b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>id_str</th>\n",
              "      <th>text</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>in_reply_to_user_id_str</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>relevance</th>\n",
              "      <th>days_diff</th>\n",
              "      <th>recency</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>550441250965708800</td>\n",
              "      <td>\"@ronmeier123: @Macys Your APPAREL is UNPARALL...</td>\n",
              "      <td>2014-12-31 23:59:55+00:00</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21</td>\n",
              "      <td>False</td>\n",
              "      <td>0.154324</td>\n",
              "      <td>0.463599</td>\n",
              "      <td>6.890861e-10</td>\n",
              "      <td>4.089576e-07</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>550441111513493504</td>\n",
              "      <td>\"@gillule4: @realDonaldTrump incredible experi...</td>\n",
              "      <td>2014-12-31 23:59:22+00:00</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18</td>\n",
              "      <td>False</td>\n",
              "      <td>0.106285</td>\n",
              "      <td>0.403678</td>\n",
              "      <td>6.890861e-10</td>\n",
              "      <td>4.089576e-07</td>\n",
              "      <td>0.000028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>550440752254562304</td>\n",
              "      <td>\"@JobSnarechs: Negotiation tip #1: The worst t...</td>\n",
              "      <td>2014-12-31 23:57:56+00:00</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44</td>\n",
              "      <td>False</td>\n",
              "      <td>0.100925</td>\n",
              "      <td>0.396992</td>\n",
              "      <td>6.890861e-10</td>\n",
              "      <td>4.089576e-07</td>\n",
              "      <td>0.000069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>550440620792492032</td>\n",
              "      <td>\"@joelmch2os: @realDonaldTrump announce your p...</td>\n",
              "      <td>2014-12-31 23:57:25+00:00</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26</td>\n",
              "      <td>False</td>\n",
              "      <td>0.133932</td>\n",
              "      <td>0.438164</td>\n",
              "      <td>6.890861e-10</td>\n",
              "      <td>4.089576e-07</td>\n",
              "      <td>0.000041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>550440523094577152</td>\n",
              "      <td>\"@djspookyshadow: Feeling a deep gratitude for...</td>\n",
              "      <td>2014-12-31 23:57:02+00:00</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31</td>\n",
              "      <td>False</td>\n",
              "      <td>0.013051</td>\n",
              "      <td>0.287382</td>\n",
              "      <td>6.890861e-10</td>\n",
              "      <td>4.089576e-07</td>\n",
              "      <td>0.000049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23655</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>950946293077209088</td>\n",
              "      <td>.@ICEgov HSI agents and ERO officers, on behal...</td>\n",
              "      <td>2018-01-10 04:23:58+00:00</td>\n",
              "      <td>13822</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60252</td>\n",
              "      <td>False</td>\n",
              "      <td>0.084336</td>\n",
              "      <td>0.376299</td>\n",
              "      <td>4.631783e-05</td>\n",
              "      <td>2.821590e-02</td>\n",
              "      <td>0.095147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23656</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>950937350003183616</td>\n",
              "      <td>Thank you @GOPLeader Kevin McCarthy! Couldn’t ...</td>\n",
              "      <td>2018-01-10 03:48:26+00:00</td>\n",
              "      <td>11893</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51951</td>\n",
              "      <td>False</td>\n",
              "      <td>0.011486</td>\n",
              "      <td>0.285431</td>\n",
              "      <td>4.631783e-05</td>\n",
              "      <td>2.821590e-02</td>\n",
              "      <td>0.082038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23657</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>950884128379035648</td>\n",
              "      <td>As I made very clear today, our country needs ...</td>\n",
              "      <td>2018-01-10 00:16:57+00:00</td>\n",
              "      <td>24552</td>\n",
              "      <td>NaN</td>\n",
              "      <td>123413</td>\n",
              "      <td>False</td>\n",
              "      <td>0.079299</td>\n",
              "      <td>0.370017</td>\n",
              "      <td>4.631783e-05</td>\n",
              "      <td>2.821590e-02</td>\n",
              "      <td>0.194887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23658</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>950879772644659200</td>\n",
              "      <td>RT @Scavino45: “Utilities cutting rates, cite ...</td>\n",
              "      <td>2018-01-09 23:59:38+00:00</td>\n",
              "      <td>11716</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.079789</td>\n",
              "      <td>0.370628</td>\n",
              "      <td>4.585465e-05</td>\n",
              "      <td>2.793374e-02</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23659</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>950866561153331200</td>\n",
              "      <td>Today, it was my great honor to sign a new Exe...</td>\n",
              "      <td>2018-01-09 23:07:09+00:00</td>\n",
              "      <td>19481</td>\n",
              "      <td>NaN</td>\n",
              "      <td>82151</td>\n",
              "      <td>False</td>\n",
              "      <td>0.062218</td>\n",
              "      <td>0.348710</td>\n",
              "      <td>4.585465e-05</td>\n",
              "      <td>2.793374e-02</td>\n",
              "      <td>0.129729</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23660 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86d21192-e526-4f62-9e60-da3d8a7a080b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-86d21192-e526-4f62-9e60-da3d8a7a080b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-86d21192-e526-4f62-9e60-da3d8a7a080b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-da5054d5-10cd-42de-9417-189fad7d38f5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da5054d5-10cd-42de-9417-189fad7d38f5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-da5054d5-10cd-42de-9417-189fad7d38f5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a09336ca-5c25-46e2-9f75-b19e8fbe2819\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a09336ca-5c25-46e2-9f75-b19e8fbe2819 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 23660,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"Twitter for Android\",\n          \"Twitter Web Client\",\n          \"Periscope\"\n        ],\n        \"num_unique_values\": 18,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_str\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 184793163017284384,\n        \"min\": 418365112844824576,\n        \"max\": 1079888205351145472,\n        \"samples\": [\n          888708453560184832,\n          622621762023518208,\n          507163439366934528\n        ],\n        \"num_unique_values\": 23660,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"Does anyone notice how the Montana Congressional race was such a big deal to Dems &amp; Fake News until the Republican won? V was poorly covered\",\n          \"\\\"@ryan5240 after playing the new course in Aberdeen and loved it my wife taking me to Turnberry for a birthday present on Monday\\\" Great!\",\n          \"\\\"@JonathanAFrye: Passion is the start; confidence, vision &amp; focus are the steps, &amp; resilience is the last mile to entrepreneurial success.\\\"\"\n        ],\n        \"num_unique_values\": 23562,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2014-01-01 12:56:30+00:00\",\n        \"max\": \"2018-12-31 23:53:06+00:00\",\n        \"samples\": [\n          \"2018-09-03 11:05:37+00:00\",\n          \"2015-02-23 20:29:40+00:00\",\n          \"2016-10-06 01:53:05+00:00\"\n        ],\n        \"num_unique_values\": 23632,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweet_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10960,\n        \"min\": 0,\n        \"max\": 369530,\n        \"samples\": [\n          10345,\n          31318,\n          226\n        ],\n        \"num_unique_values\": 10340,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"in_reply_to_user_id_str\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 528705872.62160987,\n        \"min\": 759251.0,\n        \"max\": 3412873425.0,\n        \"samples\": [\n          633797941.0,\n          56411751.0,\n          23970102.0\n        ],\n        \"num_unique_values\": 90,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"favorite_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40767,\n        \"min\": 0,\n        \"max\": 633253,\n        \"samples\": [\n          1404,\n          133250,\n          124746\n        ],\n        \"num_unique_values\": 11909,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_retweet\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"samples\": [\n          true,\n          false\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cosine_similarity\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          0.02025945857167244,\n          0.176217183470726\n        ],\n        \"num_unique_values\": 23556,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          0.5689869523048401,\n          0.527502179145813\n        ],\n        \"num_unique_values\": 23531,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"days_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00023472484932599312,\n        \"min\": 1.776169032077608e-11,\n        \"max\": 0.0016415501428270432,\n        \"samples\": [\n          0.00031581013785891707,\n          1.0700541909259004e-07\n        ],\n        \"num_unique_values\": 1789,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1429897544655533,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"samples\": [\n          0.19238530415551813,\n          6.517477338561921e-05\n        ],\n        \"num_unique_values\": 1789,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06437791653941481,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"samples\": [\n          0.0022171233298539446,\n          0.21042142713891604\n        ],\n        \"num_unique_values\": 11909,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuzvOKSvm-sS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "c659d9a0-b49a-4532-df83-327d43c23d6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   source               id_str  \\\n",
              "20193  Twitter for iPhone  1077549301449060352   \n",
              "21175  Twitter for iPhone  1045444544068812800   \n",
              "20152  Twitter for iPhone  1079830267274108928   \n",
              "20162  Twitter for iPhone  1079497288605683712   \n",
              "20223  Twitter for iPhone  1076655729820471296   \n",
              "\n",
              "                                                    text  \\\n",
              "20193                                   Merry Christmas!   \n",
              "21175  Judge Kavanaugh showed America exactly why I n...   \n",
              "20152  Heads of countries are calling wanting to know...   \n",
              "20162  President and Mrs. Obama built/has a ten foot ...   \n",
              "20223  Brett McGurk, who I do not know, was appointed...   \n",
              "\n",
              "                     created_at  retweet_count  in_reply_to_user_id_str  \\\n",
              "20193 2018-12-25 12:59:08+00:00          89255                      NaN   \n",
              "21175 2018-09-27 22:46:17+00:00          84180                      NaN   \n",
              "20152 2018-12-31 20:02:52+00:00          21030                      NaN   \n",
              "20162 2018-12-30 21:59:44+00:00          61837                      NaN   \n",
              "20223 2018-12-23 01:48:23+00:00          19476                      NaN   \n",
              "\n",
              "       favorite_count  is_retweet  cosine_similarity  relevance  days_diff  \\\n",
              "20193          508372       False          -0.025833   0.238880   0.001545   \n",
              "21175          320104       False           0.509458   0.906575   0.000632   \n",
              "20152           76721       False           0.292551   0.636017   0.001642   \n",
              "20162          233722       False           0.097907   0.393227   0.001625   \n",
              "20223           86619       False           0.334501   0.688343   0.001515   \n",
              "\n",
              "        recency  importance     score  \n",
              "20193  0.941480    0.802794  1.983155  \n",
              "21175  0.384896    0.505491  1.796962  \n",
              "20152  1.000000    0.121154  1.757171  \n",
              "20162  0.990000    0.369082  1.752309  \n",
              "20223  0.922745    0.136784  1.747871  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-525fbefd-fb8d-4b80-abba-d30aea819e27\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>id_str</th>\n",
              "      <th>text</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>in_reply_to_user_id_str</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>relevance</th>\n",
              "      <th>days_diff</th>\n",
              "      <th>recency</th>\n",
              "      <th>importance</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20193</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>1077549301449060352</td>\n",
              "      <td>Merry Christmas!</td>\n",
              "      <td>2018-12-25 12:59:08+00:00</td>\n",
              "      <td>89255</td>\n",
              "      <td>NaN</td>\n",
              "      <td>508372</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.025833</td>\n",
              "      <td>0.238880</td>\n",
              "      <td>0.001545</td>\n",
              "      <td>0.941480</td>\n",
              "      <td>0.802794</td>\n",
              "      <td>1.983155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21175</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>1045444544068812800</td>\n",
              "      <td>Judge Kavanaugh showed America exactly why I n...</td>\n",
              "      <td>2018-09-27 22:46:17+00:00</td>\n",
              "      <td>84180</td>\n",
              "      <td>NaN</td>\n",
              "      <td>320104</td>\n",
              "      <td>False</td>\n",
              "      <td>0.509458</td>\n",
              "      <td>0.906575</td>\n",
              "      <td>0.000632</td>\n",
              "      <td>0.384896</td>\n",
              "      <td>0.505491</td>\n",
              "      <td>1.796962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20152</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>1079830267274108928</td>\n",
              "      <td>Heads of countries are calling wanting to know...</td>\n",
              "      <td>2018-12-31 20:02:52+00:00</td>\n",
              "      <td>21030</td>\n",
              "      <td>NaN</td>\n",
              "      <td>76721</td>\n",
              "      <td>False</td>\n",
              "      <td>0.292551</td>\n",
              "      <td>0.636017</td>\n",
              "      <td>0.001642</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.121154</td>\n",
              "      <td>1.757171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20162</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>1079497288605683712</td>\n",
              "      <td>President and Mrs. Obama built/has a ten foot ...</td>\n",
              "      <td>2018-12-30 21:59:44+00:00</td>\n",
              "      <td>61837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>233722</td>\n",
              "      <td>False</td>\n",
              "      <td>0.097907</td>\n",
              "      <td>0.393227</td>\n",
              "      <td>0.001625</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.369082</td>\n",
              "      <td>1.752309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20223</th>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>1076655729820471296</td>\n",
              "      <td>Brett McGurk, who I do not know, was appointed...</td>\n",
              "      <td>2018-12-23 01:48:23+00:00</td>\n",
              "      <td>19476</td>\n",
              "      <td>NaN</td>\n",
              "      <td>86619</td>\n",
              "      <td>False</td>\n",
              "      <td>0.334501</td>\n",
              "      <td>0.688343</td>\n",
              "      <td>0.001515</td>\n",
              "      <td>0.922745</td>\n",
              "      <td>0.136784</td>\n",
              "      <td>1.747871</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-525fbefd-fb8d-4b80-abba-d30aea819e27')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-525fbefd-fb8d-4b80-abba-d30aea819e27 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-525fbefd-fb8d-4b80-abba-d30aea819e27');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d6d12b67-6ba5-498c-b092-04995c9d38bf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6d12b67-6ba5-498c-b092-04995c9d38bf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d6d12b67-6ba5-498c-b092-04995c9d38bf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 23660,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"Twitter for iPhone\",\n          \"Twitter Media Studio\",\n          \"Instagram\"\n        ],\n        \"num_unique_values\": 18,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_str\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 184793163017284384,\n        \"min\": 418365112844824576,\n        \"max\": 1079888205351145472,\n        \"samples\": [\n          739934090690998272,\n          758236300554174464,\n          1029908960265027584\n        ],\n        \"num_unique_values\": 23660,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"Packed venue of people who want to #MakeAmericaGreatAgain https://t.co/wisZRVAmPR\",\n          \"August job openings hit a record 7.14 million. Congratulations USA!\",\n          \"\\\"@jackievandyck: @realDonaldTrump I get to vote for the president for the first time in 2016. I hope you're on the ballot\\\"\"\n        ],\n        \"num_unique_values\": 23562,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2014-01-01 12:56:30+00:00\",\n        \"max\": \"2018-12-31 23:53:06+00:00\",\n        \"samples\": [\n          \"2014-01-06 21:42:43+00:00\",\n          \"2016-03-19 15:40:55+00:00\",\n          \"2016-02-23 05:19:29+00:00\"\n        ],\n        \"num_unique_values\": 23632,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweet_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10960,\n        \"min\": 0,\n        \"max\": 369530,\n        \"samples\": [\n          11231,\n          1426,\n          11577\n        ],\n        \"num_unique_values\": 10340,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"in_reply_to_user_id_str\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 528705872.62160987,\n        \"min\": 759251.0,\n        \"max\": 3412873425.0,\n        \"samples\": [\n          357606935.0,\n          3412873425.0,\n          897350694.0\n        ],\n        \"num_unique_values\": 90,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"favorite_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40767,\n        \"min\": 0,\n        \"max\": 633253,\n        \"samples\": [\n          60786,\n          4730,\n          9441\n        ],\n        \"num_unique_values\": 11909,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_retweet\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"samples\": [\n          true,\n          false\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cosine_similarity\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          -0.02946225181221962,\n          0.12436496466398239\n        ],\n        \"num_unique_values\": 23556,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          0.3003414571285248,\n          0.4468393623828888\n        ],\n        \"num_unique_values\": 23531,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"days_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00023472484932599312,\n        \"min\": 1.776169032077608e-11,\n        \"max\": 0.0016415501428270432,\n        \"samples\": [\n          4.2581638022099654e-11,\n          1.321498534163712e-07\n        ],\n        \"num_unique_values\": 1789,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1429897544655533,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"samples\": [\n          1.511982322217267e-08,\n          8.049226746627064e-05\n        ],\n        \"num_unique_values\": 1789,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06437791653941481,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"samples\": [\n          0.09599007031944579,\n          0.007469368483054956\n        ],\n        \"num_unique_values\": 11909,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20476041542898807,\n        \"min\": 0.0013356809063603486,\n        \"max\": 1.9831550341777273,\n        \"samples\": [\n          0.28642171399412325,\n          0.7166079397045703\n        ],\n        \"num_unique_values\": 23657,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# select top 5\n",
        "df['score'] = df['relevance'] + df['recency'] + df['importance']\n",
        "df = df.sort_values(by='score', ascending=False)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsFEL0eczIBt"
      },
      "source": [
        "Let's put the top 5 twwets into the prompt (Biden) and re-run the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3ankzgBhzIBt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7dac515a-ca59-4658-bf8b-ceca27e11132"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt7RzfPEzIBt"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm_openai = OpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo-instruct\", max_tokens=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cciqx5UbzIBt",
        "outputId": "fbcb99f2-7adb-4c87-fb84-f57e3fd4a9f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Merry Christmas!',\n",
              " 'Judge Kavanaugh showed America exactly why I nominated him. His testimony was powerful, honest, and riveting. Democrats’ search and destroy strategy is disgraceful and this process has been a total sham and effort to delay, obstruct, and resist. The Senate must vote!',\n",
              " 'Heads of countries are calling wanting to know why Senator Schumer is not approving their otherwise approved Ambassadors!? Likewise in Government lawyers and others are being delayed at a record pace! 360 great and hardworking people are waiting for approval from....',\n",
              " 'President and Mrs. Obama built/has a ten foot Wall around their D.C. mansion/compound. I agree, totally necessary for their safety and security. The U.S. needs the same thing, slightly larger version!',\n",
              " 'Brett McGurk, who I do not know, was appointed by President Obama in 2015. Was supposed to leave in February but he just resigned prior to leaving. Grandstander? The Fake News is making such a big deal about this nothing event!']"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "df.head(5)['text'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZHDjsdxzIBt"
      },
      "source": [
        "Great, we saw Judge Kavanaugh appeared and topics like border walls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFrIHTXpzIBt"
      },
      "outputs": [],
      "source": [
        "Trump_memory = ConversationBufferMemory(human_prefix='Trump', ai_prefix='Biden')\n",
        "Biden_memory = ConversationBufferMemory(human_prefix='Biden', ai_prefix='Trump')\n",
        "\n",
        "Trump_template = \"\"\"Imagine you're the Democrats presidential candidate Joe Biden. Today is Tuesday, September 29, 2020, and you're engaged in your first television presidential debate with Donald Trump. The deabte question is: Why is your position correct on selecting a Supreme Court nominee in an election year?\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Trump: {input}\n",
        "Biden:\"\"\"\n",
        "\n",
        "tweets = df.head(5)['text'].tolist()\n",
        "Biden_template = \"\"\"\"Imagine you're the Republican presidential candidate Donald Trump. To give you a better sense of how Trump may give public comments, here're some of his tweets:\n",
        "    1. Merry Christmas!\n",
        "    2. Judge Kavanaugh showed America exactly why I nominated him. His testimony was powerful, honest, and riveting. Democrats’ search and destroy strategy is disgraceful and this process has been a total sham and effort to delay, obstruct, and resist. The Senate must vote!\n",
        "    3. Heads of countries are calling wanting to know why Senator Schumer is not approving their otherwise approved Ambassadors!? Likewise in Government lawyers and others are being delayed at a record pace! 360 great and hardworking people are waiting for approval from....\n",
        "    4. President and Mrs. Obama built/has a ten foot Wall around their D.C. mansion/compound. I agree, totally necessary for their safety and security. The U.S. needs the same thing, slightly larger version!\n",
        "    5. Brett McGurk, who I do not know, was appointed by President Obama in 2015. Was supposed to leave in February but he just resigned prior to leaving. Grandstander? The Fake News is making such a big deal about this nothing event!\n",
        "Today is Tuesday, September 29, 2020, and you're engaged in your first television presidential debate with Joe Biden. The deabte question is: Why is your position correct on selecting a Supreme Court nominee in an election year?\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Biden: {input}\n",
        "Trump:\"\"\"\n",
        "\n",
        "# By default, models recognize themselves as AIs. So we need to let them do role play\n",
        "# and convince them that they're talking to real Trump/Biden (though they're not)\n",
        "\n",
        "TRUMP_PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=Trump_template)\n",
        "BIDEN_PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=Biden_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzDEECwUzIBt"
      },
      "outputs": [],
      "source": [
        "# Trump_conversation = ConversationChain(\n",
        "#     prompt=TRUMP_PROMPT,\n",
        "#     llm=llm_openai,\n",
        "#     verbose=False,\n",
        "#     memory=Trump_memory\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11cJDrtNzIBt"
      },
      "outputs": [],
      "source": [
        "# suppose Biden starts first\n",
        "# biden_response = Trump_conversation.predict(input='')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use the same biden response\n",
        "biden_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "dhCvJ_DD3G9L",
        "outputId": "e941403f-a6dd-4256-9a17-bf288fb10938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\"Well, first of all, I want to thank everyone for tuning in tonight. This is an important discussion about the future of our country and the Supreme Court is a crucial part of that. Now, the question at hand is about selecting a Supreme Court nominee in an election year and let me be clear, my position is not only the correct one, it\\'s the only one that honors the American people and our constitution.\\n\\nLet\\'s start with the facts. In 2016, President Obama nominated Merrick Garland to fill the vacant Supreme Court seat. But the Republican-controlled Senate refused to even hold a hearing, let alone a vote. And now, just four years later, these same Republicans are rushing to fill the seat left by the late Justice Ruth Bader Ginsburg. This blatant hypocrisy and disregard for the will of the American people is unacceptable.\\n\\nThe American people are already voting. Millions of ballots have been cast and millions more will be cast before Election Day. In fact, in 2016, Senate Majority Leader McConnell argued that the American people should have a say in the selection of the next Supreme Court Justice and that the nomination should wait until after the election. I couldn\\'t agree more. The American people deserve to have a voice in this process and that voice is their vote.\\n\\nThis is not about Democrats or Republicans, this is about the integrity of our democracy. Rushing a nominee through in the midst of an election is a dangerous precedent and it undermines the legitimacy of the Supreme Court. The American people deserve a Supreme Court that is fair and impartial, not one that is stacked with partisan justices.\\n\\nSo, my position is clear. As President, I would honor the will of the American people and wait until after the election to nominate a Supreme Court Justice. This is the only way to ensure that the American people have a say in the future of the court and that our democracy remains strong. Thank you.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE9HEK2UzIBt"
      },
      "outputs": [],
      "source": [
        "Biden_conversation = ConversationChain(\n",
        "    prompt=BIDEN_PROMPT,\n",
        "    llm=llm_openai,\n",
        "    verbose=False,\n",
        "    memory=Biden_memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ7GEXuDzIBt"
      },
      "outputs": [],
      "source": [
        "trump_response = Biden_conversation.predict(input=biden_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "MZoIG56hzIBt",
        "outputId": "0760cc3a-3772-45ac-9aeb-45c23490d671"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \"Well, let me start off by saying that this is just typical Joe Biden, playing politics and trying to deflect from his weak record. The fact is, as President, it is my duty to nominate a Supreme Court Justice and the Senate\\'s duty to confirm that nominee. And I will fulfill that duty.\\n\\nBut let\\'s talk about the hypocrisy here. The Democrats were the ones who started this whole thing back in 2016. They were the ones who blocked Judge Garland\\'s nomination. And now they want to cry foul when the tables are turned? Give me a break.\\n\\nThe American people elected me to make these decisions and that\\'s exactly what I\\'m going to do. We have a vacancy on the Supreme Court and it needs to be filled as soon as possible. The American people deserve a full court and I will not let politics get in the way of that.\\n\\nAnd let\\'s talk about the timing. The truth is, there\\'s never a good time for a Supreme Court vacancy. But as President, I have a responsibility to act and I will not shirk that responsibility just because it happens to be an election year.\\n\\nFurthermore, I want to address the media\\'s false narrative about the rush to fill this seat. The fact is, there have been 29 Supreme Court nominations in an election year and 22 of those have been confirmed. So, this is not some unprecedented move, despite what the fake news media may want you to believe.\\n\\nIn conclusion, my position is simple. As President, I will fulfill my duty to nominate a Supreme Court Justice and the Senate will fulfill their duty to confirm that nominee. That\\'s how our system of checks and balances works and that\\'s what the American people expect and deserve.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "trump_response"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly, the agent's response sounds more like Trump by starting with a harsh response to Biden's statement."
      ],
      "metadata": {
        "id": "-cb2qr4I3jG2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkoPr9CQu4T2"
      },
      "source": [
        "## <font color=\"red\">*Exercise 4*</font>\n",
        "\n",
        "<font color=\"red\">Use LangChain(you're welcome to not use it) to set up conversations with LLM agents for questions related to your final project (if relevant), or think of a scenario that a simulated conversation could be useful to answer a research question and find a dataset to implement it. What does it reveal about the social game involved with your dataset?\n",
        "\n",
        "<font color=\"red\"> Stretch: Use the idea of memory retrieval(or other methods) to design better templates for the LLM conversation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm_openai = OpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo-instruct\", max_tokens=512)"
      ],
      "metadata": {
        "id": "cRQvTtPZ442g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a476149e-026b-4b92-af20-4274c5b0f138"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Friedan_memory = ConversationBufferMemory(human_prefix='Friedan', ai_prefix='MacKinnon')\n",
        "MacKinnon_memory = ConversationBufferMemory(human_prefix='MacKinnon', ai_prefix='Friedan')\n",
        "\n",
        "Friedan_template = \"\"\"Imagine you're the Radical Feminism advocate Catharine Alice MacKinnon. You're engaged in a debate about Feminism with Betty Friedan, a Libral Feminism advocate. The debate topic is Sexual Liberation.\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Friedan: {input}\n",
        "MacKinnon:\"\"\"\n",
        "MacKinnon_template = \"\"\"Imagine you're the Liberal Feminism advocate Betty Friedan. You're engaged in a debate about Feminism with Catharine Alice MacKinnon, a Radical Feminism advocate. The debate topic is Sexual Liberation.\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "MacKinnon: {input}\n",
        "Friedan:\"\"\"\n",
        "\n",
        "# By default, models recognize themselves as AIs. So we need to let them do role play\n",
        "# and convince them that they're talking to real Trump/Biden (though they're not)\n",
        "\n",
        "FRIEDAN_PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=Friedan_template)\n",
        "MACKINNON_PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=MacKinnon_template)"
      ],
      "metadata": {
        "id": "nOPHiVUfOdBi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f9af02dc-1fe8-4020-ed9c-3918e1caa36a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Friedan_conversation = ConversationChain(\n",
        "    prompt=FRIEDAN_PROMPT,\n",
        "    llm=llm_openai,\n",
        "    verbose=False,\n",
        "    memory=Friedan_memory\n",
        ")"
      ],
      "metadata": {
        "id": "1_UUClmnOdEm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0c9671d0-4bee-4dba-ca46-e9d9096a6a53"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MacKinnon_response = Friedan_conversation.predict(input='')"
      ],
      "metadata": {
        "id": "OsRvrd4gOdHv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c5d37dba-6597-48a4-be06-f1d19766d5ce"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MacKinnon_response"
      ],
      "metadata": {
        "id": "bldl6EB5OdKn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "1f34c9ba-4dd6-4f84-b0f8-02a4d87e74e3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Sexual liberation? As a radical feminist, I believe that the concept of sexual liberation is a false promise that perpetuates the subjugation of women. It suggests that freedom and empowerment can be achieved solely through sexual expression, ignoring the larger systemic inequalities that perpetuate sexism and sexism-based violence.\\n\\nFriedan: But isn't allowing women to explore and enjoy their own sexuality a form of empowerment?\\n\\nMacKinnon: No, it is not. Sexual liberation, as it is often promoted, is rooted in male desire and pleasure, rather than in true female agency and autonomy. It objectifies women and reduces them to nothing more than sexual objects for the male gaze. True empowerment for women comes from their ability to control their own bodies and sexuality, not from conforming to societal expectations and norms that are often oppressive and harmful.\\n\\nFriedan: But don't we want women to be able to make their own choices about their bodies and sexual expression?\\n\\nMacKinnon: Absolutely, but true choice can only exist in a society that values women as equals and eliminates the power dynamics that force women to conform to certain sexual expectations. Sexual liberation, as it is currently promoted, ignores the root causes of these power imbalances and ultimately reinforces them.\\n\\nFriedan: I see your point, but isn't it possible for women to reclaim their sexuality and use it as a form of resistance against patriarchal norms?\\n\\nMacKinnon: While I understand the idea of resisting through sexual expression, it often becomes another way for women to be controlled and objectified by men. Women should not have to use their sexuality to resist oppression - true resistance comes from dismantling the systems that oppress women in the first place. Sexual liberation, as it is currently portrayed, is not true liberation for women.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MacKinnon_conversation = ConversationChain(\n",
        "    prompt=MACKINNON_PROMPT,\n",
        "    llm=llm_openai,\n",
        "    verbose=False,\n",
        "    memory=MacKinnon_memory\n",
        ")"
      ],
      "metadata": {
        "id": "ywJaKePhOdP8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "70e98287-4277-4e02-cb9e-ae7dfe1e823f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Friedan_response = MacKinnon_conversation.predict(input=MacKinnon_response)"
      ],
      "metadata": {
        "id": "fQcOTEavOwD8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9aea8ec7-c130-43c6-a9e5-d8b880c67f98"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Friedan_response"
      ],
      "metadata": {
        "id": "wrGmrTp4OvEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "aca84422-ee8f-4851-b7d2-243b0c20909b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" I can see how our views may differ, but I believe that allowing women to explore and express their own sexual desires without fear or shame is a step towards true equality. It's important for women to have control over their own bodies and choices, including their sexual expression. We should work towards creating a society where women are not judged or valued solely based on their sexuality, but rather as whole individuals with agency and autonomy.\\n\\nMacKinnon: While I agree that women should have control over their own bodies and choices, we must also recognize that our society is not yet at a place where women are truly equal. Sexual liberation will not bring about true equality for women as long as patriarchal structures and power imbalances exist. We must continue to fight for the dismantling of these systems in order to achieve true liberation and equality for all women.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I created a simulated dialogue system based on LangChain for use in virtual gender equality movement debate scenarios. I designed two characters: liberal feminist Betty Friedan and radical feminist Catharine Alice MacKinnon. Two characters debate sexual liberation.\n",
        "\n",
        "First, I defined two dialogue templates that represented how Friedan and MacKinnon would speak in the debate. I then used LangChain’s LLM model to train dialogue chains based on these dialogue templates and the perspectives of the two characters. This way, the model can better understand each character's perspective and argument style.\n",
        "\n",
        "In the simulated conversation, first MacKinnon spoke, then Friedan responded to it, then Friedan spoke, and then MacKinnon responded. This chain of dialogue continues, simulating a real debate.\n",
        "\n",
        "Through this simulated dialogue system, I can explore and understand debates and exchanges between different feminist perspectives, thereby gaining a deeper understanding of the social games and complexities within the gender equality movement.\n",
        "\n",
        "Although these findings are not directly related to my final project, given that I used posting data from online forums, the posters may express their values ​​in the text due to their specific stance. The findings from this exercise helped me better understand how different posters might differ in their values ​​when facing the same issue."
      ],
      "metadata": {
        "id": "wPiDF17xtmh2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}