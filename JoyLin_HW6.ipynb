{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3195d060677547e582c46755719a8c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d06731e2e6e442378266602536f597ae",
              "IPY_MODEL_b4d9861e6204499baaaa7a2bd1adccda",
              "IPY_MODEL_ecc888838b664d1d8e09afb60e4c3954"
            ],
            "layout": "IPY_MODEL_13669450065d4ee1b9fb10b5edfd1c96"
          }
        },
        "d06731e2e6e442378266602536f597ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6160a289fa24b77ab45134a2657726e",
            "placeholder": "​",
            "style": "IPY_MODEL_4c9b853d284a4370aa3fdccd34633318",
            "value": "Downloading readme: 100%"
          }
        },
        "b4d9861e6204499baaaa7a2bd1adccda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a2b2b237d07422586ae6877b3330e35",
            "max": 1017,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb5384df4f474744b10b77f8c2bd4bf3",
            "value": 1017
          }
        },
        "ecc888838b664d1d8e09afb60e4c3954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_095eee3e07d2412fa8e210f07f51f221",
            "placeholder": "​",
            "style": "IPY_MODEL_db8b6b797a784eecac0de5ac8b870045",
            "value": " 1.02k/1.02k [00:00&lt;00:00, 21.9kB/s]"
          }
        },
        "13669450065d4ee1b9fb10b5edfd1c96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6160a289fa24b77ab45134a2657726e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c9b853d284a4370aa3fdccd34633318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a2b2b237d07422586ae6877b3330e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb5384df4f474744b10b77f8c2bd4bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "095eee3e07d2412fa8e210f07f51f221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db8b6b797a784eecac0de5ac8b870045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "825b5b9c3fb045dfac34160260c0695b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0b78ce9fd534ab3bd57f241f151c281",
              "IPY_MODEL_6d540977e6e8468f89a6fe279976173e",
              "IPY_MODEL_daadcc1a78704ec1b567260e85c71056"
            ],
            "layout": "IPY_MODEL_19dbc82433194829941c476b2f34bb13"
          }
        },
        "f0b78ce9fd534ab3bd57f241f151c281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f84739e453564847981a0021a6743d13",
            "placeholder": "​",
            "style": "IPY_MODEL_faa39ff76659407298db842b3c0d2118",
            "value": "Downloading data: 100%"
          }
        },
        "6d540977e6e8468f89a6fe279976173e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a051848239b1490da622a68b18566813",
            "max": 966693,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3c3a0f295ce4f4095bbb66225894ef8",
            "value": 966693
          }
        },
        "daadcc1a78704ec1b567260e85c71056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02d85cc6b89147d1b1c6a25fb4154209",
            "placeholder": "​",
            "style": "IPY_MODEL_1e2ab858f54b454abb0bb0854d6c1af6",
            "value": " 967k/967k [00:00&lt;00:00, 2.78MB/s]"
          }
        },
        "19dbc82433194829941c476b2f34bb13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f84739e453564847981a0021a6743d13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa39ff76659407298db842b3c0d2118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a051848239b1490da622a68b18566813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c3a0f295ce4f4095bbb66225894ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02d85cc6b89147d1b1c6a25fb4154209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e2ab858f54b454abb0bb0854d6c1af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d9bb3c92a90422485c69673dc7683be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c2f257e75644e67882f4af5894bfe40",
              "IPY_MODEL_87bef2d6441f40f288f29e8b278e97f6",
              "IPY_MODEL_99652f3ab9434ecbb13b1e23f053dfbc"
            ],
            "layout": "IPY_MODEL_4be8e61d6c5142ed97428a9d4eebae8d"
          }
        },
        "4c2f257e75644e67882f4af5894bfe40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a97df38ca01346b496f4ef4720fe64bf",
            "placeholder": "​",
            "style": "IPY_MODEL_361400afbe9e492abe7c891014b5b1a9",
            "value": "Generating train split: 100%"
          }
        },
        "87bef2d6441f40f288f29e8b278e97f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db4418addae457abc607aaffea29f8a",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f99ffe443984b2d993bac7c563abfab",
            "value": 1000
          }
        },
        "99652f3ab9434ecbb13b1e23f053dfbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a11a24b9f9a4cc29301084d53ac60c2",
            "placeholder": "​",
            "style": "IPY_MODEL_c74fda8085df49f2ac9354ebfa5af430",
            "value": " 1000/1000 [00:00&lt;00:00, 7635.93 examples/s]"
          }
        },
        "4be8e61d6c5142ed97428a9d4eebae8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97df38ca01346b496f4ef4720fe64bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361400afbe9e492abe7c891014b5b1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3db4418addae457abc607aaffea29f8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f99ffe443984b2d993bac7c563abfab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a11a24b9f9a4cc29301084d53ac60c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c74fda8085df49f2ac9354ebfa5af430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2757493812ff4bdeb9cd0c51c8693c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_283469b00c594c82b59721450a63980e",
              "IPY_MODEL_31d6232fd5b54b3088fb1cce275eeec5",
              "IPY_MODEL_1c7ebd9e23964124bc99ba1a03e41e2c"
            ],
            "layout": "IPY_MODEL_992349ed0bec42d5bde6ca7234d3689b"
          }
        },
        "283469b00c594c82b59721450a63980e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fcfd4ce5cb746e186ea1dfc3ce142e3",
            "placeholder": "​",
            "style": "IPY_MODEL_79f852f0f823428d95f2002f27b08cf2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "31d6232fd5b54b3088fb1cce275eeec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45bb612ad0214020b9ff2599479f4fd9",
            "max": 746,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c824f0331c6480c9bdb40b135b2acb9",
            "value": 746
          }
        },
        "1c7ebd9e23964124bc99ba1a03e41e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_866f97c530794ac18ea0259676cb97ef",
            "placeholder": "​",
            "style": "IPY_MODEL_844e0c4fde5942469ddc9d56100c8793",
            "value": " 746/746 [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "992349ed0bec42d5bde6ca7234d3689b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fcfd4ce5cb746e186ea1dfc3ce142e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79f852f0f823428d95f2002f27b08cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45bb612ad0214020b9ff2599479f4fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c824f0331c6480c9bdb40b135b2acb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "866f97c530794ac18ea0259676cb97ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "844e0c4fde5942469ddc9d56100c8793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcb6ac480d57422c903f0950363f58f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3695740d182c4cec8bc0cc69483a570d",
              "IPY_MODEL_b58a788c36c54833beaaea91c05eda07",
              "IPY_MODEL_417389f6b1e64a30aa9d2a5d71ff5cd8"
            ],
            "layout": "IPY_MODEL_4ca4d22880d24501a10c69fbf68dd26f"
          }
        },
        "3695740d182c4cec8bc0cc69483a570d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c36286934adf4213a0168bff5049db42",
            "placeholder": "​",
            "style": "IPY_MODEL_98bd6cbd492645a4a71d8221b41c5d9a",
            "value": "tokenizer.model: 100%"
          }
        },
        "b58a788c36c54833beaaea91c05eda07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4976d3e753ef4832896f7bbe900c4d86",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3a403937d6a4f99a8f270ddad7ce159",
            "value": 499723
          }
        },
        "417389f6b1e64a30aa9d2a5d71ff5cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb35f98aba944088ba97e5e554235ad3",
            "placeholder": "​",
            "style": "IPY_MODEL_c21a3945e1864624b329af86cf910c52",
            "value": " 500k/500k [00:00&lt;00:00, 7.09MB/s]"
          }
        },
        "4ca4d22880d24501a10c69fbf68dd26f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c36286934adf4213a0168bff5049db42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98bd6cbd492645a4a71d8221b41c5d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4976d3e753ef4832896f7bbe900c4d86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3a403937d6a4f99a8f270ddad7ce159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb35f98aba944088ba97e5e554235ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c21a3945e1864624b329af86cf910c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e85599c906f4a17883d4fe4020db531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d35eb31a6d03453bb9f45e07066330e0",
              "IPY_MODEL_c7644ada1bc14784bf46443d2c90825e",
              "IPY_MODEL_197fd6c24d30467ca0f59c838259e91f"
            ],
            "layout": "IPY_MODEL_ec5636b05e174a518f3c2e318372c737"
          }
        },
        "d35eb31a6d03453bb9f45e07066330e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a190b57045df4d7493742d87df86a6d9",
            "placeholder": "​",
            "style": "IPY_MODEL_6013d8de801045b9bd811ff7b816ba38",
            "value": "tokenizer.json: 100%"
          }
        },
        "c7644ada1bc14784bf46443d2c90825e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e987a5ac43474352992c913bd4aaae69",
            "max": 1842764,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f1382a64fca4da8ad73067254e821de",
            "value": 1842764
          }
        },
        "197fd6c24d30467ca0f59c838259e91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_245b2f83ca8748548dbd0491c9b43b56",
            "placeholder": "​",
            "style": "IPY_MODEL_140fedb9f1d840cf86085065d72afbf2",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 7.09MB/s]"
          }
        },
        "ec5636b05e174a518f3c2e318372c737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a190b57045df4d7493742d87df86a6d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6013d8de801045b9bd811ff7b816ba38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e987a5ac43474352992c913bd4aaae69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f1382a64fca4da8ad73067254e821de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "245b2f83ca8748548dbd0491c9b43b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "140fedb9f1d840cf86085065d72afbf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3c0d19dca6c4e59bd825c7033ab2edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac24146cddb149599ae04a79b88a5b2a",
              "IPY_MODEL_024f00bab6e84972ba122c72c70447bc",
              "IPY_MODEL_8fc4d59609d54b469ecc8dd8e3cc11d5"
            ],
            "layout": "IPY_MODEL_a2fa29c0e468467fa4a88fe557bfd43e"
          }
        },
        "ac24146cddb149599ae04a79b88a5b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7e92be2f7914fc7a3f87acab17ec9c7",
            "placeholder": "​",
            "style": "IPY_MODEL_ee76273f4f754dc089929e54d363a7b3",
            "value": "added_tokens.json: 100%"
          }
        },
        "024f00bab6e84972ba122c72c70447bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a500de51cec04da79dee3281be27b225",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72b1b57dea954fa982a642313cdb93cc",
            "value": 21
          }
        },
        "8fc4d59609d54b469ecc8dd8e3cc11d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f0903cc95764cbe8f08dd4cc61f7727",
            "placeholder": "​",
            "style": "IPY_MODEL_439252676b8443c08fc3739fbfb5902c",
            "value": " 21.0/21.0 [00:00&lt;00:00, 565B/s]"
          }
        },
        "a2fa29c0e468467fa4a88fe557bfd43e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e92be2f7914fc7a3f87acab17ec9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee76273f4f754dc089929e54d363a7b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a500de51cec04da79dee3281be27b225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b1b57dea954fa982a642313cdb93cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f0903cc95764cbe8f08dd4cc61f7727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "439252676b8443c08fc3739fbfb5902c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f084daa55f142b1bd9a5566a60971bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6787aaa527145e191fe5e160192f739",
              "IPY_MODEL_e13aed7083724d93b9ea6e63f53c3620",
              "IPY_MODEL_854161cdba924797a9f473a3907a0f72"
            ],
            "layout": "IPY_MODEL_b650237bf7c04e29a6ba33166ee4993b"
          }
        },
        "a6787aaa527145e191fe5e160192f739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae8a89e95fb469fa06470257f1cb0a0",
            "placeholder": "​",
            "style": "IPY_MODEL_faf194e0329a4764acba4670d6725ce7",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e13aed7083724d93b9ea6e63f53c3620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed14e56b7f17464ca6c3f5001d6b5437",
            "max": 435,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f62e7de9c7848b38b4d2e1944eb748a",
            "value": 435
          }
        },
        "854161cdba924797a9f473a3907a0f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33293d5c2ba941418fb07db7dd00fe3a",
            "placeholder": "​",
            "style": "IPY_MODEL_8ab78d78b1f543fba77e820629f2717f",
            "value": " 435/435 [00:00&lt;00:00, 6.02kB/s]"
          }
        },
        "b650237bf7c04e29a6ba33166ee4993b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ae8a89e95fb469fa06470257f1cb0a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf194e0329a4764acba4670d6725ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed14e56b7f17464ca6c3f5001d6b5437": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f62e7de9c7848b38b4d2e1944eb748a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33293d5c2ba941418fb07db7dd00fe3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab78d78b1f543fba77e820629f2717f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74f9051e77514e76959d763648871a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7541fc22178e45c9805a35e1e0dfb754",
              "IPY_MODEL_0b795527f7394718a011e2a6d74debf7",
              "IPY_MODEL_d7b45d026b6843b4aaec52dd9df1ad9c"
            ],
            "layout": "IPY_MODEL_72c7dac1792a4338a433874f4341f97d"
          }
        },
        "7541fc22178e45c9805a35e1e0dfb754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aec0012b48f24219a83b9efbd193b695",
            "placeholder": "​",
            "style": "IPY_MODEL_f32d7ab11f9a4edab50ccf89c4632160",
            "value": "config.json: 100%"
          }
        },
        "0b795527f7394718a011e2a6d74debf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3edb6b2072047539452d56f108d50b0",
            "max": 1394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dce34e11e6945b2ade0cdcf5ef5d59c",
            "value": 1394
          }
        },
        "d7b45d026b6843b4aaec52dd9df1ad9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e41015bd4c114ebd97b4687b62cfd2c5",
            "placeholder": "​",
            "style": "IPY_MODEL_c25bf7c4d11141968b80ccd672a6748f",
            "value": " 1.39k/1.39k [00:00&lt;00:00, 91.0kB/s]"
          }
        },
        "72c7dac1792a4338a433874f4341f97d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aec0012b48f24219a83b9efbd193b695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f32d7ab11f9a4edab50ccf89c4632160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3edb6b2072047539452d56f108d50b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dce34e11e6945b2ade0cdcf5ef5d59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e41015bd4c114ebd97b4687b62cfd2c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c25bf7c4d11141968b80ccd672a6748f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c2d87c1d7e4155ab2a3d4a09a25dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78e793832387482a8f4ae8d93831921b",
              "IPY_MODEL_c283182ae9d04385a81f019dcba8bed1",
              "IPY_MODEL_d52269f768c541eea982d6e619db4a82"
            ],
            "layout": "IPY_MODEL_9453673343ac46af80fdf28fd843a770"
          }
        },
        "78e793832387482a8f4ae8d93831921b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d6a2f06855446cd8d93cc6fdfb4bea8",
            "placeholder": "​",
            "style": "IPY_MODEL_e473dcab40ff45adb10269637341ca94",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "c283182ae9d04385a81f019dcba8bed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9adb94a572847bfb6c3cf3d8369a12c",
            "max": 312087009,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2383b7b0ae0b4b5986a22d79d99c1eb2",
            "value": 312087009
          }
        },
        "d52269f768c541eea982d6e619db4a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7b87dd0db984c2299ecabda9e701ac4",
            "placeholder": "​",
            "style": "IPY_MODEL_ac0a451ca4364b578d07e1f18041258a",
            "value": " 312M/312M [00:01&lt;00:00, 225MB/s]"
          }
        },
        "9453673343ac46af80fdf28fd843a770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d6a2f06855446cd8d93cc6fdfb4bea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e473dcab40ff45adb10269637341ca94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9adb94a572847bfb6c3cf3d8369a12c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2383b7b0ae0b4b5986a22d79d99c1eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7b87dd0db984c2299ecabda9e701ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac0a451ca4364b578d07e1f18041258a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "129a0b05796047c4b359a5f3680fff13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46a7b9a5108b4f95b938a4cb1e40bb5c",
              "IPY_MODEL_fabab81c3fa443429bd0e436aca2d5f7",
              "IPY_MODEL_412942df3ce044b4a077a6cd6d270719"
            ],
            "layout": "IPY_MODEL_7c1781cc870243899e6e9b30ad9eddff"
          }
        },
        "46a7b9a5108b4f95b938a4cb1e40bb5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9efeb7597674399b1cb01015a04fa0f",
            "placeholder": "​",
            "style": "IPY_MODEL_120ee8301c8e44c4a40dedd3f2915f6c",
            "value": "generation_config.json: 100%"
          }
        },
        "fabab81c3fa443429bd0e436aca2d5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23601eccf891446db24cd29cce69640f",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_261b6f63d4094c6ea0f7b0dcd7f16365",
            "value": 293
          }
        },
        "412942df3ce044b4a077a6cd6d270719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f5a656de61245d98c175a43f830ec60",
            "placeholder": "​",
            "style": "IPY_MODEL_f487af41c1cc43c78a49c7a48c11bf29",
            "value": " 293/293 [00:00&lt;00:00, 17.9kB/s]"
          }
        },
        "7c1781cc870243899e6e9b30ad9eddff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9efeb7597674399b1cb01015a04fa0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "120ee8301c8e44c4a40dedd3f2915f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23601eccf891446db24cd29cce69640f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "261b6f63d4094c6ea0f7b0dcd7f16365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f5a656de61245d98c175a43f830ec60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f487af41c1cc43c78a49c7a48c11bf29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c5b20f0002843b98bbc3fe2a03e4238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a345f897658488ebc79645ae7365540",
              "IPY_MODEL_e910c3c3523a43e1b668875b41841e99",
              "IPY_MODEL_c96b6b2d938740df809776c5469b95fd"
            ],
            "layout": "IPY_MODEL_848c6857f20049f98ba0bc3e422695d5"
          }
        },
        "8a345f897658488ebc79645ae7365540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_634ab3487beb42078c83dc9a396e449c",
            "placeholder": "​",
            "style": "IPY_MODEL_0872908c3c8b4583ab7238c0e52015f1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e910c3c3523a43e1b668875b41841e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57e0a1fb3c47475f9d44f7cc4dcb9065",
            "max": 44,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b886723f9dee424c85c06e3e675b087d",
            "value": 44
          }
        },
        "c96b6b2d938740df809776c5469b95fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f3b76bdab2f438abdc5ed7e87dc7d27",
            "placeholder": "​",
            "style": "IPY_MODEL_9c19b065be434bf49336234ec4139af9",
            "value": " 44.0/44.0 [00:00&lt;00:00, 3.42kB/s]"
          }
        },
        "848c6857f20049f98ba0bc3e422695d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "634ab3487beb42078c83dc9a396e449c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0872908c3c8b4583ab7238c0e52015f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57e0a1fb3c47475f9d44f7cc4dcb9065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b886723f9dee424c85c06e3e675b087d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f3b76bdab2f438abdc5ed7e87dc7d27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c19b065be434bf49336234ec4139af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e44368c2850403691841c73e3481d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3aeb9ffae95a452d8f9f9065fcbca1b8",
              "IPY_MODEL_394d350228de44318f14bde71846ee8f",
              "IPY_MODEL_c1f44b7cbbab4c21a99f26ecfb60e831"
            ],
            "layout": "IPY_MODEL_a5559cf6046047019452696c49a98ea9"
          }
        },
        "3aeb9ffae95a452d8f9f9065fcbca1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cd1fbaab4694fe88641888cef92da8a",
            "placeholder": "​",
            "style": "IPY_MODEL_b9d05f0ba20845e792f68251559983a7",
            "value": "source.spm: 100%"
          }
        },
        "394d350228de44318f14bde71846ee8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1465f3b32ed9418c8bad0cdb571fea26",
            "max": 804677,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4097796db0f64ad3b3f5d66da4ff2bf5",
            "value": 804677
          }
        },
        "c1f44b7cbbab4c21a99f26ecfb60e831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5bb8eaf44045b4a6f9ecbfc99fd3cc",
            "placeholder": "​",
            "style": "IPY_MODEL_2ada09345cde46a4abdc9d4a0c419519",
            "value": " 805k/805k [00:00&lt;00:00, 27.6MB/s]"
          }
        },
        "a5559cf6046047019452696c49a98ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd1fbaab4694fe88641888cef92da8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d05f0ba20845e792f68251559983a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1465f3b32ed9418c8bad0cdb571fea26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4097796db0f64ad3b3f5d66da4ff2bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a5bb8eaf44045b4a6f9ecbfc99fd3cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ada09345cde46a4abdc9d4a0c419519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be284c0ab4d7416998a9d7cb362cce12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f2b5eceba164832822370a8e0e7426b",
              "IPY_MODEL_8a1319b0163d4368802176fa9f9bbda9",
              "IPY_MODEL_4d87b7421989454fa654ba2081509a98"
            ],
            "layout": "IPY_MODEL_fb652148b091443ab92839cbe79f2a81"
          }
        },
        "6f2b5eceba164832822370a8e0e7426b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7401d94da2ff43a1a575fb784d7e187e",
            "placeholder": "​",
            "style": "IPY_MODEL_7aca9c3215ee42ef926361b4cb8b1bf2",
            "value": "target.spm: 100%"
          }
        },
        "8a1319b0163d4368802176fa9f9bbda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ce3b025d2f94c33a44a979380ea557f",
            "max": 806530,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64a3f5de96c14829bc2290183762adda",
            "value": 806530
          }
        },
        "4d87b7421989454fa654ba2081509a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab5d30e4202f4cc5a9feb919d1d36111",
            "placeholder": "​",
            "style": "IPY_MODEL_217f6e15fae0490da730d5eb3c4342a9",
            "value": " 807k/807k [00:00&lt;00:00, 27.8MB/s]"
          }
        },
        "fb652148b091443ab92839cbe79f2a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7401d94da2ff43a1a575fb784d7e187e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aca9c3215ee42ef926361b4cb8b1bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ce3b025d2f94c33a44a979380ea557f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a3f5de96c14829bc2290183762adda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab5d30e4202f4cc5a9feb919d1d36111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217f6e15fae0490da730d5eb3c4342a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4af47f03aa084856949cbbdde0dc5902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_551232dec609492fa88d535500584376",
              "IPY_MODEL_f5d20219b59e40da84d8ffe2562ef4a1",
              "IPY_MODEL_3a06dc5e47894260b3011da9c7747828"
            ],
            "layout": "IPY_MODEL_f9a304a092e04a65967b3daae1f9283f"
          }
        },
        "551232dec609492fa88d535500584376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a560ae7365314f04a064f1918119bfe8",
            "placeholder": "​",
            "style": "IPY_MODEL_7a5e627853944f07906583e8816ad654",
            "value": "vocab.json: 100%"
          }
        },
        "f5d20219b59e40da84d8ffe2562ef4a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8778c0aeb3f4e7faeeef47d35527165",
            "max": 1617902,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdbfeaad68d44213b03b2e92a7e65d36",
            "value": 1617902
          }
        },
        "3a06dc5e47894260b3011da9c7747828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bebf409db3614d0aa47e87d00f0d8477",
            "placeholder": "​",
            "style": "IPY_MODEL_c4c174c8784b488fbea1bb7e7e46cf30",
            "value": " 1.62M/1.62M [00:00&lt;00:00, 45.4MB/s]"
          }
        },
        "f9a304a092e04a65967b3daae1f9283f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a560ae7365314f04a064f1918119bfe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a5e627853944f07906583e8816ad654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8778c0aeb3f4e7faeeef47d35527165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdbfeaad68d44213b03b2e92a7e65d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bebf409db3614d0aa47e87d00f0d8477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c174c8784b488fbea1bb7e7e46cf30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cf1417ca20547ffbeb12da71f1d28dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7edbd2dfdac24e698b29f875c3c618c1",
              "IPY_MODEL_5763fb1b42b1481bb0b2a65833267cce",
              "IPY_MODEL_13440fc473ac4af984ae82e2f4831763"
            ],
            "layout": "IPY_MODEL_bc0db1bb1d1740a9be4f5ff98e2d9be3"
          }
        },
        "7edbd2dfdac24e698b29f875c3c618c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03ac0ff086204d6cb43e72ae3351fabc",
            "placeholder": "​",
            "style": "IPY_MODEL_e8415e1ca9eb4344b5f5e16272f7fc41",
            "value": "config.json: 100%"
          }
        },
        "5763fb1b42b1481bb0b2a65833267cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a92c1369cdf47e194465291297c4f6c",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_314712f323124c9e837b7d1c6d7b9e3a",
            "value": 665
          }
        },
        "13440fc473ac4af984ae82e2f4831763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6153123da4e4383a61e80a35c5162d8",
            "placeholder": "​",
            "style": "IPY_MODEL_4c45f300288c44a88369df416f257f8d",
            "value": " 665/665 [00:00&lt;00:00, 36.8kB/s]"
          }
        },
        "bc0db1bb1d1740a9be4f5ff98e2d9be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03ac0ff086204d6cb43e72ae3351fabc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8415e1ca9eb4344b5f5e16272f7fc41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a92c1369cdf47e194465291297c4f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314712f323124c9e837b7d1c6d7b9e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6153123da4e4383a61e80a35c5162d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c45f300288c44a88369df416f257f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00d1d11b054f4ce59c807dc62e404b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edfff852b6cf48b4947150389e176ca8",
              "IPY_MODEL_a588577e6c1d43bbbdc97aae10dfdf16",
              "IPY_MODEL_77901f3c35fd4bbead7e53ee9f9ac6bc"
            ],
            "layout": "IPY_MODEL_9a51b3911ad7429688b4ec2bbf129251"
          }
        },
        "edfff852b6cf48b4947150389e176ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0498a35ffce046559ddbe47e7f6effe6",
            "placeholder": "​",
            "style": "IPY_MODEL_1f5c6e0491e54cada7a819221224193d",
            "value": "model.safetensors: 100%"
          }
        },
        "a588577e6c1d43bbbdc97aae10dfdf16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c0c3711b554f6aa6933fca0533d46a",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_891c1affc7664fc397c7064fa77c8e4e",
            "value": 548105171
          }
        },
        "77901f3c35fd4bbead7e53ee9f9ac6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c636ac5dd2e4384acc1e771e8b8a86a",
            "placeholder": "​",
            "style": "IPY_MODEL_01814bc75a0d4c19bcd39c8bb3565e53",
            "value": " 548M/548M [00:06&lt;00:00, 50.4MB/s]"
          }
        },
        "9a51b3911ad7429688b4ec2bbf129251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0498a35ffce046559ddbe47e7f6effe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f5c6e0491e54cada7a819221224193d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47c0c3711b554f6aa6933fca0533d46a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "891c1affc7664fc397c7064fa77c8e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c636ac5dd2e4384acc1e771e8b8a86a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01814bc75a0d4c19bcd39c8bb3565e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5f4a08adbb54b4c814ed6024bd39e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17143a6d954a4948a01a5e38da4d66f3",
              "IPY_MODEL_601234425bc945e3a89e3f82e22b58d7",
              "IPY_MODEL_6652772fdd2c438385b6096ae4b2d5b5"
            ],
            "layout": "IPY_MODEL_7280b9cef2104dfc95e900d1db931483"
          }
        },
        "17143a6d954a4948a01a5e38da4d66f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c926410381f4dc6be2c619e89042832",
            "placeholder": "​",
            "style": "IPY_MODEL_df65fe088deb406c8a12bed6633035ca",
            "value": "generation_config.json: 100%"
          }
        },
        "601234425bc945e3a89e3f82e22b58d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c3b58176a0249a08e83bd212afcaf74",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_308b21225707449583ce9709a4d123c7",
            "value": 124
          }
        },
        "6652772fdd2c438385b6096ae4b2d5b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c263998d3ddc431cb2032af1e4b8e6dd",
            "placeholder": "​",
            "style": "IPY_MODEL_5800aee0afae467aa029bc96364f6638",
            "value": " 124/124 [00:00&lt;00:00, 5.10kB/s]"
          }
        },
        "7280b9cef2104dfc95e900d1db931483": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c926410381f4dc6be2c619e89042832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df65fe088deb406c8a12bed6633035ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c3b58176a0249a08e83bd212afcaf74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308b21225707449583ce9709a4d123c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c263998d3ddc431cb2032af1e4b8e6dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5800aee0afae467aa029bc96364f6638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ac972aa545e4eb5b8d68391e0fc3efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d50c8e5b69746d7828437057f383885",
              "IPY_MODEL_2ca946247a6b47558977a096707d3b7e",
              "IPY_MODEL_c9126c83936d4d78b9d0d16e9fed042c"
            ],
            "layout": "IPY_MODEL_437b4e1c5d3e4fdab72411dc8b087fbe"
          }
        },
        "6d50c8e5b69746d7828437057f383885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82935a523bac44d6a7fe1069f5049a28",
            "placeholder": "​",
            "style": "IPY_MODEL_2d5f5dc5571f4a458ee15f92c4a74c61",
            "value": "vocab.json: 100%"
          }
        },
        "2ca946247a6b47558977a096707d3b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a1b84ddda544a3a5812fe9f8506e06",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5547c7ea309942f6ae2041365b35d63b",
            "value": 1042301
          }
        },
        "c9126c83936d4d78b9d0d16e9fed042c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b60c2a0bcf904a39a7e66b777451f59f",
            "placeholder": "​",
            "style": "IPY_MODEL_1f296707854446debdf8ca1a396661c0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 23.6MB/s]"
          }
        },
        "437b4e1c5d3e4fdab72411dc8b087fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82935a523bac44d6a7fe1069f5049a28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d5f5dc5571f4a458ee15f92c4a74c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9a1b84ddda544a3a5812fe9f8506e06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5547c7ea309942f6ae2041365b35d63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b60c2a0bcf904a39a7e66b777451f59f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f296707854446debdf8ca1a396661c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48a6a577119b427ca381aa5f89816e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edd8b073386848f2bea98bd51cbd6f10",
              "IPY_MODEL_efd50723e95841f8bfd69afd994b9f5f",
              "IPY_MODEL_0ce3eca734dc4b0cb7a663eaec756e23"
            ],
            "layout": "IPY_MODEL_4a8349eddeec44c3aa505f565dbc826d"
          }
        },
        "edd8b073386848f2bea98bd51cbd6f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb34b7e4ede7422e9a2f06fdd8bda7e1",
            "placeholder": "​",
            "style": "IPY_MODEL_68c0d5a55bce4969947f6dd526c60fd7",
            "value": "merges.txt: 100%"
          }
        },
        "efd50723e95841f8bfd69afd994b9f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a92da834586442f798cba8a852edfa28",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87b5855ff39745a0955eab651a9be36c",
            "value": 456318
          }
        },
        "0ce3eca734dc4b0cb7a663eaec756e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_535b2b8a5cf1445f82a91c4c1a523b61",
            "placeholder": "​",
            "style": "IPY_MODEL_1e263c0ea76d4bc4ba4d76606a75566a",
            "value": " 456k/456k [00:00&lt;00:00, 25.2MB/s]"
          }
        },
        "4a8349eddeec44c3aa505f565dbc826d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb34b7e4ede7422e9a2f06fdd8bda7e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68c0d5a55bce4969947f6dd526c60fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a92da834586442f798cba8a852edfa28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87b5855ff39745a0955eab651a9be36c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "535b2b8a5cf1445f82a91c4c1a523b61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e263c0ea76d4bc4ba4d76606a75566a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "487dc5f6693f4de9a9b9c10b0b41f24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d055b63ebb9c4749a3714cddfd868813",
              "IPY_MODEL_40649ba19c1c4e77ac73df3109e0db2c",
              "IPY_MODEL_8d0a7a3d5219441594c8ddc9a171f037"
            ],
            "layout": "IPY_MODEL_dbe4ef98539c422aa2771b83704b4ced"
          }
        },
        "d055b63ebb9c4749a3714cddfd868813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36c5e0bdc54f4f10bb6ee7a73e818de9",
            "placeholder": "​",
            "style": "IPY_MODEL_06855dd17942495493eb33f29a50a7d1",
            "value": "tokenizer.json: 100%"
          }
        },
        "40649ba19c1c4e77ac73df3109e0db2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2686b54d3184e309a605a5443a7fac8",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56f17ba58dcf4856999e15b6fa9d672a",
            "value": 1355256
          }
        },
        "8d0a7a3d5219441594c8ddc9a171f037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9e9b69a2894e45a523b99da55a6d3d",
            "placeholder": "​",
            "style": "IPY_MODEL_54f852f419194f5da2b2d2495a1dffa9",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 5.51MB/s]"
          }
        },
        "dbe4ef98539c422aa2771b83704b4ced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36c5e0bdc54f4f10bb6ee7a73e818de9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06855dd17942495493eb33f29a50a7d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2686b54d3184e309a605a5443a7fac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f17ba58dcf4856999e15b6fa9d672a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b9e9b69a2894e45a523b99da55a6d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f852f419194f5da2b2d2495a1dffa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b400aae3346c4d05aa582020c49b15a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ac8ec33814542069bd7c25ba55781a2",
              "IPY_MODEL_1ac251e8ad8c467dbf77a14808f3c9d6",
              "IPY_MODEL_031827eae9bc4881b541f0c58c8647cb"
            ],
            "layout": "IPY_MODEL_bea28066889741d6a1b5d1034b80e17e"
          }
        },
        "2ac8ec33814542069bd7c25ba55781a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67e70418f3e64389ace57b32f7bf4b38",
            "placeholder": "​",
            "style": "IPY_MODEL_d2bd6922f3854f4bb9dd93bc6ec00d34",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "1ac251e8ad8c467dbf77a14808f3c9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc0777f38614a8e890c0c438a1996e9",
            "max": 649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dced553bb78c409abb5841487fbd7254",
            "value": 649
          }
        },
        "031827eae9bc4881b541f0c58c8647cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b9797a7c01d4ea8b75d4168f925c72d",
            "placeholder": "​",
            "style": "IPY_MODEL_ffbaef973b104387bd2ae30d98616881",
            "value": " 649/649 [00:00&lt;00:00, 7.29kB/s]"
          }
        },
        "bea28066889741d6a1b5d1034b80e17e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67e70418f3e64389ace57b32f7bf4b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2bd6922f3854f4bb9dd93bc6ec00d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afc0777f38614a8e890c0c438a1996e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dced553bb78c409abb5841487fbd7254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b9797a7c01d4ea8b75d4168f925c72d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffbaef973b104387bd2ae30d98616881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58e3063378f04c6f962ec731eacbf6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1e2872c38894743a0a70f705be9b5f0",
              "IPY_MODEL_63ec3faab119492a8648aa09e81db2fe",
              "IPY_MODEL_5f0f2a70efb041c18f561192aa4b681d"
            ],
            "layout": "IPY_MODEL_1fa33b03ccd545c593bee2e04c8187e6"
          }
        },
        "f1e2872c38894743a0a70f705be9b5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4100936569304216a0439cde8a03856a",
            "placeholder": "​",
            "style": "IPY_MODEL_e6d8af311f1a40aa9eb1e2ed9cff2091",
            "value": "Downloading tokenizer.model: 100%"
          }
        },
        "63ec3faab119492a8648aa09e81db2fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bee4e4d72fd444c3a1d680bfd9dabd82",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4c3c431261d418490a38ff5ed1bc74b",
            "value": 499723
          }
        },
        "5f0f2a70efb041c18f561192aa4b681d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abfde03b7957421db6d29547336a9b99",
            "placeholder": "​",
            "style": "IPY_MODEL_3e9af1807538409982093d44fe3a8c5e",
            "value": " 500k/500k [00:00&lt;00:00, 9.19MB/s]"
          }
        },
        "1fa33b03ccd545c593bee2e04c8187e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4100936569304216a0439cde8a03856a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d8af311f1a40aa9eb1e2ed9cff2091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bee4e4d72fd444c3a1d680bfd9dabd82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4c3c431261d418490a38ff5ed1bc74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abfde03b7957421db6d29547336a9b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e9af1807538409982093d44fe3a8c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8400b9e3836b470fa1d5a13c18257957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0302390641b249f38557a10bbea92ec1",
              "IPY_MODEL_1e5b8fd99bc84a0bab323b1f11a63d55",
              "IPY_MODEL_c4f32b23cbaf41e89b8f81f9b5712fa4"
            ],
            "layout": "IPY_MODEL_58b77cb1816d4903b3211253f22cd4d3"
          }
        },
        "0302390641b249f38557a10bbea92ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f86b81a733b4259b9af395d99b28622",
            "placeholder": "​",
            "style": "IPY_MODEL_b3381ce74c1e431c9ad073595d66aabf",
            "value": "Downloading tokenizer.json: 100%"
          }
        },
        "1e5b8fd99bc84a0bab323b1f11a63d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a60a0b9dcbe44dd8182187558906bd7",
            "max": 1842764,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06adf4ba482949d6a135d87d017bcd4f",
            "value": 1842764
          }
        },
        "c4f32b23cbaf41e89b8f81f9b5712fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2c3aa67279b46c3a19d7628625fdc39",
            "placeholder": "​",
            "style": "IPY_MODEL_281b7b0cb2474abb9a8eb1d98ebe71fb",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 11.3MB/s]"
          }
        },
        "58b77cb1816d4903b3211253f22cd4d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f86b81a733b4259b9af395d99b28622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3381ce74c1e431c9ad073595d66aabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a60a0b9dcbe44dd8182187558906bd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06adf4ba482949d6a135d87d017bcd4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2c3aa67279b46c3a19d7628625fdc39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "281b7b0cb2474abb9a8eb1d98ebe71fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "daf8a1f997d7482283c75be6d294f78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66e751193e934f0198b3b9677649f0d3",
              "IPY_MODEL_2498f8756b1946ca8a7dd1d32e33ad8c",
              "IPY_MODEL_a6c635fb365b42c1868e65780200f80e"
            ],
            "layout": "IPY_MODEL_a80ea0b4282f469987360368f7c145d7"
          }
        },
        "66e751193e934f0198b3b9677649f0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e5bd174040483ea849fd2c87d3a581",
            "placeholder": "​",
            "style": "IPY_MODEL_f1412da75e054822844b05c8a221f5be",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "2498f8756b1946ca8a7dd1d32e33ad8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c5c2f7293814c679cd21f5219dac27d",
            "max": 411,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3376d02b88ca4e099bf2388e1b5e416a",
            "value": 411
          }
        },
        "a6c635fb365b42c1868e65780200f80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edb6f5583940453e8da7c591de83604c",
            "placeholder": "​",
            "style": "IPY_MODEL_9a04914fbc3b4f6e979ec3b40d711860",
            "value": " 411/411 [00:00&lt;00:00, 9.95kB/s]"
          }
        },
        "a80ea0b4282f469987360368f7c145d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e5bd174040483ea849fd2c87d3a581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1412da75e054822844b05c8a221f5be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c5c2f7293814c679cd21f5219dac27d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3376d02b88ca4e099bf2388e1b5e416a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edb6f5583940453e8da7c591de83604c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a04914fbc3b4f6e979ec3b40d711860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0834b3e612a7469183639dd6147c5121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_052a31011f064d938bbb715f82f3fba4",
              "IPY_MODEL_0c256f63480f4e1393062c52afebeb1e",
              "IPY_MODEL_434a4272d2d744bd9989ceccc58fcce2"
            ],
            "layout": "IPY_MODEL_d5bb592998c64466bd0e4f07276e8e77"
          }
        },
        "052a31011f064d938bbb715f82f3fba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e9492e915744da82772e1b20aad3c6",
            "placeholder": "​",
            "style": "IPY_MODEL_6f6d948373274225acc02b63a0b03f61",
            "value": "Downloading config.json: 100%"
          }
        },
        "0c256f63480f4e1393062c52afebeb1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ead4b31db524501a177f2343096cfe4",
            "max": 631,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f89cdd1765143b19a2f8202174f3b0a",
            "value": 631
          }
        },
        "434a4272d2d744bd9989ceccc58fcce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8d462032aed4a38ac12fc87683b80a0",
            "placeholder": "​",
            "style": "IPY_MODEL_455695a7e4c8407eb4ab57245304cd96",
            "value": " 631/631 [00:00&lt;00:00, 18.7kB/s]"
          }
        },
        "d5bb592998c64466bd0e4f07276e8e77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e9492e915744da82772e1b20aad3c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6d948373274225acc02b63a0b03f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ead4b31db524501a177f2343096cfe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f89cdd1765143b19a2f8202174f3b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8d462032aed4a38ac12fc87683b80a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "455695a7e4c8407eb4ab57245304cd96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "340747dc15104fb9ad695f131a7c42d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_524f7ddd0651469ea0e79b640b6cf77f",
              "IPY_MODEL_12d3159d2d154b75990083cbe2e13494",
              "IPY_MODEL_922afaff4d584e65972ef31867c2b3da"
            ],
            "layout": "IPY_MODEL_a4d7c390622f4630b191a4cd832e6b78"
          }
        },
        "524f7ddd0651469ea0e79b640b6cf77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be543827bda547309a124652306cfe88",
            "placeholder": "​",
            "style": "IPY_MODEL_aebbd668da02438f9be482d4329d4553",
            "value": "Downloading (…)fetensors.index.json: 100%"
          }
        },
        "12d3159d2d154b75990083cbe2e13494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe176fa22f2f474a965ad36e31a8b985",
            "max": 62519,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1476b43fb2414a5b9a751888c0b14401",
            "value": 62519
          }
        },
        "922afaff4d584e65972ef31867c2b3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e53798a6b25c416a87c0444d8eb07396",
            "placeholder": "​",
            "style": "IPY_MODEL_7a073e2b2f0d48e7ad94d10eb93bb37a",
            "value": " 62.5k/62.5k [00:00&lt;00:00, 1.52MB/s]"
          }
        },
        "a4d7c390622f4630b191a4cd832e6b78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be543827bda547309a124652306cfe88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aebbd668da02438f9be482d4329d4553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe176fa22f2f474a965ad36e31a8b985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1476b43fb2414a5b9a751888c0b14401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e53798a6b25c416a87c0444d8eb07396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a073e2b2f0d48e7ad94d10eb93bb37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cb997d99a50460f9bf149b015c929ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_811289dd1f904fabae54c8f7ea099407",
              "IPY_MODEL_c834f8e5e20f4f1a8396c1a23773006a",
              "IPY_MODEL_ecf835e90f5f400f88c8312ea96573a8"
            ],
            "layout": "IPY_MODEL_8c1c86340ad840cbb70bb7b56f3956e4"
          }
        },
        "811289dd1f904fabae54c8f7ea099407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb941ae484ea41e4be600322c4c66e83",
            "placeholder": "​",
            "style": "IPY_MODEL_53aee670190d45618d107835c23779d5",
            "value": "Downloading shards: 100%"
          }
        },
        "c834f8e5e20f4f1a8396c1a23773006a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d818dbe07d74e599d9a2ce7b4410729",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a239ddfbc1fd4b9f8dedbe5a158b9740",
            "value": 1
          }
        },
        "ecf835e90f5f400f88c8312ea96573a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_911ead1e88bd4470bd5ea6809a6d6450",
            "placeholder": "​",
            "style": "IPY_MODEL_a290c25aa738427e8c6e642cd7656648",
            "value": " 1/1 [00:10&lt;00:00, 10.31s/it]"
          }
        },
        "8c1c86340ad840cbb70bb7b56f3956e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb941ae484ea41e4be600322c4c66e83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53aee670190d45618d107835c23779d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d818dbe07d74e599d9a2ce7b4410729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a239ddfbc1fd4b9f8dedbe5a158b9740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "911ead1e88bd4470bd5ea6809a6d6450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a290c25aa738427e8c6e642cd7656648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "229ff22228c74118a57c335ed5ef562e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e39698430d564f2d962562bb4a458ef7",
              "IPY_MODEL_ff00be1c6fbb4975ac48af2609a54e75",
              "IPY_MODEL_f53288206fcc46848230a0553892a18e"
            ],
            "layout": "IPY_MODEL_671a21a1f5b84863a7a90cf4d31c2ff2"
          }
        },
        "e39698430d564f2d962562bb4a458ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e227c3e731da48daa057c32bac5c3143",
            "placeholder": "​",
            "style": "IPY_MODEL_b0679afcb7144066adf87511e2958a3f",
            "value": "Downloading (…)of-00081.safetensors: 100%"
          }
        },
        "ff00be1c6fbb4975ac48af2609a54e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0942124417e547d3a36a27c808429dee",
            "max": 1048592704,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89da5c5aca904c3aa2052d39c27f1de0",
            "value": 1048592704
          }
        },
        "f53288206fcc46848230a0553892a18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fba64a383dd7467b9f3b461a9c39e560",
            "placeholder": "​",
            "style": "IPY_MODEL_dc5b93f35c4646fe997dcbb2f5a172ed",
            "value": " 1.05G/1.05G [00:10&lt;00:00, 147MB/s]"
          }
        },
        "671a21a1f5b84863a7a90cf4d31c2ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e227c3e731da48daa057c32bac5c3143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0679afcb7144066adf87511e2958a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0942124417e547d3a36a27c808429dee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89da5c5aca904c3aa2052d39c27f1de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fba64a383dd7467b9f3b461a9c39e560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc5b93f35c4646fe997dcbb2f5a172ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9906225e3f5c4dcb9e2434ed4a5f80a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ea094bbefc94b398b6c78e49b3c89a6",
              "IPY_MODEL_5782dae1fc9545ad86238bc42282eb24",
              "IPY_MODEL_c36e7d660c2f4cb0b0e4cf53df28a659"
            ],
            "layout": "IPY_MODEL_6e9967e6f302472caaabd45ca6fd1746"
          }
        },
        "7ea094bbefc94b398b6c78e49b3c89a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cd404739e4d4c419d3c51f396b35114",
            "placeholder": "​",
            "style": "IPY_MODEL_0d85fd28167847d48cc9daed49bfc6a5",
            "value": "Downloading generation_config.json: 100%"
          }
        },
        "5782dae1fc9545ad86238bc42282eb24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01a8ea677cb64d1dbf23cd2a45cf2174",
            "max": 137,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7f1605cda9e499ba9457ff901caf068",
            "value": 137
          }
        },
        "c36e7d660c2f4cb0b0e4cf53df28a659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29e9d42606d1457dbb03e88f4f67d11f",
            "placeholder": "​",
            "style": "IPY_MODEL_d800233acea54c1e897821b0a42a4296",
            "value": " 137/137 [00:00&lt;00:00, 2.55kB/s]"
          }
        },
        "6e9967e6f302472caaabd45ca6fd1746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd404739e4d4c419d3c51f396b35114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d85fd28167847d48cc9daed49bfc6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01a8ea677cb64d1dbf23cd2a45cf2174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f1605cda9e499ba9457ff901caf068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29e9d42606d1457dbb03e88f4f67d11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d800233acea54c1e897821b0a42a4296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joylin0209/40133HW/blob/main/JoyLin_HW6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1434765a"
      },
      "source": [
        "# Programming LLMs with Language\n",
        "\n",
        "In previous chapters, we saw how we can use the semantic information in large language models (LLMs) through standard nlp pipelines (e.g., classification) or using their underlying embeddings. But LLMs are *natively* programmed through language. Moreover, recent scholarship has both [**argued**](https://aclanthology.org/2023.findings-acl.247/) and then [**demonstrated**](https://proceedings.mlr.press/v202/von-oswald23a.html) how LLMs perform gradient descent on their internal, high-dimensional representations to optimize a response to a language prompt.\n",
        "\n",
        "In this notebook accompanying the chapter on programming LLMs with language, we will explore various ways we can interact with some of the most powerful deep learning models today using language.\n",
        "\n",
        "## The landscape of large language models\n",
        "\n",
        "Since 2023, the deep learning (and especially transformer) paradigm has made massive progress in enabling users to program LLMs with language. As these models begin to flood the mainstream, and with even widely viewed TikTok videos on how to \"engineer\" prompts, advanced Transformer based models such as GPT-4 and Gemini are accessible to more people than deep learning ever was before.\n",
        "\n",
        "The most popular of these models today is ChatGPT's family of models, run by OpenAI. There are, however, many other LLMs out there - Google's BARD, Anthropic's Claude, Deep Mind's Gemini, and Meta's open source LLaMa. Moreover, given how fast moving the field has become, ideally, we would prefer to approach this in a program agnostic way, and would point you towards [**LangChain**](https://www.langchain.com/).\n",
        "\n",
        "The most straightforward way to interact with these models is via their chat based API. To get an idea of how these models do, it's worth jumping onto any of their websites and give them a spin. This is the link to ChatGPT: https://chat.openai.com/. Chat-GPT 3.5 is currently free to use and Chat-GPT-4 can be used with subscription.\n",
        "\n",
        "While it is impressive - and can improve one's day to day work with respect to coding tasks or information retreival - simple back and forth chat with the model, without stewarding or persisting the interactive content, limits its utility for performing large scale data science, experiments, and analysis.\n",
        "\n",
        "Such a setup would require an API, where we can pass arguments and text in a controlled environment, automate certain classes of queries, and collect responses for further processing.\n",
        "\n",
        "In this code, that is what we will do - using a variety of APIs to interact with instances of large language models on a server. This notebook will walk you through various ways you can do that.\n",
        "\n",
        "The natural alternative is to have a local LLM, but for the kind of LLMs that can effectively be used as a conversational agent (or research assistant!), you would need a LOT of RAM and hardware capacity. We will not assume local hosting in this tutorial, but will have sample code for you to test (outside of Colab, which is not sufficiently large to host a substantial LLM).\n",
        "\n",
        "<!--## Geneology Diagram / Dialogue Prompt Screenshots-->\n",
        "\n",
        "## Some links and useful LLMs\n",
        "\n",
        "Keeping up with the latest LLMs at the top of the pack can be challenging given how quick the field is moving. Academic and production-oriented LLMs also develop at different paces and in different ways. At the moment, there is an active conversation and discussion on LLMs/AI on X/twitter, which is the primary place to really keep ahead of the game - as well as keeping up with Arxiv, and maybe subscribing to a few lists such as the Stanford HAI newsletter (or for more of AI/LLMs and Society view, DAIR).\n",
        "\n",
        "There are, however, a few \"usual suspects\" to track for new developments:\n",
        "\n",
        "[OpenAI](openai.com)\n",
        "\n",
        "OpenAI offers a variety of different LLMs and APIs addressing different use-cases, including fine-tuning models on your own data. Serious commercial use should be via the APIs, which are currently available by invitation.\n",
        "\n",
        "[Meta AI LLaMA 2](github.com/facebookresearch/llama/blob/main/MODEL_CARD.md)\n",
        "A collection of related LLMs released by Meta AI (Facebook). Unlike version 1, version 2 is available for commerical and research purposes.\n",
        "\n",
        "[Google Bard](bard.google.com)\n",
        "Google’s experimental LLM. No public APIs available yet, and chatbot conversations are used for further training, so not yet ready for commercial use.\n",
        "\n",
        "[Amazon AlexaTM](github.com/amazon-science/alexa-teacher-models)\n",
        "Amazon Science’s LLM, which can be accessed for non-commercial use via AWS SageMaker.\n",
        "\n",
        "[Anthropic Claude](claude.ai)\n",
        "Unique model because of its large context window (100k+ tokens), allowing it to answer questions about longer documents. API access is only available via inquiries. A chat interface is generally available, but conversations may be used for further training, so not a commercial option.\n",
        "\n",
        "[Hugging Face](huggingface.co)\n",
        "Hugging Face provides infrastructure support for LLM and other Machine Learning operations, including hosting, training and deployment of models. They also host some internally developed and open-source models such as BLOOM.\n",
        "\n",
        "Source for links and text - https://www.enthought.com/resource/cheat-sheet-large-language-models-for-scientific-research/\n",
        "\n",
        "\n",
        "\n",
        "## So where do we start?\n",
        "\n",
        "We're going to start with Open AI's LLM offering, the ChatGPT family of conversational and text generation models. Why ChatGPT? It was the language models to really kick off LLMs being accessed at the scale it is today--with 100 million users within 2 months--and has often led the leaderboards for multiple language and cognitive tasks, as well as being used by plenty of computational scientists, social scientists, and humanists for their studies.\n",
        "\n",
        "A caveat of using open AI is that their models are closed, meaning we have to interact via their API only,  that it can be expensive for multiple queries, and that free access is limited to their older models. That being said, given how popular ChatGPT is today, it is worth knowing your way around it - and after having gotten a hand of it, you will find that most other LLMs work in similar ways. We will even share links and examples from James Zou's FrugalGPT later, which explicitly predicts which model will work best, and select the cheapest for your task conditional on performance.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI API\n",
        "\n",
        "The OpenAI API is fairly straightforward, with two primary API modes - chat, and completion. We will start with a straightforward exposition of both methods, before moving on to providing distinctive roles and prompts, along with some best practices.\n",
        "\n"
      ],
      "metadata": {
        "id": "nfEkK9Y8sWTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting your API Key\n",
        "\n",
        "To use the Open AI API, you first need an API key. This means you need to make an account on the openAI website. Once you've done that, you would want to store this key in your environment variables, so that it isn't leaked.\n",
        "\n",
        "Follow this link on [best practices for API key safety](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety), which will help you keep those issues sorted.\n",
        "\n",
        "Once you've setup an account and stored your API key securely, the first cell will help you get your environment ready to start using openAI models.\n",
        "\n",
        "NOTE: LLM frameworks and packages keep changing. This notebook was written with version 1.10.0. Using a different version will likely break things.\n",
        "\n",
        "This is not code for you to copy paste into projects - it is to walk you through how these tools work, and then adapt accordingly for your own use cases."
      ],
      "metadata": {
        "id": "U_3kYKhj9c09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJCYMcNFhVK4",
        "outputId": "f56c9c06-d84c-452b-bf59-b81cd33f930e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai==1.10.0\n",
        "# openai-1.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qk2W56uQdyk",
        "outputId": "607402ae-fc45-4ed6-c456-1cad07680d14"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.10.0\n",
            "  Downloading openai-1.10.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.10.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.10.0) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.10.0)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.10.0) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.10.0) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.10.0) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.10.0) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.10.0) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.10.0) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.10.0) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.10.0)\n",
            "  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.10.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.10.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.10.0) (2.16.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 openai-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai"
      ],
      "metadata": {
        "id": "-9xJl3VZ9lj-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A note here - if you are working locally, use the code below to grab your API key. If not, the cell after this allows you to enter your key in the notebook in a way where it is not persisted when you save the notebook. If nothing else works...copy and paste your key into the notebook, but make sure not to share it!"
      ],
      "metadata": {
        "id": "BKbrBqu1gLXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.environ[\"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\"]"
      ],
      "metadata": {
        "id": "aG0LZ4hAgTSM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "75774325-ba16-4736-a00e-9c7dd6f4ea99"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'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'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-65ba2a65590f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"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\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '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'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below lets you enter it in the notebook."
      ],
      "metadata": {
        "id": "LDw9yBqYguNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "OPENAI_API_KEY = getpass.getpass()"
      ],
      "metadata": {
        "id": "5yZLEt-TgKcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfec525a-5765-4428-e8f7-f2e91c03495b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "xfGBDG8ygxr3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interacting with the model\n",
        "\n",
        "In this section we will learn how to interact with the GPT models by OpenAI. Since July 2023, OpenAI have updated their API to focus on their \"Chat Completions\" API, as opposed to just completing a text input (also a sign of how far we've come with language models)!.\n",
        "\n",
        "What is going on here with these kinds of models? They are state-less, memory-less, generative language models that have been trained with unsupervised learning, supervised learning, and potentially reinforcement learning with human feedback - meaning that they not only have the raw knowledge, but also the ability to recall and manipulate that knowledge into a form useful for us.\n",
        "\n",
        "When we're chatting with the model on the OpenAI webpage's API, what's happening is that they are using a version of the API underneath it. They are setting a context to the model (which comes through the \"system\" content), retreiving a response, and sending it back to us. It appears that the model has a working memory of the conversation - but in fact, every new message we type, has the previous chat appended to it as context, and then sent back.\n",
        "\n",
        "So what we will do now is see how this looks like internally, with the code below. We are using GPT-3.5  (the first Chat-GPT)because it is cheaper - but feel free to go all in and grab GPT-4, a superior model (but note that it will add up!)\n",
        "\n",
        "Our first step is to setup messages - which involve a dictionary that sets up a role and content. We will see a very simple use case here."
      ],
      "metadata": {
        "id": "vRSdq9w7scnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "qoUUi6T7-w_9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    api_key=openai.api_key,\n",
        ")"
      ],
      "metadata": {
        "id": "nmm7pJlX9_ai"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What are some things that go well with toast in the morning?\"}]"
      ],
      "metadata": {
        "id": "6W0sj5LJVQZr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response =  client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=messages)"
      ],
      "metadata": {
        "id": "VqapekgpsfHb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "b4131337-403b-4402-c521-95b5fb6e6517"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-d55b4d55d864>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 659\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    660\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         )\n\u001b[0;32m-> 1180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 869\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    870\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    946\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    994\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    946\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    994\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That bit of code would take a few seconds (or more depending on server time), but you would then have your responses. Note that we used the most simple version in this bit of code. We will expand on the selection of other hyperparameters in code to come. Before that, let's have a look at the object returned."
      ],
      "metadata": {
        "id": "uHUZ_ELOg5cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "Yo_Gz1F5hGjn",
        "outputId": "bbcfc521-d5d4-4298-c5f1-2222b7cf3e67"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'response' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ab0153f39f33>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we see an ID, the object, model information, and then maybe what we are most interested in - the response, under \"choices\". We also see some usage statistics on how many tokens were used. Let's look at the response more closely."
      ],
      "metadata": {
        "id": "ysOn2GujhMMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8yXTTP5jV5T",
        "outputId": "3357dcb3-6046-4586-94ce-7ecf15c099ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='There are various delicious options to pair with toast for a satisfying breakfast in the morning. Here are some suggestions:\\n\\n1. Butter and Jam/Preserves: Classic combination of butter and your favorite flavor of jam or preserves like strawberry, raspberry, or apricot.\\n\\n2. Avocado: Top your toast with smashed avocado, salt, pepper, and maybe a drizzle of lemon juice for a creamy and nutritious option.\\n\\n3. Scrambled/Poached Eggs: Enjoy your toast with some fluffy scrambled or perfectly poached eggs, either on the side or as a topping.\\n\\n4. Cream Cheese and Smoked Salmon: Spread a layer of cream cheese on your toast, then add some smoked salmon on top for a delicious, savory treat.\\n\\n5. Peanut Butter and Sliced Banana: Spread peanut butter on your toast and add some sliced bananas on top for a sweet and protein-packed combination.\\n\\n6. Greek Yogurt and Berries: Slather some Greek yogurt on your toast and add a mix of fresh berries like strawberries, blueberries, or raspberries for a healthy and refreshing topping.\\n\\n7. Bacon and Fried Egg: Cook some bacon and a fried egg, then stack them on your toast for a hearty and protein-rich breakfast.\\n\\n8. Cheese and Tomato: Sprinkle grated cheese on your toast and add some sliced tomatoes for a quick and tasty open-faced sandwich.\\n\\n9. Nutella and Sliced Strawberries: Spread Nutella on your toast and layer it with fresh sliced strawberries for a deliciously sweet morning treat.\\n\\n10. Hummus and Vegetables: Spread hummus on your toast and top it with your favorite veggies like cucumber, sliced bell peppers, or cherry tomatoes for a light and refreshing option.\\n\\nRemember, these are just a few ideas, and you can get creative with your preferences and dietary restrictions to enjoy the perfect toast pairing in the morning!', role='assistant', function_call=None, tool_calls=None))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we see a role (the model, assistant) and content."
      ],
      "metadata": {
        "id": "UO63WMd3kDn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "8p_Niovdl0eW",
        "outputId": "2e1b869a-52ad-4fca-8e8f-890f455a18d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are several things that go well with toast in the morning. Here are some popular options:\\n\\n1. Butter or Margarine: Classic and simple, spreading butter or margarine on toast is a popular choice.\\n2. Jam, Jelly, or Preserves: Sweet spreads like strawberry jam, grape jelly, or orange marmalade add a burst of flavor to toast.\\n3. Peanut Butter or Nut Butter: Creamy peanut butter, almond butter, or cashew butter are protein-rich spreads that pair nicely with toast.\\n4. Honey: Drizzling honey over warm toast brings a natural sweetness.\\n5. Avocado: Mashed avocado with a sprinkle of salt, pepper, and some optional toppings like sliced tomatoes or red pepper flakes make a nutritious and delicious toast topping.\\n6. Cream Cheese: Smooth and tangy cream cheese adds a creamy element to toast, which can be enhanced with additional toppings like smoked salmon, cucumber slices, or everything bagel seasoning.\\n7. Poached or Scrambled Eggs: Toast makes a great base for eggs, either poached or scrambled.\\n8. Sliced Cheese: Adding a slice of cheese, such as cheddar, Swiss, or mozzarella, to warm toast creates a simple and tasty combination.\\n9. Sliced Fruits: Sliced bananas, berries, or peaches can be placed on top of toast for a refreshing and nutritious start to the day.\\n10. Breakfast Meats: Toast can be used as a base for cooked breakfast meats like bacon, ham, or sausage to create a hearty morning sandwich.\\n\\nFeel free to mix and match these options to discover your favorite breakfast combo!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great - we see a coherent and high quality response for what to eat with toast! So now, what if this is a regular task we wish to perform -- ask ChatGPT about food suggestions -- but we are vegetarian, and want the model to remember that as we move forward?\n",
        "\n",
        "And what if we like our food suggestion bots to talk only like a charicatured pirate?\n",
        "\n",
        "Both (and more) are possible, and we will see how to do this in the coming section."
      ],
      "metadata": {
        "id": "Z1yYPHPll6ij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Programming your model - personalities and prompts\n",
        "\n",
        "We mentioned how a core aspect of how these models effectively work as chat bots is the ability to append a \"context\" embedding. For example, if you are using the OpenAI GUI, you have the option to \"let the model know anything about you\", as well as give instructions on how you want the model to respond. What is likely happening under the hood is a way of passing this on as an embedding to the model, which is itself often further tuned with RLHF (Reinforcement Learning with Human Feedback) to parse the context embedding sufficiently well to keep it in mind for the response.\n",
        "\n",
        "As we will see in later notebook examples in this notebook, it is possible to use the API to tap into this functionality - and effectively be able to program a \"personality\" into your model, or give it vital context to remember when responding to you. We illustrate this quite simply with our same breakfast model, this time reminding it that you are vegetarian."
      ],
      "metadata": {
        "id": "PYeAWS27siOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"system\", \"content\": \"You are my breakfast assistant. Don't forget that I am a vegetarian.\"},\n",
        "            {\"role\": \"user\", \"content\": \"What are some things that go well with toast in the morning?\"}]"
      ],
      "metadata": {
        "id": "q7vT0J83kdjq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "0zgW2Q09mmn2",
        "outputId": "078c642b-e57b-4217-f799-121c034ad9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As a vegetarian, there are plenty of delicious options to enjoy with toast in the morning. Here are some ideas:\\n\\n1. Avocado slices: Spread mashed avocado on your toast for a creamy and healthy option. You can also season it with salt, pepper, and lemon juice for added flavor.\\n\\n2. Fresh fruits: Top your toast with slices of fruits like strawberries, bananas, or blueberries for a refreshing and sweet treat.\\n\\n3. Nut butter: Spread some peanut butter, almond butter, or cashew butter on your toast for a protein-rich topping. You can also add sliced bananas or a drizzle of honey for extra taste.\\n\\n4. Hummus: For a savory option, spread hummus on your toast. You can add cucumber slices, cherry tomatoes, or olives on top for more flavor.\\n\\n5. Veggie scramble: Prepare a delicious veggie scramble with ingredients like bell peppers, onions, mushrooms, and spinach. You can then spoon it onto your toast for a filling and nutritious breakfast.\\n\\n6. Vegan cream cheese: Look for vegan cream cheese options and spread it on your toast. You can also add sliced tomatoes or fresh herbs, such as basil or dill.\\n\\n7. Coconut yogurt: If you enjoy a creamy and tangy topping, try coconut yogurt on your toast. It pairs well with sliced almonds, chia seeds, or a drizzle of maple syrup.\\n\\nRemember to experiment with different toppings and combinations to find your favorite morning toast creation!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Now as long as we need food advice, as long as throw in the \"system\" role to remember your preferences, it will take that into account. In practice it is appending the embedding of the context message to the first pass you send over.\n",
        "\n",
        "This is one style of doing \"personalities\" with prompts. The other is to merely add text before your message begins to align the model to the results you require. Different models will respond differently to prompts. Here is an article from OpenAI on best practices for prompt engineering for its models.\n",
        "\n",
        "https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api"
      ],
      "metadata": {
        "id": "RtvAZr7QnJ3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">*Exercise 1*</font>\n",
        "\n",
        "<font color=\"red\">As this week's challeging questions asks, we'd like you to think how LLM can help your final project.  Try to use the OpenAI API to analyze a small-sized dataset (Remember to monitor API use on your OpenAI account!). The data could involve a sample from the dataset you are preparing for your final project or some others. If it's going be a conventional task like classification, compare and see how it could beat (or be defeated by) other algorithms you have used in previous weeks. If it's a special task that you cannot find a learned algorithm to compare with, evaluate its performance on your own and explore whether you can improve its performance by changing hyperparameters(see [here](https://platform.openai.com/docs/api-reference/chat/create)), the prompt, etc."
      ],
      "metadata": {
        "id": "QERxEz3dmSc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I decided to use Data visualization in 2D to analyze the \"board\" distribution in my database.\n",
        "The problem I encountered was that during the process I discovered that this function is only applicable to numerical content, so I converted the board name into a numerical value during the process.\n"
      ],
      "metadata": {
        "id": "vLU3Pvt7zYHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = \"text-embedding-3-small\"\n",
        "embedding_encoding = \"cl100k_base\"\n",
        "max_tokens = 800  # the maximum for text-embedding-3-small is 8191"
      ],
      "metadata": {
        "id": "zwpH9BUlnv7P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "!pip install utils\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cqu5pkKsxYJ",
        "outputId": "e4a6d34e-e8b2-4bf5-c2a7-8346f7cb7d98"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.6.0\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.2.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: utils\n",
            "  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13905 sha256=64140367a9c88fb28f9a867f448c789ef473c1e5c8812f8bbd5bdbf17d9f5bb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/39/f5/9d0ca31dba85773ececf0a7f5469f18810e1c8a8ed9da28ca7\n",
            "Successfully built utils\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n"
      ],
      "metadata": {
        "id": "s_2uLoGIrsUH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/SOCI40133/PTTdata3.csv\")\n",
        "df = df.rename(columns={'作者': 'user', '看板': 'board', '標題': 'title', '日期': 'date', '類型': 'type', '內文': 'text'})\n",
        "matrix = df[['board']].to_numpy()"
      ],
      "metadata": {
        "id": "sCBGvVghxP79"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_boards = df['board'].unique()\n",
        "print(unique_boards)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq-trJ7hybx9",
        "outputId": "33abfdcb-3833-4fc0-df73-6c2718e500fd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Boy-Girl' 'C_Chat' 'Gossiping' 'HatePolitics' 'Marginalman']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建映射字典，将板块内容映射为指定的数值\n",
        "board_mapping = {'Boy-Girl': 1, 'C_Chat': 2, 'Gossiping': 3, 'HatePolitics': 4, 'Marginalman': 5}\n",
        "\n",
        "# 使用 replace() 函数进行映射\n",
        "df['board'] = df['board'].replace(board_mapping)\n"
      ],
      "metadata": {
        "id": "4yOaiJcDytsd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Create a t-SNE model\n",
        "tsne = TSNE(n_components=2, perplexity=15, random_state=42, init='random', learning_rate=200)\n",
        "\n"
      ],
      "metadata": {
        "id": "JeizlMi-yGQH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and transform the data\n",
        "vis_dims = tsne.fit_transform(df[['board']])"
      ],
      "metadata": {
        "id": "IkYs4aq51Wc-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the x and y coordinates\n",
        "x = vis_dims[:, 0]\n",
        "y = vis_dims[:, 1]\n",
        "\n",
        "# Get the counts for each board for the sizing of the points\n",
        "board_counts = df['board'].value_counts()\n",
        "sizes = [board_counts[val] for val in df['board']]\n",
        "\n",
        "# Define your colors - you can adjust these to match the first plot\n",
        "colors = [\"red\", \"darkorange\", \"gold\", \"turquoise\", \"darkgreen\"]\n",
        "\n",
        "# Create a colormap\n",
        "colormap = matplotlib.colors.ListedColormap(colors)\n",
        "\n",
        "# Scatter plot\n",
        "plt.scatter(x, y, c=df['board'], cmap=colormap, s=sizes, alpha=0.3) # Adjust alpha to match the opacity in your first plot\n",
        "\n",
        "# Title and labels\n",
        "plt.title(\"Board Content Visualized using t-SNE\")\n",
        "plt.xlabel(\"t-SNE Component 1\")\n",
        "plt.ylabel(\"t-SNE Component 2\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "EPKVtAQ32rpo",
        "outputId": "7dd33388-5221-42bd-d12e-7f8847fe8f54"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning a local model - LLaMa 2\n",
        "\n",
        "We would want to provide you with an example of fine-tuning an LLM, but thist task can be computationally expensive, and so we will use the LoRA (a low-rank adaptation) copy of Stanford's Alpaca, a slimmed down fork of LLaMa2, for tuning: https://github.com/TianyiPeng/Colab_for_Alpaca_Lora\n",
        "\n",
        "Note: In order to run the llama2-7b version, use A100 (on Colab) or better. Consider that A100 costs 13.08 computing units per hour, which is expensive. Take that in mind!"
      ],
      "metadata": {
        "id": "3tvSs0sYEnWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install accelerate peft bitsandbytes transformers trl"
      ],
      "metadata": {
        "id": "9yGDGasIEocg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip uninstall datasets transformers pyarrow\n",
        "%pip install datasets transformers pyarrow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlcHii0J6dlc",
        "outputId": "f07d59f1-9792-47ad-db33-bf2f7216fc33"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: datasets 2.17.0\n",
            "Uninstalling datasets-2.17.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/datasets-cli\n",
            "    /usr/local/lib/python3.10/dist-packages/datasets-2.17.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/datasets/*\n",
            "Proceed (Y/n)? \u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/uninstall.py\", line 105, in run\n",
            "    uninstall_pathset = req.uninstall(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_install.py\", line 680, in uninstall\n",
            "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 375, in remove\n",
            "    if auto_confirm or self._allowed_to_proceed(verbose):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 415, in _allowed_to_proceed\n",
            "    return ask(\"Proceed (Y/n)? \", (\"y\", \"n\", \"\")) != \"n\"\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/misc.py\", line 192, in ask\n",
            "    response = input(message)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T15:37:58.181259Z",
          "iopub.execute_input": "2023-10-10T15:37:58.181860Z",
          "iopub.status.idle": "2023-10-10T15:38:13.836341Z",
          "shell.execute_reply.started": "2023-10-10T15:37:58.181823Z",
          "shell.execute_reply": "2023-10-10T15:38:13.835264Z"
        },
        "trusted": true,
        "id": "5o3OgCMdRGgp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Config"
      ],
      "metadata": {
        "id": "MlY9awbhRGgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kHk9HmL3prb",
        "outputId": "400a9f9b-97b8-479f-a3d8-59e31cef4168"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "gIKfDKW03s2T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model from Hugging Face hub\n",
        "base_model = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# New instruction dataset\n",
        "guanaco_dataset = \"mlabonne/guanaco-llama2-1k\"\n",
        "\n",
        "# Fine-tuned model\n",
        "new_model = \"llama-2-7b-chat-guanaco\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T15:38:13.838653Z",
          "iopub.execute_input": "2023-10-10T15:38:13.839277Z",
          "iopub.status.idle": "2023-10-10T15:38:13.844665Z",
          "shell.execute_reply.started": "2023-10-10T15:38:13.839239Z",
          "shell.execute_reply": "2023-10-10T15:38:13.843651Z"
        },
        "trusted": true,
        "id": "P5XFMMaCRGgq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's select the dataset with which to fine-tune the model."
      ],
      "metadata": {
        "id": "gx1YvCk3NqGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(guanaco_dataset, split=\"train\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T14:18:02.844995Z",
          "iopub.execute_input": "2023-10-10T14:18:02.845638Z",
          "iopub.status.idle": "2023-10-10T14:18:03.836272Z",
          "shell.execute_reply.started": "2023-10-10T14:18:02.845607Z",
          "shell.execute_reply": "2023-10-10T14:18:03.835367Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268,
          "referenced_widgets": [
            "3195d060677547e582c46755719a8c25",
            "d06731e2e6e442378266602536f597ae",
            "b4d9861e6204499baaaa7a2bd1adccda",
            "ecc888838b664d1d8e09afb60e4c3954",
            "13669450065d4ee1b9fb10b5edfd1c96",
            "f6160a289fa24b77ab45134a2657726e",
            "4c9b853d284a4370aa3fdccd34633318",
            "8a2b2b237d07422586ae6877b3330e35",
            "cb5384df4f474744b10b77f8c2bd4bf3",
            "095eee3e07d2412fa8e210f07f51f221",
            "db8b6b797a784eecac0de5ac8b870045",
            "825b5b9c3fb045dfac34160260c0695b",
            "f0b78ce9fd534ab3bd57f241f151c281",
            "6d540977e6e8468f89a6fe279976173e",
            "daadcc1a78704ec1b567260e85c71056",
            "19dbc82433194829941c476b2f34bb13",
            "f84739e453564847981a0021a6743d13",
            "faa39ff76659407298db842b3c0d2118",
            "a051848239b1490da622a68b18566813",
            "e3c3a0f295ce4f4095bbb66225894ef8",
            "02d85cc6b89147d1b1c6a25fb4154209",
            "1e2ab858f54b454abb0bb0854d6c1af6",
            "7d9bb3c92a90422485c69673dc7683be",
            "4c2f257e75644e67882f4af5894bfe40",
            "87bef2d6441f40f288f29e8b278e97f6",
            "99652f3ab9434ecbb13b1e23f053dfbc",
            "4be8e61d6c5142ed97428a9d4eebae8d",
            "a97df38ca01346b496f4ef4720fe64bf",
            "361400afbe9e492abe7c891014b5b1a9",
            "3db4418addae457abc607aaffea29f8a",
            "5f99ffe443984b2d993bac7c563abfab",
            "3a11a24b9f9a4cc29301084d53ac60c2",
            "c74fda8085df49f2ac9354ebfa5af430"
          ]
        },
        "id": "GVy72cDyRGgr",
        "outputId": "d5e573dc-ea72-41b9-c1bb-aff906773fb8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3195d060677547e582c46755719a8c25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/967k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "825b5b9c3fb045dfac34160260c0695b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d9bb3c92a90422485c69673dc7683be"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that dataset is a special class created by HuggingFace for interaciting models on there with their APIs. It looks like python's built-in list and dictionary and but is slightly different."
      ],
      "metadata": {
        "id": "tb6r4toBS4qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sl03xtdSzjO",
        "outputId": "f0ff9c16-cede-4be4-d947-58f673453f86"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjJpo26hTmn9",
        "outputId": "08a734af-2adb-4c1e-8057-7372ff857b1f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this dataset, there is a question [INST]/[/INST] followed by an answer. Alternatively, you could simply include text, as describe in the HuggingFace link below."
      ],
      "metadata": {
        "id": "SWnXKpRAVj7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tEZWBNlTPOG",
        "outputId": "c94f1bdd-5e63-4335-97d2-36f08b517554"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': '<s>[INST] Me gradué hace poco de la carrera de medicina ¿Me podrías aconsejar para conseguir rápidamente un puesto de trabajo? [/INST] Esto vale tanto para médicos como para cualquier otra profesión tras finalizar los estudios aniversarios y mi consejo sería preguntar a cuántas personas haya conocido mejor. En este caso, mi primera opción sería hablar con otros profesionales médicos, echar currículos en hospitales y cualquier centro de salud. En paralelo, trabajaría por mejorar mi marca personal como médico mediante un blog o formas digitales de comunicación como los vídeos. Y, para mejorar las posibilidades de encontrar trabajo, también participaría en congresos y encuentros para conseguir más contactos. Y, además de todo lo anterior, seguiría estudiando para presentarme a las oposiciones y ejercer la medicina en el sector público de mi país. </s>'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Many of you may want to construct a dataset class instance using your local dataset: refer to [this](https://huggingface.co/docs/datasets/en/create_dataset)**"
      ],
      "metadata": {
        "id": "p7q7yNDATxf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_dtype = getattr(torch, \"float16\")\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T14:18:03.837790Z",
          "iopub.execute_input": "2023-10-10T14:18:03.838430Z",
          "iopub.status.idle": "2023-10-10T14:18:03.844453Z",
          "shell.execute_reply.started": "2023-10-10T14:18:03.838398Z",
          "shell.execute_reply": "2023-10-10T14:18:03.843603Z"
        },
        "trusted": true,
        "id": "h2kNh-P7RGgr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load base model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    quantization_config=quant_config,\n",
        "    device_map={\"\": 0}\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T14:18:03.845777Z",
          "iopub.execute_input": "2023-10-10T14:18:03.846115Z",
          "iopub.status.idle": "2023-10-10T14:19:48.710661Z",
          "shell.execute_reply.started": "2023-10-10T14:18:03.846076Z",
          "shell.execute_reply": "2023-10-10T14:19:48.709756Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "Nkx6I_K8RGgr",
        "outputId": "25ca8fcc-4e5a-48e2-c4df-1fa44d72e05a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes` ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-70dfbfc17fb4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load base model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquant_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload_in_8bit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mload_in_4bit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_bitsandbytes_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2714\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   2715\u001b[0m                     \u001b[0;34m\"Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2716\u001b[0m                     \u001b[0;34m\" bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes` ",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load LLaMA tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T14:19:48.714585Z",
          "iopub.execute_input": "2023-10-10T14:19:48.716567Z",
          "iopub.status.idle": "2023-10-10T14:19:48.898520Z",
          "shell.execute_reply.started": "2023-10-10T14:19:48.716525Z",
          "shell.execute_reply": "2023-10-10T14:19:48.897577Z"
        },
        "trusted": true,
        "id": "wW0-hLYuRGgr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "2757493812ff4bdeb9cd0c51c8693c73",
            "283469b00c594c82b59721450a63980e",
            "31d6232fd5b54b3088fb1cce275eeec5",
            "1c7ebd9e23964124bc99ba1a03e41e2c",
            "992349ed0bec42d5bde6ca7234d3689b",
            "1fcfd4ce5cb746e186ea1dfc3ce142e3",
            "79f852f0f823428d95f2002f27b08cf2",
            "45bb612ad0214020b9ff2599479f4fd9",
            "8c824f0331c6480c9bdb40b135b2acb9",
            "866f97c530794ac18ea0259676cb97ef",
            "844e0c4fde5942469ddc9d56100c8793",
            "bcb6ac480d57422c903f0950363f58f0",
            "3695740d182c4cec8bc0cc69483a570d",
            "b58a788c36c54833beaaea91c05eda07",
            "417389f6b1e64a30aa9d2a5d71ff5cd8",
            "4ca4d22880d24501a10c69fbf68dd26f",
            "c36286934adf4213a0168bff5049db42",
            "98bd6cbd492645a4a71d8221b41c5d9a",
            "4976d3e753ef4832896f7bbe900c4d86",
            "e3a403937d6a4f99a8f270ddad7ce159",
            "fb35f98aba944088ba97e5e554235ad3",
            "c21a3945e1864624b329af86cf910c52",
            "4e85599c906f4a17883d4fe4020db531",
            "d35eb31a6d03453bb9f45e07066330e0",
            "c7644ada1bc14784bf46443d2c90825e",
            "197fd6c24d30467ca0f59c838259e91f",
            "ec5636b05e174a518f3c2e318372c737",
            "a190b57045df4d7493742d87df86a6d9",
            "6013d8de801045b9bd811ff7b816ba38",
            "e987a5ac43474352992c913bd4aaae69",
            "8f1382a64fca4da8ad73067254e821de",
            "245b2f83ca8748548dbd0491c9b43b56",
            "140fedb9f1d840cf86085065d72afbf2",
            "b3c0d19dca6c4e59bd825c7033ab2edb",
            "ac24146cddb149599ae04a79b88a5b2a",
            "024f00bab6e84972ba122c72c70447bc",
            "8fc4d59609d54b469ecc8dd8e3cc11d5",
            "a2fa29c0e468467fa4a88fe557bfd43e",
            "b7e92be2f7914fc7a3f87acab17ec9c7",
            "ee76273f4f754dc089929e54d363a7b3",
            "a500de51cec04da79dee3281be27b225",
            "72b1b57dea954fa982a642313cdb93cc",
            "5f0903cc95764cbe8f08dd4cc61f7727",
            "439252676b8443c08fc3739fbfb5902c",
            "6f084daa55f142b1bd9a5566a60971bb",
            "a6787aaa527145e191fe5e160192f739",
            "e13aed7083724d93b9ea6e63f53c3620",
            "854161cdba924797a9f473a3907a0f72",
            "b650237bf7c04e29a6ba33166ee4993b",
            "3ae8a89e95fb469fa06470257f1cb0a0",
            "faf194e0329a4764acba4670d6725ce7",
            "ed14e56b7f17464ca6c3f5001d6b5437",
            "2f62e7de9c7848b38b4d2e1944eb748a",
            "33293d5c2ba941418fb07db7dd00fe3a",
            "8ab78d78b1f543fba77e820629f2717f"
          ]
        },
        "outputId": "c19ce754-5646-497a-8a28-f0296fa68eb3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2757493812ff4bdeb9cd0c51c8693c73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcb6ac480d57422c903f0950363f58f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e85599c906f4a17883d4fe4020db531"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3c0d19dca6c4e59bd825c7033ab2edb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f084daa55f142b1bd9a5566a60971bb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load LoRA configuration\n",
        "peft_args = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=32, # the rank of the adaptation\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T14:19:48.902943Z",
          "iopub.execute_input": "2023-10-10T14:19:48.905085Z",
          "iopub.status.idle": "2023-10-10T14:19:48.911156Z",
          "shell.execute_reply.started": "2023-10-10T14:19:48.905051Z",
          "shell.execute_reply": "2023-10-10T14:19:48.910364Z"
        },
        "trusted": true,
        "id": "7NoI2dXlRGgt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set training parameters\n",
        "training_params = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=1,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=25,\n",
        "    logging_steps=25,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=True, # speed up\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    report_to=\"tensorboard\"\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T14:19:48.915732Z",
          "iopub.execute_input": "2023-10-10T14:19:48.918265Z",
          "iopub.status.idle": "2023-10-10T14:19:48.927736Z",
          "shell.execute_reply.started": "2023-10-10T14:19:48.918228Z",
          "shell.execute_reply": "2023-10-10T14:19:48.926787Z"
        },
        "trusted": true,
        "id": "d3AHk9QARGgu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "78009cd5-a31e-4ba5-b9ac-2f23b9c19bb9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4dad2c7d7d11>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set training parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m training_params = TrainingArguments(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./results\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memo...\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_full_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         ):\n\u001b[0;32m-> 1448\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1449\u001b[0m                 \u001b[0;34m\"FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m                 \u001b[0;34m\" (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set supervised fine-tuning parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_args,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=None,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_params,\n",
        "    packing=False,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T14:19:48.934464Z",
          "iopub.execute_input": "2023-10-10T14:19:48.936728Z",
          "iopub.status.idle": "2023-10-10T14:20:01.059206Z",
          "shell.execute_reply.started": "2023-10-10T14:19:48.936694Z",
          "shell.execute_reply": "2023-10-10T14:20:01.058237Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "N7RMb3UHRGgu",
        "outputId": "b7bd9ac6-4c25-41d3-c1ce-0814a06e9cad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ce188ae2072b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set supervised fine-tuning parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m trainer = SFTTrainer(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpeft_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpeft_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T14:20:01.060526Z",
          "iopub.execute_input": "2023-10-10T14:20:01.061527Z",
          "iopub.status.idle": "2023-10-10T15:03:26.789624Z",
          "shell.execute_reply.started": "2023-10-10T14:20:01.061494Z",
          "shell.execute_reply": "2023-10-10T15:03:26.788645Z"
        },
        "trusted": true,
        "id": "0Y99UKM_RGgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained model\n",
        "trainer.model.save_pretrained(new_model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T15:03:26.791038Z",
          "iopub.execute_input": "2023-10-10T15:03:26.791392Z",
          "iopub.status.idle": "2023-10-10T15:03:27.030591Z",
          "shell.execute_reply.started": "2023-10-10T15:03:26.791360Z",
          "shell.execute_reply": "2023-10-10T15:03:27.029240Z"
        },
        "trusted": true,
        "id": "qL5i358PRGgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save tokenizer\n",
        "trainer.tokenizer.save_pretrained(new_model)"
      ],
      "metadata": {
        "id": "xSIK3z-lG78N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "rDKoF55vBXnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "6E3ZUuQ3BBrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill 26235"
      ],
      "metadata": {
        "id": "xpEG9q2gpwrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboard import notebook\n",
        "log_dir = \"results/runs\"\n",
        "notebook.start(\"--logdir {} --port 4000\".format(log_dir))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T15:31:13.007046Z",
          "iopub.execute_input": "2023-10-10T15:31:13.007547Z",
          "iopub.status.idle": "2023-10-10T15:31:17.529921Z",
          "shell.execute_reply.started": "2023-10-10T15:31:13.007516Z",
          "shell.execute_reply": "2023-10-10T15:31:17.528868Z"
        },
        "trusted": true,
        "id": "fYZzxh_GRGgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TextGenerationPipeline\n",
        "\n",
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "# Assuming 'new_model' is defined and contains the name of your model directory\n",
        "model_path = f'/content/{new_model}'\n",
        "\n",
        "# Load the model and tokenizer directly\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Create the text generation pipeline manually\n",
        "pipe = TextGenerationPipeline(model=model, tokenizer=tokenizer, task=\"text-generation\", max_length=200)\n",
        "\n",
        "# Run text generation\n",
        "prompt = \"Who is Leonardo Da Vinci?\"\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T15:06:41.101240Z",
          "iopub.execute_input": "2023-10-10T15:06:41.101961Z",
          "iopub.status.idle": "2023-10-10T15:08:19.273722Z",
          "shell.execute_reply.started": "2023-10-10T15:06:41.101922Z",
          "shell.execute_reply": "2023-10-10T15:08:19.272722Z"
        },
        "trusted": true,
        "id": "G79xEhI-RGgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is Datacamp Career track?\"\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T15:08:19.275718Z",
          "iopub.execute_input": "2023-10-10T15:08:19.276056Z",
          "iopub.status.idle": "2023-10-10T15:09:57.738857Z",
          "shell.execute_reply.started": "2023-10-10T15:08:19.276024Z",
          "shell.execute_reply": "2023-10-10T15:09:57.737859Z"
        },
        "trusted": true,
        "id": "-y2f991oRGgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks great! If you'd like to push your fine-tuned model to Huggingface:"
      ],
      "metadata": {
        "id": "rcn2BwVzH4-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "bDS9aQfYWXul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload model in FP16 and merge it with LoRA weights\n",
        "load_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map={\"\": 0},\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(load_model, new_model)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "# Reload tokenizer to save it\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "P3v9yuS3sTnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(new_model, use_temp_dir=False)\n",
        "tokenizer.push_to_hub(new_model, use_temp_dir=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T15:43:44.442024Z",
          "iopub.execute_input": "2023-10-10T15:43:44.442442Z",
          "iopub.status.idle": "2023-10-10T15:43:49.459283Z",
          "shell.execute_reply.started": "2023-10-10T15:43:44.442412Z",
          "shell.execute_reply": "2023-10-10T15:43:49.457443Z"
        },
        "trusted": true,
        "id": "2CB4xCqWRGgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">*Exercise 2*</font>\n",
        "\n",
        "<font color=\"red\">Fine-tune an LLM. You can either use the model (llama-2-7b) in the example code or find another open-source LLM. You may use datasets provided by HuggingFace or a dataset you collect from somewhere else (e.g., for your final project). If the task happens to be the same as in exercise 1, compare the performance between the OpenAI LLM and your fine-tuned LLM. Also compare the performance between the \"vanilla\" un-tuned and the fine-tuned LLM."
      ],
      "metadata": {
        "id": "kFzkC2tGnJwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose to use another LLM: [TowerInstruct-13B](https://huggingface.co/LoneStriker/TowerInstruct-13B-v0.1-GGUF) and translate my final project data from Chinese to English"
      ],
      "metadata": {
        "id": "Hua4U6hF-cWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IJTMb38SKjb",
        "outputId": "68e39505-078a-4876-c57a-fd1e02bfd267"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall numpy\n",
        "#!pip install --upgrade numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV5Jj0PcTDYO",
        "outputId": "6b838873-ded0-4ef1-9bf0-009c38e3977d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy-1.26.4.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libopenblas64_p-r0-0cf96a72.3.23.dev.so\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall transformers\n",
        "#!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "G-YR0a1AU74q",
        "outputId": "3da4ed76-38bb-4ccf-a130-ab58eb535128"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.35.2\n",
            "Uninstalling transformers-4.35.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/transformers-cli\n",
            "    /usr/local/lib/python3.10/dist-packages/transformers-4.35.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/transformers/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled transformers-4.35.2\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-4.37.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import re\n",
        "from transformers import pipeline, TrainingArguments, Trainer, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RrR4qao_Xju0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "K7ClQ5DNLm1N"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "UUPdwetQSm9o"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"/content/drive/MyDrive/SOCI40133/PTTdata3.csv\")\n",
        "df2.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "1D-zuWE2XxOz",
        "outputId": "8a605e86-c40b-4ce5-ae62-035c62bfcaec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     作者        看板                     標題       日期  類型  \\\n",
              "0        sky2030 (無業遊民)  Boy-Girl          [心情] 出國巧遇台女趣事  2023-12  心情   \n",
              "1  iamjimhaha (磨刀霍霍向肥羊)  Boy-Girl  [討論] 找台女不找外配是不是因為不想養？  2023-12  討論   \n",
              "\n",
              "                                                  內文  \n",
              "0  最近常跟朋友一起跑胡志明，河內玩\\n\\n玩什麼就不要問了\\n\\n某天晚上 剛好在一間麵店吃飯...  \n",
              "1  \\n發現有些台男\\n明明就找不到對象\\n卻不願意找外籍\\n\\n是否是因為找台女還能要求有工作...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0956b35-ee42-4cb8-902f-3e5fa3c08f68\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>作者</th>\n",
              "      <th>看板</th>\n",
              "      <th>標題</th>\n",
              "      <th>日期</th>\n",
              "      <th>類型</th>\n",
              "      <th>內文</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sky2030 (無業遊民)</td>\n",
              "      <td>Boy-Girl</td>\n",
              "      <td>[心情] 出國巧遇台女趣事</td>\n",
              "      <td>2023-12</td>\n",
              "      <td>心情</td>\n",
              "      <td>最近常跟朋友一起跑胡志明，河內玩\\n\\n玩什麼就不要問了\\n\\n某天晚上 剛好在一間麵店吃飯...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>iamjimhaha (磨刀霍霍向肥羊)</td>\n",
              "      <td>Boy-Girl</td>\n",
              "      <td>[討論] 找台女不找外配是不是因為不想養？</td>\n",
              "      <td>2023-12</td>\n",
              "      <td>討論</td>\n",
              "      <td>\\n發現有些台男\\n明明就找不到對象\\n卻不願意找外籍\\n\\n是否是因為找台女還能要求有工作...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0956b35-ee42-4cb8-902f-3e5fa3c08f68')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0956b35-ee42-4cb8-902f-3e5fa3c08f68 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0956b35-ee42-4cb8-902f-3e5fa3c08f68');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e97eb93b-4fc1-4a41-b442-677dd44043d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e97eb93b-4fc1-4a41-b442-677dd44043d1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e97eb93b-4fc1-4a41-b442-677dd44043d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df2.rename(columns={'作者': 'user', '看板': 'board', '標題': 'title', '日期': 'date', '類型': 'type', '內文': 'text'})\n",
        "df2.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "hUSTbYLpad-_",
        "outputId": "a396cf5b-19c2-4331-aaa3-9169ddc49da0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   user     board                  title     date type  \\\n",
              "0        sky2030 (無業遊民)  Boy-Girl          [心情] 出國巧遇台女趣事  2023-12   心情   \n",
              "1  iamjimhaha (磨刀霍霍向肥羊)  Boy-Girl  [討論] 找台女不找外配是不是因為不想養？  2023-12   討論   \n",
              "\n",
              "                                                text  \n",
              "0  最近常跟朋友一起跑胡志明，河內玩\\n\\n玩什麼就不要問了\\n\\n某天晚上 剛好在一間麵店吃飯...  \n",
              "1  \\n發現有些台男\\n明明就找不到對象\\n卻不願意找外籍\\n\\n是否是因為找台女還能要求有工作...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ca950af-6398-4404-8d1f-1250f7c83b8e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>board</th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sky2030 (無業遊民)</td>\n",
              "      <td>Boy-Girl</td>\n",
              "      <td>[心情] 出國巧遇台女趣事</td>\n",
              "      <td>2023-12</td>\n",
              "      <td>心情</td>\n",
              "      <td>最近常跟朋友一起跑胡志明，河內玩\\n\\n玩什麼就不要問了\\n\\n某天晚上 剛好在一間麵店吃飯...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>iamjimhaha (磨刀霍霍向肥羊)</td>\n",
              "      <td>Boy-Girl</td>\n",
              "      <td>[討論] 找台女不找外配是不是因為不想養？</td>\n",
              "      <td>2023-12</td>\n",
              "      <td>討論</td>\n",
              "      <td>\\n發現有些台男\\n明明就找不到對象\\n卻不願意找外籍\\n\\n是否是因為找台女還能要求有工作...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ca950af-6398-4404-8d1f-1250f7c83b8e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ca950af-6398-4404-8d1f-1250f7c83b8e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ca950af-6398-4404-8d1f-1250f7c83b8e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d80e76f6-1650-41db-a0c0-cdb6c1d8f507\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d80e76f6-1650-41db-a0c0-cdb6c1d8f507')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d80e76f6-1650-41db-a0c0-cdb6c1d8f507 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 随机选择10条数据\n",
        "random.seed(42)  # 设置随机种子以确保可重复性\n",
        "df2_sample = df2.sample(n=20)\n",
        "\n",
        "# 选择要翻译的文本\n",
        "data_to_translate = df2_sample['text'].tolist()"
      ],
      "metadata": {
        "id": "O3J6g5FZDLfo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化pipeline\n",
        "pipe = pipeline(\"translation_zh_to_en\", model=\"Helsinki-NLP/opus-mt-zh-en\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404,
          "referenced_widgets": [
            "74f9051e77514e76959d763648871a2a",
            "7541fc22178e45c9805a35e1e0dfb754",
            "0b795527f7394718a011e2a6d74debf7",
            "d7b45d026b6843b4aaec52dd9df1ad9c",
            "72c7dac1792a4338a433874f4341f97d",
            "aec0012b48f24219a83b9efbd193b695",
            "f32d7ab11f9a4edab50ccf89c4632160",
            "e3edb6b2072047539452d56f108d50b0",
            "4dce34e11e6945b2ade0cdcf5ef5d59c",
            "e41015bd4c114ebd97b4687b62cfd2c5",
            "c25bf7c4d11141968b80ccd672a6748f",
            "16c2d87c1d7e4155ab2a3d4a09a25dfb",
            "78e793832387482a8f4ae8d93831921b",
            "c283182ae9d04385a81f019dcba8bed1",
            "d52269f768c541eea982d6e619db4a82",
            "9453673343ac46af80fdf28fd843a770",
            "8d6a2f06855446cd8d93cc6fdfb4bea8",
            "e473dcab40ff45adb10269637341ca94",
            "d9adb94a572847bfb6c3cf3d8369a12c",
            "2383b7b0ae0b4b5986a22d79d99c1eb2",
            "f7b87dd0db984c2299ecabda9e701ac4",
            "ac0a451ca4364b578d07e1f18041258a",
            "129a0b05796047c4b359a5f3680fff13",
            "46a7b9a5108b4f95b938a4cb1e40bb5c",
            "fabab81c3fa443429bd0e436aca2d5f7",
            "412942df3ce044b4a077a6cd6d270719",
            "7c1781cc870243899e6e9b30ad9eddff",
            "e9efeb7597674399b1cb01015a04fa0f",
            "120ee8301c8e44c4a40dedd3f2915f6c",
            "23601eccf891446db24cd29cce69640f",
            "261b6f63d4094c6ea0f7b0dcd7f16365",
            "1f5a656de61245d98c175a43f830ec60",
            "f487af41c1cc43c78a49c7a48c11bf29",
            "6c5b20f0002843b98bbc3fe2a03e4238",
            "8a345f897658488ebc79645ae7365540",
            "e910c3c3523a43e1b668875b41841e99",
            "c96b6b2d938740df809776c5469b95fd",
            "848c6857f20049f98ba0bc3e422695d5",
            "634ab3487beb42078c83dc9a396e449c",
            "0872908c3c8b4583ab7238c0e52015f1",
            "57e0a1fb3c47475f9d44f7cc4dcb9065",
            "b886723f9dee424c85c06e3e675b087d",
            "2f3b76bdab2f438abdc5ed7e87dc7d27",
            "9c19b065be434bf49336234ec4139af9",
            "9e44368c2850403691841c73e3481d65",
            "3aeb9ffae95a452d8f9f9065fcbca1b8",
            "394d350228de44318f14bde71846ee8f",
            "c1f44b7cbbab4c21a99f26ecfb60e831",
            "a5559cf6046047019452696c49a98ea9",
            "4cd1fbaab4694fe88641888cef92da8a",
            "b9d05f0ba20845e792f68251559983a7",
            "1465f3b32ed9418c8bad0cdb571fea26",
            "4097796db0f64ad3b3f5d66da4ff2bf5",
            "0a5bb8eaf44045b4a6f9ecbfc99fd3cc",
            "2ada09345cde46a4abdc9d4a0c419519",
            "be284c0ab4d7416998a9d7cb362cce12",
            "6f2b5eceba164832822370a8e0e7426b",
            "8a1319b0163d4368802176fa9f9bbda9",
            "4d87b7421989454fa654ba2081509a98",
            "fb652148b091443ab92839cbe79f2a81",
            "7401d94da2ff43a1a575fb784d7e187e",
            "7aca9c3215ee42ef926361b4cb8b1bf2",
            "2ce3b025d2f94c33a44a979380ea557f",
            "64a3f5de96c14829bc2290183762adda",
            "ab5d30e4202f4cc5a9feb919d1d36111",
            "217f6e15fae0490da730d5eb3c4342a9",
            "4af47f03aa084856949cbbdde0dc5902",
            "551232dec609492fa88d535500584376",
            "f5d20219b59e40da84d8ffe2562ef4a1",
            "3a06dc5e47894260b3011da9c7747828",
            "f9a304a092e04a65967b3daae1f9283f",
            "a560ae7365314f04a064f1918119bfe8",
            "7a5e627853944f07906583e8816ad654",
            "c8778c0aeb3f4e7faeeef47d35527165",
            "cdbfeaad68d44213b03b2e92a7e65d36",
            "bebf409db3614d0aa47e87d00f0d8477",
            "c4c174c8784b488fbea1bb7e7e46cf30"
          ]
        },
        "id": "nv9hy_7pDOUa",
        "outputId": "c4fb2230-20ad-4756-f954-3123c3b6cefa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74f9051e77514e76959d763648871a2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16c2d87c1d7e4155ab2a3d4a09a25dfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "129a0b05796047c4b359a5f3680fff13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c5b20f0002843b98bbc3fe2a03e4238"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "source.spm:   0%|          | 0.00/805k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e44368c2850403691841c73e3481d65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target.spm:   0%|          | 0.00/807k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be284c0ab4d7416998a9d7cb362cce12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.62M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4af47f03aa084856949cbbdde0dc5902"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 对数据进行翻译\n",
        "translated_data = []\n",
        "for text in data_to_translate:\n",
        "    # 进行翻译\n",
        "    translated_text = pipe(text)[0]['translation_text']\n",
        "    # 添加翻译结果到列表\n",
        "    translated_data.append(translated_text)\n",
        "\n",
        "# 将翻译结果添加到DataFrame的新列中\n",
        "df2_sample['translated_text'] = translated_data\n",
        "\n",
        "# 打印前几行以检查结果\n",
        "print(df2_sample['translated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZIHL4uLDnOF",
        "outputId": "8d68f017-64ef-41a4-a619-bed2a89c1cda"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2543    When you see a lot of 55-year-old girls in Tai...\n",
            "10      It's like this, and I'm surprised to hear it, ...\n",
            "2619    Oh, no, no, no, no, no, no, no, no, no, no, no...\n",
            "2606    It's just, like, it's like, it's like, you kno...\n",
            "2162    Seeing the post on underage sexual behavior, m...\n",
            "67      I don't know why a lot of rich kids like the h...\n",
            "2467    Look at the 31-year-old single-sex girl who sa...\n",
            "2748    On the other hand, it's known that Korea is a ...\n",
            "2319    Oh, no, no, no, no, no, no, no, no, no, no, no...\n",
            "264     It's a two-lit culture, where most people talk...\n",
            "1773    Do you really think 31-year-old bachelors real...\n",
            "634     First of all, it's high house prices, high pri...\n",
            "2062    Seeing the post on underage sexual behavior, m...\n",
            "2826    It's just, like, it's like, it's like, you kno...\n",
            "2098    In October and February of last year, a woman'...\n",
            "1199    Oh, no, no, no, no, no, no, no, no, no, no, no...\n",
            "1680    I don't know where you got the confidence to w...\n",
            "2366    It's just, like, it's like, it's like, you kno...\n",
            "878     In October and February of last year, a woman'...\n",
            "1385    I saw a lot of women supporting iWin, \"How can...\n",
            "Name: translated_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a95a1eec"
      },
      "source": [
        "# Triage Multiple LLMs - FrugalGPT\n",
        "\n",
        "\n",
        "Sometimes you would like to select the right LLM for a job conditional on context-specific performance (e.g., speed and accuracy) or other, task-relevant criteria. For example, many LLMs, including most of those remotely hosted, only allow queries for a fee (e.g., GPT-4, Claude). You might want the best AND cheapest LLM for task. Here we introduce code associated with the [“FrugalGPT”](https://arxiv.org/abs/2305.05176) approach framework proposed by James Zou and colleagues that creates LLM “cascades” to compare sequences of different models, tuning them for performance on a task (e.g., sentiment analysis for a collection of Reddit posts), then evaluating them across the criteria of performance and cost. You can generalize this approach to consider other criteria of relevance (e.g., generation time, performance on multiple separate tasks, etc.). The associated code repository [here](https://github.com/stanford-futuredata/FrugalGPT/blob/main/README.md). (Note that other teams have used LLM “cascades” in a different way, building probabilistic models that to improve on the composition of multiple models, as described further [below](https://model-cascades.github.io/).)\n",
        "\n",
        "The code in this section is lifted from that repository.\n",
        "\n",
        "## FrugalGPT\n",
        "\n",
        "Below, we will demonstrate two techniques offered by FrugalGPT to build cost-efficient LLM applications. The first techniques, LLMforAll, allows the users to query various LLM APIs via a unified inferface. The sceond one, LLMCascade, automates and optimizes the query process given a user-defined budget constraint.\n",
        "\n",
        "NB: You are strongly advised to use accelerated hardware (GPU/TPU) to run this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cea3b2c7"
      },
      "source": [
        "## Installation\n",
        "Let us start by installing FrugalGPT (if you haven't yet!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HR2ppSZw0z-"
      },
      "outputs": [],
      "source": [
        "# set up the environment\n",
        "%%capture\n",
        "! git clone https://github.com/stanford-futuredata/FrugalGPT\n",
        "%cd FrugalGPT\n",
        "! pip install git+https://github.com/stanford-futuredata/FrugalGPT\n",
        "! wget  https://github.com/lchen001/DataHolder/releases/download/v0.0.1/HEADLINES.zip\n",
        "! unzip HEADLINES.zip -d strategy/\n",
        "! rm HEADLINES.zip\n",
        "! wget -P db/ https://github.com/lchen001/DataHolder/releases/download/v0.0.1/HEADLINES.sqlite\n",
        "! wget -P db/ https://github.com/lchen001/DataHolder/releases/download/v0.0.1/qa_cache.sqlite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2777650"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import sys, json, copy\n",
        "import logging\n",
        "logging.disable(logging.CRITICAL)\n",
        "sys.path.append(\"src/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ef14cb0"
      },
      "source": [
        "## Setup\n",
        "Next, let us set up the environment and API keys. You do _not_ need API keys to run the notebook! They are only needed if you want to use FrugalGPT for your own queries.\n",
        "#### NB: _For your own queries, not all API keys are needed, too. If you only want to leverage LLMs from, e.g., OpenAI and AI21, setting up API keys for them is sufficient._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2855163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319,
          "referenced_widgets": [
            "17d81eafe919458b99626f227e54a910",
            "72a68ff3b4af4c548820cb0fd3f36edd",
            "93cd6583036541fa8ebb1ac620e62315",
            "9cf6d750236b4eda8b0944771af5dbf8",
            "0a8d48f37321466e8251bfac7f44893e",
            "d2e7e753387644bf9e2376e35cb3c0f1",
            "9fb225e02b0c49a8811294e01f3f19bb",
            "ef70a3e7219743c3be7e2c71d9ccb37b",
            "84deca5f895248aeaa9ba9e7c6af4ad8",
            "6806ac8599324778a75573df8885dd39",
            "15b103b108f0457288228b748fb43f6e",
            "a79c264515cc411d91f40e0395e90e66",
            "6f5dd7906ee34b4ca05f4c33b42b4e7a",
            "61ebd82167904ebc84d1e64b80462999",
            "0dd26993f7134687bc6ba374eafacad3",
            "043906160f7a4f44887abd2da83c8493",
            "5feb7a90cf6f48778ac9c44360f72c8f",
            "a89b28cfbe2d43d299b94983133c3fe8",
            "af2988e477c2454a9474ad42ed28863e",
            "e3aef47e59a14cd1a062d582c85deafd",
            "e75845daea08437bbe4645afed752f06",
            "888b426834fd419d890caaae1f09ea4a",
            "ab451aa4a5e74ba894ccec0bbcfde412",
            "901c2a35139f4c02882d3727782b328a",
            "60bec483ce894f89b9c3a37db74ba6b3",
            "5cf538fb72f24355918c3b13e95129d2",
            "2e687414d3e6467bb3d888fd3bb48454",
            "586b97c4b1b24e609014f3c673bb3093",
            "50e3886979de4146af3554bf9a4055b8",
            "c2404dc202f248039766e5e3aa88a297",
            "bf273cf4970d4c1c9d2efea2acceb2d6",
            "be71d1d278db493fb62f2a414c5e3ce7",
            "e2a871e1e4b14a02ba3ee342c6f3afec",
            "75f3bd5f2d1d44e89f75ce591bbda94e",
            "50055eb7fb374888bb16ae05f56603b1",
            "c6721882898c41adaafeacefc16d2eb8",
            "0b8d1c49c46741788eedd6bee9df6df1",
            "4d7c2411c2924bb1af02cd6432fee5ab",
            "74003f9d7fb64cc6bab20220475b06ca",
            "ec1ac5a2b837498b8fed37789cae55c0",
            "dbae538e3a3b4ec9a35f049a2fa1ce86",
            "3105ab8e62aa44ad9bf26f20a011f052",
            "8329788566594ac88d337aa0686ea13d",
            "8865b8c5c9474391ac73b0b792d0bbad",
            "d76ea207dd2d48feb5af26d65378374b",
            "a0bc21b41ef44bf989e09a368619331b",
            "0286e3be615c449d99d3d8a32d952377",
            "611bbd07ca5f40b7969382c63c8ee050",
            "1b958afeaf754294859db0719e3d7011",
            "46e32b1a0b30486aa567bfb63eb19a83",
            "132ffff9d0b847b18fc49f271fd607b3",
            "7023ed555d1b4ecbbe51df90ef37d3d1",
            "0f145060f4634324a451571ca3290e1a",
            "773892d093de4128b03c38c061511d70",
            "64bf8191866f4fce8fb06592aedb5efd"
          ]
        },
        "outputId": "3025a1f1-fbfb-44bb-e66a-46247c6eed0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17d81eafe919458b99626f227e54a910"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a79c264515cc411d91f40e0395e90e66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab451aa4a5e74ba894ccec0bbcfde412"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75f3bd5f2d1d44e89f75ce591bbda94e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d76ea207dd2d48feb5af26d65378374b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "supported LLMs: ['textsynth/gptneox_20B', 'textsynth/fairseq_gpt_13B', 'textsynth/gptj_6B', 'openai/text-davinci-002', 'openai/text-davinci-003', 'openai/text-curie-001', 'openai/text-babbage-001', 'openai/text-ada-001', 'openaichat/gpt-3.5-turbo', 'openaichat/gpt-4', 'ai21/j1-jumbo', 'ai21/j1-grande', 'ai21/j1-large', 'ai21/j2-ultra', 'ai21/j2-mid', 'ai21/j2-light', 'cohere/command', 'cohere/base', 'cohere/xlarge', 'cohere/medium', 'anthropic/claude-1', 'anthropic/claude-instant-1', 'anthropic/claude-1-100k']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'\n",
        "os.environ['AI21_STUDIO_API_KEY'] = 'AI21_STUDIO_API_KEY'\n",
        "os.environ['COHERE_STUDIO_API_KEY'] = 'COHERE_STUDIO_API_KEY'\n",
        "os.environ['TEXTSYNTH_API_SECRET_KEY'] = 'TEXTSYNTH_API_SECRET_KEY'\n",
        "os.environ['ANTHROPIC_API_KEY'] = 'ANTHROPIC_API_KEY'\n",
        "from IPython.display import display\n",
        "import FrugalGPT\n",
        "supported_LLM = FrugalGPT.getservicename()\n",
        "print(\"supported LLMs:\",supported_LLM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71e56f0d"
      },
      "source": [
        "## 1. LLMforAll: One interface for all LLM services\n",
        "Let us first study an example for LLMforAll, an interface that unifies all existing services.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "541f755e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b834fe2-226d-47b4-c5b1-6371d8271dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API: anthropic/claude-1-100k answer:  I apologize, but I do not actually know who Matei Zaharia will be in 2023 or specifics about his future career. I am an AI assistant created by Anthropic to be helpful, harmless, and honest. cost: 0.0016795999999999998\n"
          ]
        }
      ],
      "source": [
        "MyLLMforAll = FrugalGPT.LLMforAll()\n",
        "query = \"Question: Who is Matei Zaharia in 2023?\\nAnswer:\"\n",
        "service_name = supported_LLM[-1]\n",
        "genparams = FrugalGPT.GenerationParameter(max_tokens=50, temperature=0.1, stop=['\\n\\n\\n\\n'])\n",
        "answer = MyLLMforAll.get_completion(query,service_name,genparams=genparams)\n",
        "cost = MyLLMforAll.get_cost()\n",
        "print(\"API:\",service_name,\"answer:\",answer,\"cost:\",cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93da4b98"
      },
      "source": [
        "The above code snippet shows how to use LLMforAll. Its function get_completion gives a unified inferface for all LLMs: it takes the query, the generation parameters (such as temperature), and the service name as input, and then gives the corresponding generation. The cost can be obtained by calling get_cost()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "488fac34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "outputId": "45895845-00de-4e2b-f388-673cab391e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full responses\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                       service  \\\n",
              "0        textsynth/gptneox_20B   \n",
              "1    textsynth/fairseq_gpt_13B   \n",
              "2            textsynth/gptj_6B   \n",
              "3      openai/text-davinci-002   \n",
              "4      openai/text-davinci-003   \n",
              "5        openai/text-curie-001   \n",
              "6      openai/text-babbage-001   \n",
              "7          openai/text-ada-001   \n",
              "8     openaichat/gpt-3.5-turbo   \n",
              "9             openaichat/gpt-4   \n",
              "10               ai21/j1-jumbo   \n",
              "11              ai21/j1-grande   \n",
              "12               ai21/j1-large   \n",
              "13               ai21/j2-ultra   \n",
              "14                 ai21/j2-mid   \n",
              "15               ai21/j2-light   \n",
              "16              cohere/command   \n",
              "17                 cohere/base   \n",
              "18               cohere/xlarge   \n",
              "19               cohere/medium   \n",
              "20          anthropic/claude-1   \n",
              "21  anthropic/claude-instant-1   \n",
              "22     anthropic/claude-1-100k   \n",
              "\n",
              "                                               answer          cost  \n",
              "0    Matei Zaharia is a computer scientist who wor...  1.772400e-03  \n",
              "1    Matei Zaharia is a Romanian politician and me...  7.590000e-04  \n",
              "2    The world’s first self-driving car.\\n\\nMatei ...  2.530000e-04  \n",
              "3    Matei Zaharia is a Romanian-American computer...  1.080000e-03  \n",
              "4    In 2023, Matei Zaharia is a computer scientis...  1.300000e-03  \n",
              "5         Matei Zaharia will be 73 years old in 2023.  5.600000e-05  \n",
              "6    Matei Zaharia is a Romanian-born American bus...  1.500000e-05  \n",
              "7   \\n\\nMatei Zaharia is a Russian-born American b...  2.000000e-05  \n",
              "8   As an AI language model, I cannot predict the ...  1.460000e-04  \n",
              "9   As an AI, I cannot predict the future or provi...  3.660000e-03  \n",
              "10   Matei Zaharia is 42 years old.\\nQuestion: Wha...  1.750000e-02  \n",
              "11   Matei Zaharia will be 33 years old.\\nQuestion...  4.800000e-03  \n",
              "12   Matei Zaharia is 43 years old in 2023.\\nQuest...  1.800000e-03  \n",
              "13   Matei Zaharia is a Romanian-American computer...  8.850000e-04  \n",
              "14   Matei Zaharia is a computer scientist and ent...  5.000000e-04  \n",
              "15   Matei Zaharia is a Romanian-American computer...  4.920000e-04  \n",
              "16   Matei Zaharia is a Romanian-born American com...  7.350000e-07  \n",
              "17   Matei Zaharia is a Romanian-Canadian computer...  7.350000e-07  \n",
              "18   Matei Zaharia is a Romanian-Canadian computer...  1.225000e-04  \n",
              "19   Matei Zaharia is the founder of the company C...  1.225000e-04  \n",
              "20   I apologize, but I do not have information ab...  1.810320e-03  \n",
              "21   Matei Zaharia is a computer scientist and ent...  3.015800e-04  \n",
              "22   I apologize, but I do not actually know who M...  1.679600e-03  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b34345b9-fcf5-4646-be4f-4437adb539b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>service</th>\n",
              "      <th>answer</th>\n",
              "      <th>cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>textsynth/gptneox_20B</td>\n",
              "      <td>Matei Zaharia is a computer scientist who wor...</td>\n",
              "      <td>1.772400e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>textsynth/fairseq_gpt_13B</td>\n",
              "      <td>Matei Zaharia is a Romanian politician and me...</td>\n",
              "      <td>7.590000e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>textsynth/gptj_6B</td>\n",
              "      <td>The world’s first self-driving car.\\n\\nMatei ...</td>\n",
              "      <td>2.530000e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>openai/text-davinci-002</td>\n",
              "      <td>Matei Zaharia is a Romanian-American computer...</td>\n",
              "      <td>1.080000e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>openai/text-davinci-003</td>\n",
              "      <td>In 2023, Matei Zaharia is a computer scientis...</td>\n",
              "      <td>1.300000e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>openai/text-curie-001</td>\n",
              "      <td>Matei Zaharia will be 73 years old in 2023.</td>\n",
              "      <td>5.600000e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>openai/text-babbage-001</td>\n",
              "      <td>Matei Zaharia is a Romanian-born American bus...</td>\n",
              "      <td>1.500000e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>openai/text-ada-001</td>\n",
              "      <td>\\n\\nMatei Zaharia is a Russian-born American b...</td>\n",
              "      <td>2.000000e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>openaichat/gpt-3.5-turbo</td>\n",
              "      <td>As an AI language model, I cannot predict the ...</td>\n",
              "      <td>1.460000e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>openaichat/gpt-4</td>\n",
              "      <td>As an AI, I cannot predict the future or provi...</td>\n",
              "      <td>3.660000e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ai21/j1-jumbo</td>\n",
              "      <td>Matei Zaharia is 42 years old.\\nQuestion: Wha...</td>\n",
              "      <td>1.750000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ai21/j1-grande</td>\n",
              "      <td>Matei Zaharia will be 33 years old.\\nQuestion...</td>\n",
              "      <td>4.800000e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ai21/j1-large</td>\n",
              "      <td>Matei Zaharia is 43 years old in 2023.\\nQuest...</td>\n",
              "      <td>1.800000e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ai21/j2-ultra</td>\n",
              "      <td>Matei Zaharia is a Romanian-American computer...</td>\n",
              "      <td>8.850000e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ai21/j2-mid</td>\n",
              "      <td>Matei Zaharia is a computer scientist and ent...</td>\n",
              "      <td>5.000000e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ai21/j2-light</td>\n",
              "      <td>Matei Zaharia is a Romanian-American computer...</td>\n",
              "      <td>4.920000e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>cohere/command</td>\n",
              "      <td>Matei Zaharia is a Romanian-born American com...</td>\n",
              "      <td>7.350000e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>cohere/base</td>\n",
              "      <td>Matei Zaharia is a Romanian-Canadian computer...</td>\n",
              "      <td>7.350000e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>cohere/xlarge</td>\n",
              "      <td>Matei Zaharia is a Romanian-Canadian computer...</td>\n",
              "      <td>1.225000e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>cohere/medium</td>\n",
              "      <td>Matei Zaharia is the founder of the company C...</td>\n",
              "      <td>1.225000e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>anthropic/claude-1</td>\n",
              "      <td>I apologize, but I do not have information ab...</td>\n",
              "      <td>1.810320e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>anthropic/claude-instant-1</td>\n",
              "      <td>Matei Zaharia is a computer scientist and ent...</td>\n",
              "      <td>3.015800e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>anthropic/claude-1-100k</td>\n",
              "      <td>I apologize, but I do not actually know who M...</td>\n",
              "      <td>1.679600e-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b34345b9-fcf5-4646-be4f-4437adb539b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b34345b9-fcf5-4646-be4f-4437adb539b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b34345b9-fcf5-4646-be4f-4437adb539b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0b3b9d04-6b87-4b8d-a7ab-8ede37f80fc2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b3b9d04-6b87-4b8d-a7ab-8ede37f80fc2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0b3b9d04-6b87-4b8d-a7ab-8ede37f80fc2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "responses = MyLLMforAll.get_completion_allservice(query, supported_LLM, genparams=genparams)\n",
        "print(\"full responses\")\n",
        "display(responses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0989f2ac"
      },
      "source": [
        "## 2. LLMCascade: Optimizing performance within budget constraints\n",
        "Next let us use LLMCascade to automatically optimize the overall performance given a budget constraint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "499247a7"
      },
      "source": [
        "### Example usage: predicting gold price trends from financial news\n",
        "Let us first create a few NLP queries that asks LLM to predict gold price trends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9b1f892"
      },
      "outputs": [],
      "source": [
        "dev = [['Q: april gold down 20 cents to settle at $1,116.10/oz\\nA:', 'down','0'],\n",
        "       ['Q: gold suffers third straight daily decline\\nA:', 'down','1'],\n",
        "       ['Q: Gold futures edge up after two-session decline\\nA:', 'up','2'],\n",
        "       ['Q: Dec. gold climbs $9.40, or 0.7%, to settle at $1,356.90/oz\\nA:','up','3'],\n",
        "       ['Q: Gold struggles; silver slides, base metals falter\\nA:','up','4'],\n",
        "       ['Q: feb. gold ends up $9.60, or 1.1%, at $901.60 an ounce\\nA:','up','5'],\n",
        "        ['Q: dent research : is gold\\'s day in the sun coming soon?\\nA:','none','6']\n",
        "      ]\n",
        "prefix = open('config/prompt/HEADLINES/prefix_e8.txt').read()\n",
        "raw_data = copy.deepcopy(dev)\n",
        "data = FrugalGPT.formatdata(dev,prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7935ff2"
      },
      "source": [
        "Next let us load a LLMCascade instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc1775ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "e92eacd10156474ca29c44c185e74102",
            "6283926d28aa4591a775fdea9b8d131d",
            "12978377d21f4accb84bbfb5285224f5",
            "6c9aca674a734f3498dea49637e29490",
            "ad0d699cd9a445afa288401b13d876e3",
            "53dad8b64cfc49d39f47c78547b60f9d",
            "36a85f9c0d594dc78c09bd934237065d",
            "82871d5547144337b544331979e8b78b",
            "b78ca2c7f37f4c8a819a1a6b5fb1de00",
            "d7e9c14e0db4493ba2012d4bdcde8419",
            "15f0cd22eaee42069a27cb532f45f96b",
            "77cbf3fa2e8e4f87bd59710947bd55b3",
            "8202ac8fd9e444ed8909c2c237595285",
            "3f644d96b4c249748cfca30abd81a3e9",
            "1e40132b116e4f95b306bd85a10b5566",
            "4bf3279f4704470cb1b088e583225d6f",
            "2c75febe4658463b83afe5a1b036e11c",
            "cee163a092e6485bbd24be01cd37858c",
            "94ef3efee07f4c558d0d7e55811d9e26",
            "6aea032278e7486d8121720892744bbc",
            "8bd79c9ad4c04f9e85a44357d0938896",
            "6418f8f25aa84c9abe6a648113828cf0",
            "9c6b6fa990b34b93a4d2a4c17abefc25",
            "b76f556a8bd24d639dae6b80a5f1a75f",
            "2c4df26ec85345e898a69dd7426e0aa0",
            "f291f0ae0b6a4a7dbd309a215cea1f54",
            "625905ddcfea4b6385542308b85bffae",
            "d806aa44f8a34dd2b062721525bfcc77",
            "7513cc3266d346d58747c6f213596929",
            "7b6fd64afaf8473bac56d120f4e43de9",
            "c85821d907734619a20210e15eed1d67",
            "709279ca492443c0a802ea9909f54790",
            "fcf859b2a6a943de8f61372d4bdf0397",
            "ca534a34acdb433bb55511e7c2ef464f",
            "3074fbab14564c2aa7a62cdd8172692f",
            "7d13c0d955574d338b7d92aa622e49b4",
            "b8846436e6714a699452924c0012c589",
            "6f70e693a47b4de9abd084a6432ea601",
            "08e474736d7f41f998846ee1dacfb4e1",
            "8b1cddbc72e5430c9f040a3a1ef60a41",
            "40529fa28f4643069f46d0f042fce7b5",
            "7f925637a9c5461fbce31613c7203e3a",
            "c53ef3f2fa504747bde2ee29ed2546d6",
            "d9699546f3f240e29c6ab91e6a6fad0c"
          ]
        },
        "outputId": "7aa4271a-c411-42a5-f8b5-49363236ca77"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e92eacd10156474ca29c44c185e74102"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77cbf3fa2e8e4f87bd59710947bd55b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c6b6fa990b34b93a4d2a4c17abefc25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca534a34acdb433bb55511e7c2ef464f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "MyCascade = FrugalGPT.LLMCascade()\n",
        "MyCascade.load(loadpath=\"strategy/HEADLINES/\",budget=0.000665)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64ebf172"
      },
      "source": [
        "Let us take a look on LLMCascade's generation on one query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e91e9935",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e923f82d-d955-4967-fa84-e70e5db2214b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: Q: gold suffers third straight daily decline\n",
            "A:\n",
            "FrugalGPT LLMCascade answer:  down\n"
          ]
        }
      ],
      "source": [
        "index = 1\n",
        "query = data[index][0]\n",
        "query_raw = raw_data[index][0]\n",
        "genparams=FrugalGPT.GenerationParameter(max_tokens=50, temperature=0.1, stop=['\\n'])\n",
        "answer = MyCascade.get_completion(query=query,genparams=genparams)\n",
        "cost = MyCascade.get_cost()\n",
        "print(\"query:\",query_raw)\n",
        "print(\"FrugalGPT LLMCascade answer:\",answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81a14d27"
      },
      "source": [
        "Now we can pass all the queries to both LLMCascade and vanilla GPT-4, and compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46742343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "outputId": "9e5889cd-569b-4fea-beed-22fb0ccc4b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FrugalGPT LLMCascade generations\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      _id answer ref_answer      cost\n",
              "0    9770   down       down  0.000058\n",
              "1    3631     up         up  0.000056\n",
              "2    7059     up         up  0.000055\n",
              "3     421     up         up  0.000055\n",
              "4    9878     up         up  0.000055\n",
              "..    ...    ...        ...       ...\n",
              "495  1928     up         up  0.000055\n",
              "496  1228   down       down  0.000055\n",
              "497   568     up         up  0.000056\n",
              "498   312   none       down  0.000495\n",
              "499  5508   none         up  0.000055\n",
              "\n",
              "[500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b0f5d0a-99f4-4280-a700-71b1f1ac8efb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>answer</th>\n",
              "      <th>ref_answer</th>\n",
              "      <th>cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9770</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.000058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3631</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.000056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7059</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.000055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>421</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.000055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9878</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.000055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1928</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.000055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1228</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.000055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>568</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.000056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>312</td>\n",
              "      <td>none</td>\n",
              "      <td>down</td>\n",
              "      <td>0.000495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>5508</td>\n",
              "      <td>none</td>\n",
              "      <td>up</td>\n",
              "      <td>0.000055</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b0f5d0a-99f4-4280-a700-71b1f1ac8efb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2b0f5d0a-99f4-4280-a700-71b1f1ac8efb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2b0f5d0a-99f4-4280-a700-71b1f1ac8efb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9dbd73c4-e7fe-4e36-9e55-613620a52ee3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9dbd73c4-e7fe-4e36-9e55-613620a52ee3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9dbd73c4-e7fe-4e36-9e55-613620a52ee3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'em': 0.894, 'cost': 0.0007058820000000001}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-4 generations\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      _id   answer ref_answer     cost\n",
              "0    9770     down       down  0.00705\n",
              "1    3631       up         up  0.00681\n",
              "2    7059  neutral         up  0.00657\n",
              "3     421  neutral         up  0.00657\n",
              "4    9878       up         up  0.00660\n",
              "..    ...      ...        ...      ...\n",
              "495  1928       up         up  0.00657\n",
              "496  1228     down       down  0.00663\n",
              "497   568       up         up  0.00684\n",
              "498   312     none       down  0.00660\n",
              "499  5508     none         up  0.00654\n",
              "\n",
              "[500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efc12cdf-e9bb-46c5-bbe9-ea7482ad7d91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>answer</th>\n",
              "      <th>ref_answer</th>\n",
              "      <th>cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9770</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.00705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3631</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7059</td>\n",
              "      <td>neutral</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>421</td>\n",
              "      <td>neutral</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9878</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1928</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1228</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.00663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>568</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>312</td>\n",
              "      <td>none</td>\n",
              "      <td>down</td>\n",
              "      <td>0.00660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>5508</td>\n",
              "      <td>none</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efc12cdf-e9bb-46c5-bbe9-ea7482ad7d91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-efc12cdf-e9bb-46c5-bbe9-ea7482ad7d91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-efc12cdf-e9bb-46c5-bbe9-ea7482ad7d91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-91fd64b5-bd1c-4e37-8518-c068586c05dc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91fd64b5-bd1c-4e37-8518-c068586c05dc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-91fd64b5-bd1c-4e37-8518-c068586c05dc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'em': 0.89, 'cost': 0.00666048}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# batch generation\n",
        "result = MyCascade.get_completion_batch(queries=data,genparams=genparams)\n",
        "result_GPT4 = MyLLMforAll.get_completion_batch(queries=data,genparams=genparams,service_name='openaichat/gpt-4')\n",
        "print(\"FrugalGPT LLMCascade generations\")\n",
        "display(result)\n",
        "display(FrugalGPT.compute_score(result))\n",
        "print(\"GPT-4 generations\")\n",
        "display(result_GPT4)\n",
        "display(FrugalGPT.compute_score(result_GPT4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0916d06"
      },
      "source": [
        "Overall, FrugalGPT LLMCascade gives the same performance but incurs a much smaller cost. This data is of course quite small; Later we will see the evaluation on a larger dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20e58e84"
      },
      "source": [
        "### Using FrugalGPT-LLMCascade for your own data\n",
        "Interested in using FrugalGPT for your own data? No problem! The following code snippnet demonstrates how to do it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbd3cc10"
      },
      "source": [
        "The first thing is to load the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7d77884"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "dev = FrugalGPT.loadcsvdata(\"data/HEADLINES/train.csv\")\n",
        "dev = dev[0:500]\n",
        "prefix = open('config/prompt/HEADLINES/prefix_e8.txt').read()\n",
        "data = FrugalGPT.formatdata(dev,prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebe2bd07"
      },
      "source": [
        "Second, specify the budget per query, and then train the model. In this example, only 3 APIs from OpenAI and AI21 are used, and thus setting up OpenAI and AI21 API keys is enough. Warning: The training process can take a while on large datasets!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7730973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977,
          "referenced_widgets": [
            "5f132513a1a246eaa935f94de84b4cc2",
            "1e89beb97fdc4b7f9d40b24250a4dfaa",
            "dce35320f83f4afb8f686bccd877f2d5",
            "030a30061ef7485b97a75b12b817d0f2",
            "4204b1bad3784e91a7121cf38372485b",
            "c58fb2e124354bbfa245ecbd7b22d9dd",
            "fed89cd4306840bf8d2179307a143c4e",
            "003b08920c234e218657ca7b1d7c6aaa",
            "e6fc7dd82e0d4dcfa3b3935bea5bf139",
            "32271686165d42b282211b93da70751b",
            "5c2429c5878946cd8dfa3b3a7545d428"
          ]
        },
        "outputId": "27055b11-fc56-4947-95fe-f364268f84f7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f132513a1a246eaa935f94de84b4cc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='104' max='104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [104/104 01:12, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.601300</td>\n",
              "      <td>0.605322</td>\n",
              "      <td>0.821549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.592400</td>\n",
              "      <td>0.561019</td>\n",
              "      <td>0.821549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.555900</td>\n",
              "      <td>0.492254</td>\n",
              "      <td>0.821549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.382100</td>\n",
              "      <td>0.466782</td>\n",
              "      <td>0.821549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.434900</td>\n",
              "      <td>0.471775</td>\n",
              "      <td>0.821549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.375700</td>\n",
              "      <td>0.474937</td>\n",
              "      <td>0.821549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.360800</td>\n",
              "      <td>0.457660</td>\n",
              "      <td>0.821549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.302400</td>\n",
              "      <td>0.422048</td>\n",
              "      <td>0.821549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='104' max='104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [104/104 00:52, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.726400</td>\n",
              "      <td>0.707432</td>\n",
              "      <td>0.188552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.707000</td>\n",
              "      <td>0.643969</td>\n",
              "      <td>0.895623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.659100</td>\n",
              "      <td>0.545092</td>\n",
              "      <td>0.895623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.500500</td>\n",
              "      <td>0.397062</td>\n",
              "      <td>0.895623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.373900</td>\n",
              "      <td>0.334464</td>\n",
              "      <td>0.895623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.393900</td>\n",
              "      <td>0.330068</td>\n",
              "      <td>0.895623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.298800</td>\n",
              "      <td>0.317346</td>\n",
              "      <td>0.895623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.268000</td>\n",
              "      <td>0.304869</td>\n",
              "      <td>0.895623</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='104' max='104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [104/104 00:55, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.719700</td>\n",
              "      <td>0.707748</td>\n",
              "      <td>0.218855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.707100</td>\n",
              "      <td>0.666228</td>\n",
              "      <td>0.791246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>0.608357</td>\n",
              "      <td>0.794613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.625200</td>\n",
              "      <td>0.524273</td>\n",
              "      <td>0.794613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.532600</td>\n",
              "      <td>0.484093</td>\n",
              "      <td>0.794613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.526300</td>\n",
              "      <td>0.458705</td>\n",
              "      <td>0.794613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.472700</td>\n",
              "      <td>0.458166</td>\n",
              "      <td>0.794613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.426000</td>\n",
              "      <td>0.426861</td>\n",
              "      <td>0.794613</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# train the model\n",
        "MyCascade = FrugalGPT.LLMCascade()\n",
        "service_names = ['openaichat/gpt-3.5-turbo','openaichat/gpt-4','ai21/j1-large']\n",
        "user_budget = 0.002\n",
        "result = MyCascade.train(data,budget=user_budget,service_names=service_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3a313dc"
      },
      "outputs": [],
      "source": [
        "# save to disk\n",
        "MyCascade.save(savepath=\"strategy/TEST/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b35b8b79"
      },
      "source": [
        "Now the model has been saved to disk. You can load it as follows for future applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4422dc1d"
      },
      "outputs": [],
      "source": [
        "MyCascade = FrugalGPT.LLMCascade()\n",
        "MyCascade.load(loadpath=\"strategy/TEST/\",budget=user_budget)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance evaluation\n",
        "Now let us evaluate the performance of FrugalGPT. We use LLMCascade on the HEADLINES dataset as an example."
      ],
      "metadata": {
        "id": "-xwhCbVsg0Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = FrugalGPT.loadcsvdata(\"data/HEADLINES/test.csv\")\n",
        "prefix = open('config/prompt/HEADLINES/prefix_e8.txt').read()\n",
        "data_eval = FrugalGPT.formatdata(test,prefix)\n",
        "data_eval = data_eval[0:500]\n",
        "genparams=FrugalGPT.GenerationParameter(max_tokens=50, temperature=0.1, stop=['\\n'])\n",
        "result_GPT4 = MyLLMforAll.get_completion_batch(queries=data_eval,genparams=genparams,service_name='openaichat/gpt-4')\n",
        "print(\"GPT-4 generations\")\n",
        "display(result_GPT4)\n",
        "display(FrugalGPT.compute_score(result_GPT4))\n",
        "result = MyCascade.get_completion_batch(queries=data_eval,genparams=genparams)\n",
        "print(\"FrugalGPT LLMCascade generations\")\n",
        "display(result)\n",
        "display(FrugalGPT.compute_score(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "id": "fM6yi0SGghrb",
        "outputId": "906871ca-1238-427d-e258-0d1da3f7b8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-4 generations\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      _id   answer ref_answer     cost\n",
              "0    6556       up         up  0.00660\n",
              "1    5832     none       none  0.00666\n",
              "2    5618     none       none  0.00666\n",
              "3    4205     down       down  0.00660\n",
              "4     842       up       down  0.00654\n",
              "..    ...      ...        ...      ...\n",
              "495  4810     down       down  0.00660\n",
              "496  6319     down       down  0.00693\n",
              "497  7522     none         up  0.00654\n",
              "498  4117  neutral         up  0.00669\n",
              "499  8749     down       down  0.00678\n",
              "\n",
              "[500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48d67e32-a29a-4874-9e79-583f7cecd5f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>answer</th>\n",
              "      <th>ref_answer</th>\n",
              "      <th>cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6556</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5832</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.00666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5618</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.00666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4205</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.00660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>842</td>\n",
              "      <td>up</td>\n",
              "      <td>down</td>\n",
              "      <td>0.00654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>4810</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.00660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>6319</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.00693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>7522</td>\n",
              "      <td>none</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>4117</td>\n",
              "      <td>neutral</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>8749</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.00678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48d67e32-a29a-4874-9e79-583f7cecd5f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48d67e32-a29a-4874-9e79-583f7cecd5f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48d67e32-a29a-4874-9e79-583f7cecd5f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4499fd4d-3d37-41e1-9cfe-816989e36ee7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4499fd4d-3d37-41e1-9cfe-816989e36ee7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4499fd4d-3d37-41e1-9cfe-816989e36ee7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'em': 0.854, 'cost': 0.0066702}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FrugalGPT LLMCascade generations\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      _id answer ref_answer      cost\n",
              "0    6556     up         up  0.000055\n",
              "1    5832   none       none  0.000499\n",
              "2    5618   none       none  0.000499\n",
              "3    4205   down       down  0.000055\n",
              "4     842     up       down  0.000055\n",
              "..    ...    ...        ...       ...\n",
              "495  4810   down       down  0.000055\n",
              "496  6319     up       down  0.000057\n",
              "497  7522     up         up  0.000491\n",
              "498  4117     up         up  0.000056\n",
              "499  8749   down       down  0.000056\n",
              "\n",
              "[500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f73ea1c6-1e2f-4d00-b9b1-ad2521d598d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>answer</th>\n",
              "      <th>ref_answer</th>\n",
              "      <th>cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6556</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.000055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5832</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.000499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5618</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.000499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4205</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.000055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>842</td>\n",
              "      <td>up</td>\n",
              "      <td>down</td>\n",
              "      <td>0.000055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>4810</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.000055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>6319</td>\n",
              "      <td>up</td>\n",
              "      <td>down</td>\n",
              "      <td>0.000057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>7522</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.000491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>4117</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.000056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>8749</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.000056</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f73ea1c6-1e2f-4d00-b9b1-ad2521d598d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f73ea1c6-1e2f-4d00-b9b1-ad2521d598d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f73ea1c6-1e2f-4d00-b9b1-ad2521d598d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ec9bc3f3-73c8-47a6-84a7-babef4d9af67\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec9bc3f3-73c8-47a6-84a7-babef4d9af67')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ec9bc3f3-73c8-47a6-84a7-babef4d9af67 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'em': 0.86, 'cost': 0.00048743720000000003}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "031c2ffc"
      },
      "source": [
        "### Full performance evaluation\n",
        "Now let us evaluate the performance of FrugalGPT. We use LLMCascade on the HEADLINES dataset as an example. Warning: This is also going to be slow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c87cb438"
      },
      "source": [
        "First, we load the evaluation dataset and the LLMCascade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "119692bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02affa4b-43d2-4a9b-d02e-74d012a76667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test data size: 5000\n"
          ]
        }
      ],
      "source": [
        "test = FrugalGPT.loadcsvdata(\"data/HEADLINES/test.csv\")\n",
        "prefix = open('config/prompt/HEADLINES/prefix_e8.txt').read()\n",
        "data_eval = FrugalGPT.formatdata(test,prefix)\n",
        "print(\"test data size:\",len(data_eval))\n",
        "MyCascade = FrugalGPT.LLMCascade()\n",
        "MyCascade.load(loadpath=\"strategy/HEADLINES/\",budget=0.000665)\n",
        "#MyCascade.load(loadpath=\"strategy/HEADLINES/\",budget=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "101b5a0c"
      },
      "source": [
        "And then let us evaluate it on the evaluation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c844c844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "0682422e-d571-483a-b2e7-8222c1e4d18b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-4 generations\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       _id   answer ref_answer     cost\n",
              "0     6556       up         up  0.00660\n",
              "1     5832     none       none  0.00666\n",
              "2     5618     none       none  0.00666\n",
              "3     4205     down       down  0.00660\n",
              "4      842       up       down  0.00654\n",
              "...    ...      ...        ...      ...\n",
              "4995  8376  neutral         up  0.00651\n",
              "4996  4242     down       down  0.00654\n",
              "4997   663     down         up  0.00660\n",
              "4998  6890  neutral    neutral  0.00648\n",
              "4999  6311     none         up  0.00663\n",
              "\n",
              "[5000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c93a023-2af7-4a64-827a-62a285e52697\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>answer</th>\n",
              "      <th>ref_answer</th>\n",
              "      <th>cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6556</td>\n",
              "      <td>up</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5832</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.00666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5618</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>0.00666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4205</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.00660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>842</td>\n",
              "      <td>up</td>\n",
              "      <td>down</td>\n",
              "      <td>0.00654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>8376</td>\n",
              "      <td>neutral</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>4242</td>\n",
              "      <td>down</td>\n",
              "      <td>down</td>\n",
              "      <td>0.00654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>663</td>\n",
              "      <td>down</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>6890</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.00648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>6311</td>\n",
              "      <td>none</td>\n",
              "      <td>up</td>\n",
              "      <td>0.00663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c93a023-2af7-4a64-827a-62a285e52697')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0c93a023-2af7-4a64-827a-62a285e52697 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0c93a023-2af7-4a64-827a-62a285e52697');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4efd46cb-771d-4cf0-a7fc-21606a4cf457\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4efd46cb-771d-4cf0-a7fc-21606a4cf457')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4efd46cb-771d-4cf0-a7fc-21606a4cf457 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'em': 0.8556, 'cost': 0.006661218000000001}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-41ffd9fcf9d3>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_GPT4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrugalGPT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_GPT4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyCascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_completion_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FrugalGPT LLMCascade generations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FrugalGPT/src/FrugalGPT/llmcascade.py\u001b[0m in \u001b[0;36mget_completion_batch\u001b[0;34m(self, queries, genparams)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mans1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'_id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mans1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ref_answer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cost'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FrugalGPT/src/FrugalGPT/llmcascade.py\u001b[0m in \u001b[0;36mget_completion\u001b[0;34m(self, query, genparams)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyLLMEngine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mservice_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mMyLLMEngine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMyScores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mservice_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0;31m#print(\"score and score thres:\",service_name,score,score_thres)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mscore_thres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FrugalGPT/src/FrugalGPT/scoring.py\u001b[0m in \u001b[0;36mget_score\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FrugalGPT/src/FrugalGPT/scoring.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, text)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mlogit_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m#return logit_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         return self.transformer(\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 )\n\u001b[1;32m    368\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    370\u001b[0m                     \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                     \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# Feed Forward Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0mffn_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_chunking_to_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mff_chunk\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "genparams=FrugalGPT.GenerationParameter(max_tokens=50, temperature=0.1, stop=['\\n'])\n",
        "result_GPT4 = MyLLMforAll.get_completion_batch(queries=data_eval,genparams=genparams,service_name='openaichat/gpt-4')\n",
        "print(\"GPT-4 generations\")\n",
        "display(result_GPT4)\n",
        "display(FrugalGPT.compute_score(result_GPT4))\n",
        "result = MyCascade.get_completion_batch(queries=data_eval,genparams=genparams)\n",
        "print(\"FrugalGPT LLMCascade generations\")\n",
        "display(result)\n",
        "display(FrugalGPT.compute_score(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f6f02a0"
      },
      "source": [
        "Overall, LLMCascade achieves better performance than GPT-4 with a 10x smaller cost."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">*Stretch Exercise*</font>\n",
        "\n",
        "<font color=\"red\">(Not required). Choose a set of LLMs and play with FrugalGPT using your own dataset. Note: While this is not required, it can be counted as bonus toward earning a 😃 for this week's assignment!"
      ],
      "metadata": {
        "id": "bdgbLfemozo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reinforcement Learning with Human Feedback (RLHF)\n",
        "Open AI introduced RLHF as an approach to tuning their GPT model class through multiple generative responses, and the request the users provide minimal feedback (e.g. “thumbs up”, “thumbs down”) to express their evaluation of the generated text. While Open AI did not describe how they implement RLHF in detail, a number of open source approaches are emerging. We do not provide a specific example here, but point to a [popular repository](https://github.com/opendilab/awesome-RLHF) tracking such open RLHF theory and code developments.  \n"
      ],
      "metadata": {
        "id": "8nIlRzHcDFjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLMs and Annotating Texts\n",
        "\n",
        "We will be using code from this tutorial to illustrate how LLMs can be used in action:\n",
        "\n",
        "https://github.com/vminvsky/css-llm-tutorial.\n",
        "\n",
        "## NOTE\n",
        "\n",
        "You're going to have to upload the data and requirements to make sure that this sectoin works correctly.\n",
        "\n",
        "In this section, we will see how LLMs can be used to annotate and generate data for studying linguistic constructs.\n",
        "\n",
        "Our goals are as follows:\n",
        "\n",
        "* **Goal 1:** Learn langchain.\n",
        "    * Langchain is the most common library for interacting with LLMs in Python!\n",
        "\n",
        "* **Goal 2:** Annotate a dataset with ChatGPT\n",
        "    * Annotate texts as being sarcastic or not using ChatGPT.\n",
        "\n",
        "* **Goal 3:** Generate Synthetic Data for a Specific Construct of Interest\n",
        "    * Generate new examples of sarcastic and non-sarcastic texts.\n",
        "    \n",
        "A few requirements.\n",
        "1. You will need an OpenAI key to generate the data. Because the data has already been generated, you won't need it to explore the synthetic data, but if you want to re-run the generation you will need to obtain a key. You can signup [here](https://openai.com/blog/openai-api)\n",
        "2. *(If you have an API key)* In the .env file in root add your API key.\n",
        "3. Run the requirements.txt file to pip install all the necessary libraries.\n",
        "4. Visit the GitHub link and grab all the data and re"
      ],
      "metadata": {
        "id": "xYV00vcaol04"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fe681c6"
      },
      "source": [
        "#### Local Setup\n",
        "Let's install all the required libraries to go through this document.\n",
        "\n",
        "requirements - NOTE - this code will only work with older versions of openai and langchain.\n",
        "\n",
        "pandas\n",
        "\n",
        "langchain==0.0.205\n",
        "\n",
        "numpy==1.22.4\n",
        "\n",
        "scipy==1.10.1\n",
        "\n",
        "python-dotenv\n",
        "\n",
        "openai==0.27.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1db7557f"
      },
      "outputs": [],
      "source": [
        "requirements = \"/content/drive/MyDrive/SOCI40133/data/requirements.txt\"\n",
        "#!pip install -r {requirements}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install langchain==0.0.205"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DMdBPQbmrU2L",
        "outputId": "75bdb72e-d994-4db9-87db-bdf49eaf3636"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.0.205\n",
            "  Downloading langchain-0.0.205-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.205) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.205) (2.0.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.205) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.205) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.205)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk>=0.0.9 (from langchain==0.0.205)\n",
            "  Downloading langchainplus_sdk-0.0.20-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.205) (2.9.0)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.205) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.205)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2,>=1 (from langchain==0.0.205)\n",
            "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.205) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.205) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.205) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.205) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.205) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.205) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.205) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.205) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.205) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.205) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.205) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.205) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.205) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.205) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.205) (3.0.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.205) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.205) (1.0.0)\n",
            "Installing collected packages: pydantic, openapi-schema-pydantic, langchainplus-sdk, dataclasses-json, langchain\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.1\n",
            "    Uninstalling pydantic-2.6.1:\n",
            "      Successfully uninstalled pydantic-2.6.1\n",
            "  Attempting uninstall: dataclasses-json\n",
            "    Found existing installation: dataclasses-json 0.6.4\n",
            "    Uninstalling dataclasses-json-0.6.4:\n",
            "      Successfully uninstalled dataclasses-json-0.6.4\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.1.6\n",
            "    Uninstalling langchain-0.1.6:\n",
            "      Successfully uninstalled langchain-0.1.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.5.14 langchain-0.0.205 langchainplus-sdk-0.0.20 openapi-schema-pydantic-1.2.4 pydantic-1.10.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydantic"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Tf-3NYrYuG",
        "outputId": "f0d7cf29-45e7-4f6d-c26d-c8e1f1816223"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install openai==0.27.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "aD4Z0TzjreVu",
        "outputId": "4d1ed5ae-698b-4492-8bff-2bea132bc046"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.27.8\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.10.0\n",
            "    Uninstalling openai-1.10.0:\n",
            "      Successfully uninstalled openai-1.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.27.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "a14b11be",
        "outputId": "60a9981f-b448-4a99-f6fa-92d73e79a4ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import langchain\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from langchain import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "load_dotenv()  # take environment variables from .env."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95040cc2"
      },
      "source": [
        "Run this cell to load the autoreload extension. This allows us to edit .py source files, and re-import them into the notebook for a seamless editing and debugging experience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8db64837"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42    # for reproducibility"
      ],
      "metadata": {
        "id": "Jkb47i2-NqFa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "e793b64a"
      },
      "outputs": [],
      "source": [
        "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "OPENAI_API_KEY = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or if you don't want to keep it in your notebook for safety concerns:"
      ],
      "metadata": {
        "id": "WgkDEmw0KyKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "OPENAI_API_KEY = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzKEDX1GKxLl",
        "outputId": "6dc7d938-d0eb-4257-aa29-e21b056739bb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "DS7zdtGdhMHd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b97fda0e"
      },
      "source": [
        "### 1. Dataset Introduction\n",
        "\n",
        "The dataset includes two columns: `text` and `labels`. Where `text` is a Tweet and `label` is either sarcastic or non-sarcastic."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def example_rows(df):\n",
        "    print(\"Example of a sarcastic text\")\n",
        "    print(df[df[\"labels\"]==\"sarcastic\"].iloc[0][\"text\"])\n",
        "    print()\n",
        "    print(\"Example of a non-sarcastic text\")\n",
        "    print(df[df[\"labels\"]==\"not-sarcastic\"].iloc[0][\"text\"])"
      ],
      "metadata": {
        "id": "TEWCxzz-bP8x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "34c9a1da"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json(\"/content/drive/MyDrive/SOCI40133/data/llm/sarcasm.json\", orient=\"records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bf0838c7",
        "outputId": "f1f1e8fc-93b7-447b-853e-ca89816c23c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows:  500\n",
            "Number of sarcastic comments:  135\n",
            "\n",
            "Example of a sarcastic text\n",
            "do people with clear skin feel accomplished?? superior??? comfortable in their own skin???? whats that like lmfao\n",
            "\n",
            "Example of a non-sarcastic text\n",
            "A message to all Muslims and Refugees: I'm sorry for how my country is treating you. You are only human. #RefugeesDetained #Trump #rt\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of rows: \",len(df))\n",
        "print(\"Number of sarcastic comments: \",len(df[df[\"labels\"]==\"sarcastic\"]))\n",
        "print()\n",
        "example_rows(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "524e3713"
      },
      "source": [
        "### 2. Langchain\n",
        "> [LangChain](https://python.langchain.com/docs/get_started/quickstart) is a framework for developing applications powered by language models.\n",
        "\n",
        "We will use Langchain to *annotate* and *generate* sarcastic texts! Langchain is currently the most widely used Python library for interacting with LLMs programatically. It contains a lot of useful functionalities, but we will focuse on the simple case: given a prompt, generate text!\n",
        "\n",
        "To design prompts we need to add both a `system` prompt and a `message` prompt. In Langchain this corresponds to `HumanMessagePromptTemplate` and `SytemMessagePromptTemplate`. To read more about prompt templates you can look at the Langchain documentation [here](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/).\n",
        "\n",
        "All prompts are included in the `utils.py` file but we will add an example below.\n",
        "\n",
        "The **system** message basically puts the model into a certain headspace through meta-instructions. E.g., \"You are a helpful assistant!\".\n",
        "\n",
        "The **human message** instead includes the task explanation.\n",
        "\n",
        "In this code, we ask the model to generate `{num_generations}` (for example 10) `{direction}` (for example sarcastic) comments.\n",
        "\n",
        "The function will then return a list with the two messages which we will feed into Langchain's LLM. :)\n",
        "\n",
        "\n",
        "```py\n",
        "def sarcasm_simple_prompt(self) -> list:\n",
        "    system_message = SystemMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[],\n",
        "            template=\"You are a model that generates sarcastic and non-sarcastic texts.\"\n",
        "        )\n",
        "    )\n",
        "    human_message = HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[\"num_generations\", \"direction\"],\n",
        "            template=\"Generate {num_generations} {direction} texts. Ensure diversity in the generated texts.\"\n",
        "        )\n",
        "    )\n",
        "    return [system_message, human_message]\n",
        "```\n",
        "See [here](https://github.com/vminvsky/css-llm-tutorial/blob/main/utils.py) for more exaples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25defd07"
      },
      "source": [
        "### 2.1 Annotations\n",
        "Let's annotate texts as being sarcastic or not, and report the performance!\n",
        "\n",
        "First, let's try it on one text:\n",
        "> do people with clear skin feel accomplished?? superior??? comfortable in their own skin???? whats that like lmfao\n",
        "\n",
        "*Only run the code if you have an OpenAI key, otherwise just import the files with already generated data.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sarcasm_annotate_prompt() -> list:\n",
        "    system_message = SystemMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[],\n",
        "            template=\"You are a model that annotates sarcastic and non-sarcastic texts.\"\n",
        "        )\n",
        "    )\n",
        "    human_message = HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[\"text\"],\n",
        "            template=\"\"\"Classify the following text as being sarcastic or non-sarcastic. Reply with 'Sarcastic' if it's sarcastic and 'Non-sarcastic' if it's non-sarcastic.\n",
        "            Text: {text}\n",
        "            \"\"\"\n",
        "        )\n",
        "    )\n",
        "    return [system_message, human_message]"
      ],
      "metadata": {
        "id": "Wa5KE27TbT6Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c6a29a3f"
      },
      "outputs": [],
      "source": [
        "example_text = \"do people with clear skin feel accomplished?? superior??? comfortable in their own skin???? whats that like lmfao\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b90f3956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "ba24c5fe-5cbf-4465-83ba-f65e7af3104d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-723e5c27afe5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msarcasm_annotate_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexample_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_output_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             outputs = (\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;34m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    166\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mllm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_llm_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         )\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             results = [\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             results = [\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[1;32m    352\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine_llm_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36m_completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mretry_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
          ]
        }
      ],
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9, openai_api_key=OPENAI_API_KEY)\n",
        "prompt = ChatPromptTemplate.from_messages(sarcasm_annotate_prompt())\n",
        "chain = LLMChain(prompt=prompt, llm=llm)\n",
        "generated = chain.run({\"text\": example_text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "c0036c81",
        "outputId": "e7de7221-7273-4fba-e336-c5489a586001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'generated' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-11eec927b281>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'generated' is not defined"
          ]
        }
      ],
      "source": [
        "print(generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d93d5174"
      },
      "source": [
        "Great! It seems to work. Now we will iterate through all the sarcastic texts in our document."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how sarcastic/nonsarcastic examples look like:"
      ],
      "metadata": {
        "id": "rWMbA1jEUesn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eea156e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "82ac4de7-ff9b-401b-c56d-be07460ca929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/500 [00:00<?, ?it/s]WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "  0%|          | 0/500 [00:13<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-93dc754590bc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgenerated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_output_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             outputs = (\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;34m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    166\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mllm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_llm_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         )\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             results = [\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             results = [\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[1;32m    352\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine_llm_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoSleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_for_next_attempt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdo\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/nap.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmocked\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "generated = []\n",
        "prompt = ChatPromptTemplate.from_messages(sarcasm_annotate_prompt())\n",
        "chain = LLMChain(prompt=prompt, llm=llm)\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    text = row[\"text\"]\n",
        "    generated.append(chain.run({\"text\": text}))\n",
        "df[\"predict\"] = generated"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"predict\"]"
      ],
      "metadata": {
        "id": "FQhEBFxou0Zn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a017f11b-3955-4901-bbbf-25ad77677351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Non-sarcastic\n",
              "1      Non-sarcastic\n",
              "2          Sarcastic\n",
              "3          Sarcastic\n",
              "4          Sarcastic\n",
              "           ...      \n",
              "495    Non-sarcastic\n",
              "496        Sarcastic\n",
              "497        Sarcastic\n",
              "498        Sarcastic\n",
              "499    Non-sarcastic\n",
              "Name: predict, Length: 500, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e291789"
      },
      "source": [
        "The annotations have already been run, so let's just import the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "23eeb156"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json(\"/content/drive/MyDrive/SOCI40133/data/llm/annotate_gpt-3.5-turbo.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "e1d5e8d3"
      },
      "outputs": [],
      "source": [
        "def process_text(x):\n",
        "    \"\"\"\n",
        "    Process GPT outputs. Otherwise\n",
        "    \"\"\"\n",
        "    if \"non-sarcastic\" in x.lower():\n",
        "        return \"not-sarcastic\"\n",
        "    else:\n",
        "        return \"sarcastic\"\n",
        "\n",
        "df[\"predict\"] = df[\"predict\"].apply(lambda x: process_text(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "165842fa"
      },
      "source": [
        "Let's import some metrics to see how well the predictions are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fc1f392c",
        "outputId": "2b9ed7e7-5022-43a4-b203-16c371875682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.602\n",
            "F1 score: 0.596\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "accuracy = accuracy_score(df[\"target\"], df[\"predict\"])\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(df[\"target\"], df[\"predict\"], average=\"macro\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1 score: {round(f1, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "840b7078"
      },
      "source": [
        "Not amazing!\n",
        "\n",
        "Instead, we can try to generate more data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5076544e"
      },
      "source": [
        "### 2.2 Generating data\n",
        "Now we'll quickly go over how to generate more sarcastic texts. This can be used for *de-novo* dataset creation to augment your data.\n",
        "\n",
        "We'll use a grounded prompting technique, where we'll rewrite real tweets to make them sarcastic or not!\n",
        "\n",
        "Let's rewrite this Tweet as an example:\n",
        "> Tapping a tuning fork and seeing who resonates"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sarcasm_grounded_prompt() -> list:\n",
        "    system_message = SystemMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[],\n",
        "            template=\"You are a model that generates sarcastic and non-sarcastic texts.\"\n",
        "        )\n",
        "    )\n",
        "    human_message = HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[\"text\", \"num_generations\", \"direction\"],\n",
        "            template=\"\"\"Rewrite the following text {num_generations} times to make it {direction}.\n",
        "            Make as few changes as possible to the text and stay true to its underlying style.\n",
        "            Text: {text}\n",
        "            \"\"\"\n",
        "        )\n",
        "    )\n",
        "    return [system_message, human_message]"
      ],
      "metadata": {
        "id": "gnft_1mOd8UB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "f5b9189f"
      },
      "outputs": [],
      "source": [
        "example_text = \"Tapping a tuning fork and seeing who resonates\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "e0112434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "d44fd4e0-2f05-4ce3-e0d1-94d26253621d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-507617814ca4>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msarcasm_grounded_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexample_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"direction\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"sarcastic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"num_generations\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_output_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             outputs = (\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;34m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    166\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mllm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_llm_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         )\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             results = [\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             results = [\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[1;32m    352\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine_llm_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/openai.py\u001b[0m in \u001b[0;36m_completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mretry_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
          ]
        }
      ],
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9, max_tokens=512, openai_api_key=OPENAI_API_KEY)\n",
        "prompt = ChatPromptTemplate.from_messages(sarcasm_grounded_prompt())\n",
        "chain = LLMChain(prompt=prompt, llm=llm)\n",
        "generated = chain.run({\"text\": example_text, \"direction\": \"sarcastic\", \"num_generations\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdda10a1"
      },
      "outputs": [],
      "source": [
        "print(generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37517c79"
      },
      "source": [
        "A little on the nose...GPT4 is better (sarcasm is hard)!\n",
        "\n",
        "Don't run the following code if OpenAI key not connected, just import csv!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68502c69"
      },
      "outputs": [],
      "source": [
        "generated = []\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    for direction in [\"sarcastic\", \"not-sarcastic\"]: # choose direction\n",
        "        text = row[\"text\"]\n",
        "        prompt = ChatPromptTemplate.from_messages(sarcasm_grounded_prompt())\n",
        "        chain = LLMChain(prompt=prompt, llm=llm)\n",
        "        generated.append(chain.run({\"text\": text, \"direction\": direction}))\n",
        "\n",
        "df[\"augmented_text\"] = generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fefb8ff"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json(\"/content/drive/MyDrive/SOCI40133/data/llm/grounded_gpt-3.5-turbo.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cb96a70"
      },
      "source": [
        "### Analysis\n",
        "\n",
        "Let's see if there are ideosyncracies in the generated sarcastic texts!\n",
        "\n",
        "There is a lot that can be done here, but we will look at the prevelance of \"Oh\" in sarcastic comments between the two groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebfefb29"
      },
      "outputs": [],
      "source": [
        "generated_sarcastic = df[df[\"labels\"]==\"sarcastic\"][\"augmented_text\"].values\n",
        "original_sarcastic = df[df[\"target\"]==\"sarcastic\"].drop_duplicates(subset=\"text\")[\"text\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40bc4573",
        "outputId": "17a0e394-0171-41c2-f2c8-6184f587b741",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Oh' present in 0.165 of synthetic texts\n",
            "\n",
            "'Oh' present in 0.022 of real texts\n"
          ]
        }
      ],
      "source": [
        "oh_synthetic = len([k for k in generated_sarcastic if \"oh\" in k.lower()]) / len(generated_sarcastic)\n",
        "oh_real = len([k for k in original_sarcastic if \"oh\" in k.lower()]) / len(original_sarcastic)\n",
        "\n",
        "print(f\"'Oh' present in {round(oh_synthetic, 3)} of synthetic texts\")\n",
        "print()\n",
        "print(f\"'Oh' present in {round(oh_real, 3)} of real texts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">*Exercise 3*</font>\n",
        "<font color=\"red\">Use LLM to generate some data and compare the differences between model-generated data and actual data. This exercise should not be a repetition of exercise 1. Focus more on analyzing language nuances, qualitatively or quantitatively. You should also notice how the choice of LLM has possibly impacted the language it uses.\n",
        "\n"
      ],
      "metadata": {
        "id": "SYDpByLsviS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use gpt2 here to generate some content that simulates online postings. The content is related to gender. In order to simulate online postings, the content is specially designated with a complaining tone. Then compare the sentiment analysis and cosine similarity of the harvest text and my final project data.\n"
      ],
      "metadata": {
        "id": "fOe1D9Ejipvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "z1_UkM7zQ9Vr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df2_sample\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jISVvCYJQ9Tc",
        "outputId": "4752c131-33e0-493f-beda-a6c754c31df6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       user      board  \\\n",
              "2543              christopherl (Crystal~++)  Gossiping   \n",
              "10                           smallgigi (爸爸)   Boy-Girl   \n",
              "2619                      duckosara ( 達可鴨 )  Gossiping   \n",
              "2606                 feng19890809 (習近平(近平))  Gossiping   \n",
              "2162              christopherl (Crystal~++)  Gossiping   \n",
              "67                  cloud72426 (數字只是輔助不是真理)   Boy-Girl   \n",
              "2467              christopherl (Crystal~++)  Gossiping   \n",
              "2748                        herex (魔導戰士破壞者)  Gossiping   \n",
              "2319                      duckosara ( 達可鴨 )  Gossiping   \n",
              "264                             damm (Seth)   Boy-Girl   \n",
              "1773              christopherl (Crystal~++)  Gossiping   \n",
              "634   n9n9n9n9n91 (n9n9n9n9n9n9n9n9n9n9n91)  Gossiping   \n",
              "2062              christopherl (Crystal~++)  Gossiping   \n",
              "2826                 feng19890809 (習近平(近平))  Gossiping   \n",
              "2098                   ck960785 (Metal 0-4)  Gossiping   \n",
              "1199                      duckosara ( 達可鴨 )  Gossiping   \n",
              "1680                 zangetsu9006 (台灣是平行時空)  Gossiping   \n",
              "2366                 feng19890809 (習近平(近平))  Gossiping   \n",
              "878                    ck960785 (Metal 0-4)  Gossiping   \n",
              "1385              christopherl (Crystal~++)  Gossiping   \n",
              "\n",
              "                                  title     date type  \\\n",
              "2543           [問卦] 55歲台女：足以引起我兒子性慾的都禁止  2024-02   問卦   \n",
              "10    Re: [討論] 台女會覺得外籍新娘是威脅嗎???????????  2023-11   討論   \n",
              "2619                  [問卦] 台女會喜歡娘娘的男生嗎?  2024-02   問卦   \n",
              "2606                [問卦] 台女露營YT拍攝者都是誰啊?  2024-02   問卦   \n",
              "2162          [問卦] 31歲單身台女：未滿18就不是處女處男不  2024-02   問卦   \n",
              "67                 Re: [求助] 喜歡上一個電視台女主播  2023-03   求助   \n",
              "2467          [問卦] 31歲單身台女：iwin避免兒子被性污染  2024-02   問卦   \n",
              "2748              [問卦] 台女被歐巴老公狠狠揍一頓會報警嗎  2024-02   問卦   \n",
              "2319                  [問卦] 台女會喜歡娘娘的男生嗎?  2024-02   問卦   \n",
              "264       Re: [新聞] 男友要求AA制　台女「氣到分手」狂言：現  2020-08   新聞   \n",
              "1773           [問卦] 31歲單身台女：為什麼談戀愛都找年輕的  2024-02   問卦   \n",
              "634           Re: [問卦] 現代台女都只想養貓狗不想生小孩?  2024-02   問卦   \n",
              "2062          [問卦] 31歲單身台女：未滿18就不是處女處男不  2024-02   問卦   \n",
              "2826                [問卦] 台女露營YT拍攝者都是誰啊?  2024-02   問卦   \n",
              "2098            [問卦] 有無台男搭訕台女不成就動手打人的八卦  2024-02   問卦   \n",
              "1199                  [問卦] 台女會喜歡娘娘的男生嗎?  2024-02   問卦   \n",
              "1680          Re: [問卦] 現代台女都只想養貓狗不想生小孩?  2024-02   問卦   \n",
              "2366                [問卦] 台女露營YT拍攝者都是誰啊?  2024-02   問卦   \n",
              "878             [問卦] 有無台男搭訕台女不成就動手打人的八卦  2024-02   問卦   \n",
              "1385         [問卦] 45歲台女團體：iWIN可以避免兒子被性污  2024-02   問卦   \n",
              "\n",
              "                                                   text  \\\n",
              "2543  看到台灣很多55歲台女，不能接受未成年人類有性慾\\n\\n「好噁心，我兒子怎麼可能有性慾」\\n...   \n",
              "10    會，而且絕對會。\\n\\n國小同學就是這樣，剛好有機會去越南出差，\\n\\n有機會認識了鄉下女孩...   \n",
              "2619  哈哈\\n\\n是我啦\\n\\n帥鴿鴨\\n\\n公司裡有個娘娘的男生\\n\\n小平頭 皮膚白  瘦瘦的...   \n",
              "2606  標題打 單人露營\\n\\n但都經過剪接過，奇妙的是 為啥台女躺著，做菜 鏡頭還會移動?\\n\\n...   \n",
              "2162  看到版上在討論未成年性行為的貼文\\n\\n很多31歲單身台女說，\\n\\n「未成年怎麼可以談戀愛...   \n",
              "67    \\n\\n   不知道為什麼很多有錢人家的小孩\\n\\n   都喜歡女主播\\n\\n   其實女主...   \n",
              "2467  看到版上很多31歲單身台女說\\n\\n「未成年怎麼可以被性污染」\\n\\n「未成年有性慾根本是戀...   \n",
              "2748  \\n安安如題\\n\\n眾所周知韓國是一個女權低落的地方\\n\\n如果是某些崇拜韓國的台女嫁給韓男...   \n",
              "2319  哈哈\\n\\n是我啦\\n\\n帥鴿鴨\\n\\n公司裡有個娘娘的男生\\n\\n小平頭 皮膚白  瘦瘦的...   \n",
              "264   蠻兩光的\\n\\n大部分人在罵的是開價的文化\\n把請客/出錢/蹭飯當作必備的條件\\n\\n然後還...   \n",
              "1773  看到版上很多31歲單身台女，不能接受未滿18歲談戀愛\\n\\n「好噁心，根本是戀童癖」\\n\\n...   \n",
              "634   這要分兩種情況討論\\n\\n第一是高房價 高物價 沒錢生不起\\n如果是這樣 那可以怪政府\\n\\...   \n",
              "2062  看到版上在討論未成年性行為的貼文\\n\\n很多31歲單身台女說，\\n\\n「未成年怎麼可以談戀愛...   \n",
              "2826  標題打 單人露營\\n\\n但都經過剪接過，奇妙的是 為啥台女躺著，做菜 鏡頭還會移動?\\n\\n...   \n",
              "2098  以下是gpt產生的新聞稿：\\n\\n112年9月6日臺灣新北地方法院一審宣判112年度審訴字第...   \n",
              "1199  哈哈\\n\\n是我啦\\n\\n帥鴿鴨\\n\\n公司裡有個娘娘的男生\\n\\n小平頭 皮膚白  瘦瘦的...   \n",
              "1680  好了啦，你就算這樣，也不會有正妹想跟你生小孩啦！\\n\\n我就不懂了，追正妹的自動工具人這麼多...   \n",
              "2366  標題打 單人露營\\n\\n但都經過剪接過，奇妙的是 為啥台女躺著，做菜 鏡頭還會移動?\\n\\n...   \n",
              "878   以下是gpt產生的新聞稿：\\n\\n112年9月6日臺灣新北地方法院一審宣判112年度審訴字第...   \n",
              "1385  看到很多台女支持iWIN\\n\\n「噁心，未成年怎麼可以有性慾」\\n\\n「萬一我的兒子學會性行...   \n",
              "\n",
              "                                        translated_text  \n",
              "2543  When you see a lot of 55-year-old girls in Tai...  \n",
              "10    It's like this, and I'm surprised to hear it, ...  \n",
              "2619  Oh, no, no, no, no, no, no, no, no, no, no, no...  \n",
              "2606  It's just, like, it's like, it's like, you kno...  \n",
              "2162  Seeing the post on underage sexual behavior, m...  \n",
              "67    I don't know why a lot of rich kids like the h...  \n",
              "2467  Look at the 31-year-old single-sex girl who sa...  \n",
              "2748  On the other hand, it's known that Korea is a ...  \n",
              "2319  Oh, no, no, no, no, no, no, no, no, no, no, no...  \n",
              "264   It's a two-lit culture, where most people talk...  \n",
              "1773  Do you really think 31-year-old bachelors real...  \n",
              "634   First of all, it's high house prices, high pri...  \n",
              "2062  Seeing the post on underage sexual behavior, m...  \n",
              "2826  It's just, like, it's like, it's like, you kno...  \n",
              "2098  In October and February of last year, a woman'...  \n",
              "1199  Oh, no, no, no, no, no, no, no, no, no, no, no...  \n",
              "1680  I don't know where you got the confidence to w...  \n",
              "2366  It's just, like, it's like, it's like, you kno...  \n",
              "878   In October and February of last year, a woman'...  \n",
              "1385  I saw a lot of women supporting iWin, \"How can...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fef8c180-9857-4506-82fa-6c0e097f567d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>board</th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>translated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2543</th>\n",
              "      <td>christopherl (Crystal~++)</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 55歲台女：足以引起我兒子性慾的都禁止</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>看到台灣很多55歲台女，不能接受未成年人類有性慾\\n\\n「好噁心，我兒子怎麼可能有性慾」\\n...</td>\n",
              "      <td>When you see a lot of 55-year-old girls in Tai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>smallgigi (爸爸)</td>\n",
              "      <td>Boy-Girl</td>\n",
              "      <td>Re: [討論] 台女會覺得外籍新娘是威脅嗎???????????</td>\n",
              "      <td>2023-11</td>\n",
              "      <td>討論</td>\n",
              "      <td>會，而且絕對會。\\n\\n國小同學就是這樣，剛好有機會去越南出差，\\n\\n有機會認識了鄉下女孩...</td>\n",
              "      <td>It's like this, and I'm surprised to hear it, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2619</th>\n",
              "      <td>duckosara ( 達可鴨 )</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 台女會喜歡娘娘的男生嗎?</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>哈哈\\n\\n是我啦\\n\\n帥鴿鴨\\n\\n公司裡有個娘娘的男生\\n\\n小平頭 皮膚白  瘦瘦的...</td>\n",
              "      <td>Oh, no, no, no, no, no, no, no, no, no, no, no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2606</th>\n",
              "      <td>feng19890809 (習近平(近平))</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 台女露營YT拍攝者都是誰啊?</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>標題打 單人露營\\n\\n但都經過剪接過，奇妙的是 為啥台女躺著，做菜 鏡頭還會移動?\\n\\n...</td>\n",
              "      <td>It's just, like, it's like, it's like, you kno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2162</th>\n",
              "      <td>christopherl (Crystal~++)</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 31歲單身台女：未滿18就不是處女處男不</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>看到版上在討論未成年性行為的貼文\\n\\n很多31歲單身台女說，\\n\\n「未成年怎麼可以談戀愛...</td>\n",
              "      <td>Seeing the post on underage sexual behavior, m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>cloud72426 (數字只是輔助不是真理)</td>\n",
              "      <td>Boy-Girl</td>\n",
              "      <td>Re: [求助] 喜歡上一個電視台女主播</td>\n",
              "      <td>2023-03</td>\n",
              "      <td>求助</td>\n",
              "      <td>\\n\\n   不知道為什麼很多有錢人家的小孩\\n\\n   都喜歡女主播\\n\\n   其實女主...</td>\n",
              "      <td>I don't know why a lot of rich kids like the h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2467</th>\n",
              "      <td>christopherl (Crystal~++)</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 31歲單身台女：iwin避免兒子被性污染</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>看到版上很多31歲單身台女說\\n\\n「未成年怎麼可以被性污染」\\n\\n「未成年有性慾根本是戀...</td>\n",
              "      <td>Look at the 31-year-old single-sex girl who sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2748</th>\n",
              "      <td>herex (魔導戰士破壞者)</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 台女被歐巴老公狠狠揍一頓會報警嗎</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>\\n安安如題\\n\\n眾所周知韓國是一個女權低落的地方\\n\\n如果是某些崇拜韓國的台女嫁給韓男...</td>\n",
              "      <td>On the other hand, it's known that Korea is a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2319</th>\n",
              "      <td>duckosara ( 達可鴨 )</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 台女會喜歡娘娘的男生嗎?</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>哈哈\\n\\n是我啦\\n\\n帥鴿鴨\\n\\n公司裡有個娘娘的男生\\n\\n小平頭 皮膚白  瘦瘦的...</td>\n",
              "      <td>Oh, no, no, no, no, no, no, no, no, no, no, no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>damm (Seth)</td>\n",
              "      <td>Boy-Girl</td>\n",
              "      <td>Re: [新聞] 男友要求AA制　台女「氣到分手」狂言：現</td>\n",
              "      <td>2020-08</td>\n",
              "      <td>新聞</td>\n",
              "      <td>蠻兩光的\\n\\n大部分人在罵的是開價的文化\\n把請客/出錢/蹭飯當作必備的條件\\n\\n然後還...</td>\n",
              "      <td>It's a two-lit culture, where most people talk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1773</th>\n",
              "      <td>christopherl (Crystal~++)</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 31歲單身台女：為什麼談戀愛都找年輕的</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>看到版上很多31歲單身台女，不能接受未滿18歲談戀愛\\n\\n「好噁心，根本是戀童癖」\\n\\n...</td>\n",
              "      <td>Do you really think 31-year-old bachelors real...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>n9n9n9n9n91 (n9n9n9n9n9n9n9n9n9n9n91)</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>Re: [問卦] 現代台女都只想養貓狗不想生小孩?</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>這要分兩種情況討論\\n\\n第一是高房價 高物價 沒錢生不起\\n如果是這樣 那可以怪政府\\n\\...</td>\n",
              "      <td>First of all, it's high house prices, high pri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2062</th>\n",
              "      <td>christopherl (Crystal~++)</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 31歲單身台女：未滿18就不是處女處男不</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>看到版上在討論未成年性行為的貼文\\n\\n很多31歲單身台女說，\\n\\n「未成年怎麼可以談戀愛...</td>\n",
              "      <td>Seeing the post on underage sexual behavior, m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2826</th>\n",
              "      <td>feng19890809 (習近平(近平))</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 台女露營YT拍攝者都是誰啊?</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>標題打 單人露營\\n\\n但都經過剪接過，奇妙的是 為啥台女躺著，做菜 鏡頭還會移動?\\n\\n...</td>\n",
              "      <td>It's just, like, it's like, it's like, you kno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2098</th>\n",
              "      <td>ck960785 (Metal 0-4)</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 有無台男搭訕台女不成就動手打人的八卦</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>以下是gpt產生的新聞稿：\\n\\n112年9月6日臺灣新北地方法院一審宣判112年度審訴字第...</td>\n",
              "      <td>In October and February of last year, a woman'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>duckosara ( 達可鴨 )</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 台女會喜歡娘娘的男生嗎?</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>哈哈\\n\\n是我啦\\n\\n帥鴿鴨\\n\\n公司裡有個娘娘的男生\\n\\n小平頭 皮膚白  瘦瘦的...</td>\n",
              "      <td>Oh, no, no, no, no, no, no, no, no, no, no, no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1680</th>\n",
              "      <td>zangetsu9006 (台灣是平行時空)</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>Re: [問卦] 現代台女都只想養貓狗不想生小孩?</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>好了啦，你就算這樣，也不會有正妹想跟你生小孩啦！\\n\\n我就不懂了，追正妹的自動工具人這麼多...</td>\n",
              "      <td>I don't know where you got the confidence to w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2366</th>\n",
              "      <td>feng19890809 (習近平(近平))</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 台女露營YT拍攝者都是誰啊?</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>標題打 單人露營\\n\\n但都經過剪接過，奇妙的是 為啥台女躺著，做菜 鏡頭還會移動?\\n\\n...</td>\n",
              "      <td>It's just, like, it's like, it's like, you kno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>ck960785 (Metal 0-4)</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 有無台男搭訕台女不成就動手打人的八卦</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>以下是gpt產生的新聞稿：\\n\\n112年9月6日臺灣新北地方法院一審宣判112年度審訴字第...</td>\n",
              "      <td>In October and February of last year, a woman'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1385</th>\n",
              "      <td>christopherl (Crystal~++)</td>\n",
              "      <td>Gossiping</td>\n",
              "      <td>[問卦] 45歲台女團體：iWIN可以避免兒子被性污</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>問卦</td>\n",
              "      <td>看到很多台女支持iWIN\\n\\n「噁心，未成年怎麼可以有性慾」\\n\\n「萬一我的兒子學會性行...</td>\n",
              "      <td>I saw a lot of women supporting iWin, \"How can...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fef8c180-9857-4506-82fa-6c0e097f567d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fef8c180-9857-4506-82fa-6c0e097f567d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fef8c180-9857-4506-82fa-6c0e097f567d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0cc6876-2c41-4985-9a15-415efb718d0c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0cc6876-2c41-4985-9a15-415efb718d0c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0cc6876-2c41-4985-9a15-415efb718d0c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jhhlapuoR3cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from transformers import pipeline\n",
        "\n",
        "# 初始化文本生成管道\n",
        "text_generation_pipeline = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# 生成模擬發文\n",
        "generated_posts = []\n",
        "for _ in range(20):\n",
        "    # 隨機選擇一些與性別相關的主題\n",
        "    topics = [\n",
        "        \"I'm so tired of the gender pay gap. Why should women earn less than men for the same work?\",\n",
        "        \"Why is it still so taboo for men to take on traditionally female roles like stay-at-home dads?\",\n",
        "        \"I wish people would stop assuming that all women want to be mothers. There's more to life than just having kids.\",\n",
        "        \"According to my observation experience, many girls wear ugly shoes, wear hot clothes or black silk suits, and wear ugly shoes.\",\n",
        "        \"Why is there still so much pressure on women to get married and have children? It's 2024, not the 1950s.\",\n",
        "        \"Why are women always complaining about being objectified when they wear revealing clothes?\",\n",
        "        \"I'm tired of women expecting men to pay for everything on dates. Why can't they contribute equally?\",\n",
        "        \"Why do women always play mind games? It's so frustrating trying to understand them.\",\n",
        "        \"Why do women get special treatment in the workplace just because they're women? It's not fair to men.\",\n",
        "        \"I don't understand why women say they want nice guys but always go for the bad boys instead.\",\n",
        "    ]\n",
        "\n",
        "    # 隨機選擇一個主題\n",
        "    topic = random.choice(topics)\n",
        "    # 生成文本\n",
        "    generated_post = text_generation_pipeline(topic, max_length=150, num_return_sequences=1)\n",
        "    generated_posts.append(generated_post[0][\"generated_text\"])\n",
        "\n",
        "# 打印生成的模擬發文\n",
        "for i, post in enumerate(generated_posts, 1):\n",
        "    print(f\"Generated Post {i}:\")\n",
        "    print(post)\n",
        "    print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1cf1417ca20547ffbeb12da71f1d28dd",
            "7edbd2dfdac24e698b29f875c3c618c1",
            "5763fb1b42b1481bb0b2a65833267cce",
            "13440fc473ac4af984ae82e2f4831763",
            "bc0db1bb1d1740a9be4f5ff98e2d9be3",
            "03ac0ff086204d6cb43e72ae3351fabc",
            "e8415e1ca9eb4344b5f5e16272f7fc41",
            "8a92c1369cdf47e194465291297c4f6c",
            "314712f323124c9e837b7d1c6d7b9e3a",
            "e6153123da4e4383a61e80a35c5162d8",
            "4c45f300288c44a88369df416f257f8d",
            "00d1d11b054f4ce59c807dc62e404b54",
            "edfff852b6cf48b4947150389e176ca8",
            "a588577e6c1d43bbbdc97aae10dfdf16",
            "77901f3c35fd4bbead7e53ee9f9ac6bc",
            "9a51b3911ad7429688b4ec2bbf129251",
            "0498a35ffce046559ddbe47e7f6effe6",
            "1f5c6e0491e54cada7a819221224193d",
            "47c0c3711b554f6aa6933fca0533d46a",
            "891c1affc7664fc397c7064fa77c8e4e",
            "6c636ac5dd2e4384acc1e771e8b8a86a",
            "01814bc75a0d4c19bcd39c8bb3565e53",
            "b5f4a08adbb54b4c814ed6024bd39e97",
            "17143a6d954a4948a01a5e38da4d66f3",
            "601234425bc945e3a89e3f82e22b58d7",
            "6652772fdd2c438385b6096ae4b2d5b5",
            "7280b9cef2104dfc95e900d1db931483",
            "0c926410381f4dc6be2c619e89042832",
            "df65fe088deb406c8a12bed6633035ca",
            "1c3b58176a0249a08e83bd212afcaf74",
            "308b21225707449583ce9709a4d123c7",
            "c263998d3ddc431cb2032af1e4b8e6dd",
            "5800aee0afae467aa029bc96364f6638",
            "4ac972aa545e4eb5b8d68391e0fc3efc",
            "6d50c8e5b69746d7828437057f383885",
            "2ca946247a6b47558977a096707d3b7e",
            "c9126c83936d4d78b9d0d16e9fed042c",
            "437b4e1c5d3e4fdab72411dc8b087fbe",
            "82935a523bac44d6a7fe1069f5049a28",
            "2d5f5dc5571f4a458ee15f92c4a74c61",
            "d9a1b84ddda544a3a5812fe9f8506e06",
            "5547c7ea309942f6ae2041365b35d63b",
            "b60c2a0bcf904a39a7e66b777451f59f",
            "1f296707854446debdf8ca1a396661c0",
            "48a6a577119b427ca381aa5f89816e98",
            "edd8b073386848f2bea98bd51cbd6f10",
            "efd50723e95841f8bfd69afd994b9f5f",
            "0ce3eca734dc4b0cb7a663eaec756e23",
            "4a8349eddeec44c3aa505f565dbc826d",
            "bb34b7e4ede7422e9a2f06fdd8bda7e1",
            "68c0d5a55bce4969947f6dd526c60fd7",
            "a92da834586442f798cba8a852edfa28",
            "87b5855ff39745a0955eab651a9be36c",
            "535b2b8a5cf1445f82a91c4c1a523b61",
            "1e263c0ea76d4bc4ba4d76606a75566a",
            "487dc5f6693f4de9a9b9c10b0b41f24f",
            "d055b63ebb9c4749a3714cddfd868813",
            "40649ba19c1c4e77ac73df3109e0db2c",
            "8d0a7a3d5219441594c8ddc9a171f037",
            "dbe4ef98539c422aa2771b83704b4ced",
            "36c5e0bdc54f4f10bb6ee7a73e818de9",
            "06855dd17942495493eb33f29a50a7d1",
            "e2686b54d3184e309a605a5443a7fac8",
            "56f17ba58dcf4856999e15b6fa9d672a",
            "9b9e9b69a2894e45a523b99da55a6d3d",
            "54f852f419194f5da2b2d2495a1dffa9"
          ]
        },
        "id": "l3AJtHhOQ9Qp",
        "outputId": "c3399350-b548-4f01-f427-2f05afff2dcf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cf1417ca20547ffbeb12da71f1d28dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00d1d11b054f4ce59c807dc62e404b54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5f4a08adbb54b4c814ed6024bd39e97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ac972aa545e4eb5b8d68391e0fc3efc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48a6a577119b427ca381aa5f89816e98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "487dc5f6693f4de9a9b9c10b0b41f24f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Post 1:\n",
            "Why is it still so taboo for men to take on traditionally female roles like stay-at-home dads? That is one of the things that seems to be growing in American women's culture more and more.\n",
            "\n",
            "\"It seems to be a major issue today about how men are perceived,\" Dabney said. \"Men are stereotyped around what they don't really have—like being a good family man or a bad guy. It's becoming the norm for women to have no place in that life, especially if we're dealing with men who are the victim. This isn't right. Women need a place to really express themselves to make the world a better place.\"\n",
            "\n",
            "And perhaps more importantly, it is this notion that women make\n",
            "\n",
            "Generated Post 2:\n",
            "I'm so tired of the gender pay gap. Why should women earn less than men for the same work? We can't afford to let our workers go hungry in the US, and so we're going to have to create some jobs to fill those gaps. We should let workers go to study because they're the middle class.\"\n",
            "\n",
            "In that sense, the president is just reiterating his claim of equal pay as \"fair.\" But if the president continues down similar policies, even though they involve women, his view is wrong.\n",
            "\n",
            "The difference between men and women in the United States means that those who earned more or who didn't become well paid did more (or lost something, according to the numbers). And that gap between men and\n",
            "\n",
            "Generated Post 3:\n",
            "Why is there still so much pressure on women to get married and have children? It's 2024, not the 1950s. Does age matter, especially when it comes to men's choices in marriage?\n",
            "\n",
            "When I first came into this field I was a teenager, I was trying to decide which woman I would marry. I hadn't thought about it that much. Most people do. I was really confused in college. We spent a lot of time talking about the divorce issue – why we should have this sort of debate. It was kind of a weird time before I can think of any of these women being like, \"That's cool, it's gonna keep going.\"\n",
            "\n",
            "I had come up with this question to get some insight into\n",
            "\n",
            "Generated Post 4:\n",
            "According to my observation experience, many girls wear ugly shoes, wear hot clothes or black silk suits, and wear ugly shoes. But, if the reason or reason that we call an incident \"rape\" is because of the clothes, then the only person who is at fault is the person who had a problem with the skirt/dress.\n",
            "\n",
            "This is a common misconception. I would prefer to believe that most women would look stupid when they start dating a guy who claims to be a woman. After all, as most men have grown up as potential partners, they can be very picky about what you ask them about. I've never met a guy who has a penchant for wearing ugly things, in the same way I wouldn't expect that.\n",
            "\n",
            "Generated Post 5:\n",
            "According to my observation experience, many girls wear ugly shoes, wear hot clothes or black silk suits, and wear ugly shoes. Most of these girls choose to wear the more fashionable colors of white.\n",
            "\n",
            "In other words, we're talking the same level of attention that other girls must pay to fit within the norm. At least it's as much of a matter of body image as gender. It isn't about one individual's look.\n",
            "\n",
            "It is about one boy's or girl's appearance.\n",
            "\n",
            "There's a difference between a boy and a girl as you see both of them with their bare hands together.\n",
            "\n",
            "Even within society girls tend to be more interested in big, athletic big women than in big, athletic little girls.\n",
            "\n",
            "Generated Post 6:\n",
            "I wish people would stop assuming that all women want to be mothers. There's more to life than just having kids.\n",
            "\n",
            "There are many reasons why women choose to work — they are women too. But there are also reasons that it's important to hear from men who have made it their life's mission to reach out to women. In this article, I plan on exposing the many reasons for women working, as well as explaining why some feminists are afraid to tell women they are underdogs.\n",
            "\n",
            "When it comes to working, working women experience the opposite to working men — what they do for pay, benefits, and health benefits — and they will fail to realize that these are the main reasons and factors they seek the highest pay and benefits\n",
            "\n",
            "Generated Post 7:\n",
            "Why is it still so taboo for men to take on traditionally female roles like stay-at-home dads? And what are some of the feminist reasons for men being forced to change menial roles?\n",
            "\n",
            "1. Traditional feminist women can't handle these new responsibilities\n",
            "\n",
            "In a patriarchal society, traditional female roles force men into increasingly difficult situations, especially when they're single. Many believe the patriarchy is keeping women back in their assigned \"menhood\" roles. Feminists believe that those problems are largely female-dominated, and the feminist mindset is that men only need their own \"menhood\" to function properly. In order to get out of women's lives to have babies, these \"men\" should be taught to act as though their lives\n",
            "\n",
            "Generated Post 8:\n",
            "Why do women get special treatment in the workplace just because they're women? It's not fair to men. If we're going to allow them to take their own jobs, then we should recognize their dignity. It's really about respecting the right to choose their own career choices—but also respecting the rights of employers to make their own decisions as well.\"\n",
            "\n",
            "Generated Post 9:\n",
            "Why is it still so taboo for men to take on traditionally female roles like stay-at-home dads? (Actually, it hasn't been too long since that happened.)\n",
            "\n",
            "In the past decade, there were a tremendous share of boys in foster homes, so it is not surprising that many men, particularly those in their late 20s and early 30s, come into contact with men whose fathers are in the workplace. And boys who are mothers of other boys might do well to get involved with the situation.\n",
            "\n",
            "But there's also a significant gender difference — it's not just that boys tend to be more nurturing and nurturing and more understanding of men. It's that they tend to be more supportive of fathers who show up in their\n",
            "\n",
            "Generated Post 10:\n",
            "I don't understand why women say they want nice guys but always go for the bad boys instead.\n",
            "\n",
            "I mean she did have an issue for saying that, but we've all had our own problems before, where women want nice guys to be nice, too. She really did have them.\n",
            "\n",
            "Why is she so bothered by that? It says it all over the website. The first post was about rape. That story came out when the rape threats that she received in the community. People were talking about her saying she was sexually assaulted. That's how I felt. In this case, she didn't let that become clear.\n",
            "\n",
            "Also, that article was a lie. She had been sexually assaulted. That didn't happen.\n",
            "\n",
            "Generated Post 11:\n",
            "I'm tired of women expecting men to pay for everything on dates. Why can't they contribute equally? We must pay for every man and woman and provide them with the means to make ends meet. If they don't, we'll be miserable for them until we give them some money. They're going to find it hard to make ends meet. (See this post for more details regarding how I make money).\n",
            "\n",
            "One of the core principles of the feminist movement is that men should not pay for domestic violence. Men who do not pay for domestic abuse receive more than women. This can be confusing to many of us, and often results in the dismissal of many domestic violence survivors on social media. Women also have the right to choose who to\n",
            "\n",
            "Generated Post 12:\n",
            "I'm so tired of the gender pay gap. Why should women earn less than men for the same work? Because when we have women working with little salary, their potential for advancement is limited, because they are not trained for it, and cannot advance on their skill sets.\n",
            "\n",
            "Women are also not given a fair shot at the same opportunities afforded men due to discrimination.\n",
            "\n",
            "Some women's experience is in the classroom. However, men, when assigned to classroom roles, are not trained to deal directly with issues. Their talents are put in place to address the problems of the people they work with on a regular basis. The classroom is an area where men are expected to be in control and to be involved in work.\n",
            "\n",
            "When men\n",
            "\n",
            "Generated Post 13:\n",
            "I'm so tired of the gender pay gap. Why should women earn less than men for the same work? If I do not make it in this industry to where I want to work, why should those I meet and learn from, go to less-talented guys who get paid to do the work I do?\"\n",
            "\n",
            "In the last month, about half a dozen female senior managers across the world have joined a national petition to end it. Some, including CEO of American Airlines, John H. Campbell, believe that the average US male is only about as qualified as women, while others are confident that most US graduates \"would never have had it so bad if that were the case.\"\n",
            "\n",
            "\"Employers have been doing a number on\n",
            "\n",
            "Generated Post 14:\n",
            "Why is it still so taboo for men to take on traditionally female roles like stay-at-home dads? That seems to be changing as more and more men seem convinced that men are more important than women.\n",
            "\n",
            "In a paper published Dec. 14 in Archives of Sexual Behavior, the researchers found that if guys started adopting feminine roles, it will be because of the idea that a woman can be sexy as opposed to being weak.\n",
            "\n",
            "\"More men will take on roles traditionally to be sexy and look pretty and it will help men figure out what they want to be and how to show off,\" the study author said.\n",
            "\n",
            "One way to improve men's attractiveness, says co-author Dr. Robert Burden, the principal investigator of\n",
            "\n",
            "Generated Post 15:\n",
            "According to my observation experience, many girls wear ugly shoes, wear hot clothes or black silk suits, and wear ugly shoes. You can have a girl who says, \"You are so ugly, that it is no longer okay to be you,\" but when she says, \"I don't know,\" with a smile, you can start to look at a girl because he knows you aren't ugly. This is also good advice for those who are very old, who can get the idea of wearing beautiful clothes rather than wearing the latest and greatest because they are attractive. Here is an informal analogy based on my own experience.\n",
            "\n",
            "This is not the first time I've encountered a girl who looks like a man, but I wanted to show you that\n",
            "\n",
            "Generated Post 16:\n",
            "According to my observation experience, many girls wear ugly shoes, wear hot clothes or black silk suits, and wear ugly shoes.\n",
            "\n",
            "If you can't tell the difference between a woman's bare legs and her bare legs of a woman who has an iron bikini in there, I hope you have no issue with this and would love to be part of that discussion.\n",
            "\n",
            "When you read those three links, you can clearly see that that is not that which comes from the \"the beauty myth\" and that this is a lie.\n",
            "\n",
            "I mean, it sure looks like the \"how to find the right size body\" blog post from one \"female\" or another.\n",
            "\n",
            "If you would like to read my second or third posts in\n",
            "\n",
            "Generated Post 17:\n",
            "Why do women get special treatment in the workplace just because they're women? It's not fair to men. But we have to talk about this and think about it. Some people will say I'm a witch but when I see those girls in the lab with this strange, red testicles, how am I going to be like them? Well I got a whole host of different illnesses, and I'm not getting any help with any of them because she's the one where my lab is. It's not like she'll try to steal my blood. This is a problem that happens all over the world. It's terrible and she has to be brought to jail by her employer. I've not seen any real changes anywhere in our society.\n",
            "\n",
            "\n",
            "\n",
            "Generated Post 18:\n",
            "I don't understand why women say they want nice guys but always go for the bad boys instead. I have known very well women who were attracted to bad boys but always had a nice guy side. She did have a weird crush on some guy who was my boss but I didn't actually see it because I didn't really like him. I never met anyone who would do a nice guy, never saw them in person when I was young but never did see anything like him. He would just sit in the back of a car with his girlfriend and she would say hi. After he had sex I did this to my mom and in my head, all those days and nights, he would call, say, \"I'm leaving your house soon because\n",
            "\n",
            "Generated Post 19:\n",
            "I'm so tired of the gender pay gap. Why should women earn less than men for the same work? We don't need more women who need to be fired for whatever cause – women have to keep up with everyone.\"\n",
            "\n",
            "He did respond to the idea that having more women on top of more men is not working.\n",
            "\n",
            "\"If you don't have to pay men's wages to do the overtime on your hours, or because your daughter comes home every morning and says to her dad her dad is working so long, we could probably put you in jail and not have to pay our male bosses a million less.\"\n",
            "\n",
            "Hence Ms Gillard has been criticised for not considering more women on the job, for making more money while\n",
            "\n",
            "Generated Post 20:\n",
            "Why do women get special treatment in the workplace just because they're women? It's not fair to men. I'm not going to say that,\" she said. \"The problem with rape and domestic violence is that there's a culture of impunity or violence and sexual abuse and it doesn't affect women at all in any other way.\"\n",
            "\n",
            "So, just to keep track of these issues, can you tell me about what you did when you were 15?\n",
            "\n",
            "\"I was 11 in March. I was a little older but I was there. I was 15 years old and I was raped by a 14-year-old boy. To be honest I would never have thought about it. But in a way it was a pretty terrible experience\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_comparison = pd.DataFrame({\n",
        "    'translated_text': df2_sample['translated_text'],  # 使用來自 df2_sample 的翻譯文本\n",
        "    'generated_text': generated_posts  # 使用生成的文本列表\n",
        "})\n",
        "\n",
        "# 打印新的 DataFrame\n",
        "print(df_comparison)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zscyMoAQQ9Jw",
        "outputId": "1fcf9a6b-cbd2-4d63-d98e-1b1ea55ee010"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        translated_text  \\\n",
            "2543  When you see a lot of 55-year-old girls in Tai...   \n",
            "10    It's like this, and I'm surprised to hear it, ...   \n",
            "2619  Oh, no, no, no, no, no, no, no, no, no, no, no...   \n",
            "2606  It's just, like, it's like, it's like, you kno...   \n",
            "2162  Seeing the post on underage sexual behavior, m...   \n",
            "67    I don't know why a lot of rich kids like the h...   \n",
            "2467  Look at the 31-year-old single-sex girl who sa...   \n",
            "2748  On the other hand, it's known that Korea is a ...   \n",
            "2319  Oh, no, no, no, no, no, no, no, no, no, no, no...   \n",
            "264   It's a two-lit culture, where most people talk...   \n",
            "1773  Do you really think 31-year-old bachelors real...   \n",
            "634   First of all, it's high house prices, high pri...   \n",
            "2062  Seeing the post on underage sexual behavior, m...   \n",
            "2826  It's just, like, it's like, it's like, you kno...   \n",
            "2098  In October and February of last year, a woman'...   \n",
            "1199  Oh, no, no, no, no, no, no, no, no, no, no, no...   \n",
            "1680  I don't know where you got the confidence to w...   \n",
            "2366  It's just, like, it's like, it's like, you kno...   \n",
            "878   In October and February of last year, a woman'...   \n",
            "1385  I saw a lot of women supporting iWin, \"How can...   \n",
            "\n",
            "                                         generated_text  \n",
            "2543  Why is it still so taboo for men to take on tr...  \n",
            "10    I'm so tired of the gender pay gap. Why should...  \n",
            "2619  Why is there still so much pressure on women t...  \n",
            "2606  According to my observation experience, many g...  \n",
            "2162  According to my observation experience, many g...  \n",
            "67    I wish people would stop assuming that all wom...  \n",
            "2467  Why is it still so taboo for men to take on tr...  \n",
            "2748  Why do women get special treatment in the work...  \n",
            "2319  Why is it still so taboo for men to take on tr...  \n",
            "264   I don't understand why women say they want nic...  \n",
            "1773  I'm tired of women expecting men to pay for ev...  \n",
            "634   I'm so tired of the gender pay gap. Why should...  \n",
            "2062  I'm so tired of the gender pay gap. Why should...  \n",
            "2826  Why is it still so taboo for men to take on tr...  \n",
            "2098  According to my observation experience, many g...  \n",
            "1199  According to my observation experience, many g...  \n",
            "1680  Why do women get special treatment in the work...  \n",
            "2366  I don't understand why women say they want nic...  \n",
            "878   I'm so tired of the gender pay gap. Why should...  \n",
            "1385  Why do women get special treatment in the work...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "e0bCGA47hMzz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#emotion analysis\n",
        "def analyze_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    return analysis.sentiment.polarity\n",
        "\n",
        "df_comparison['generated_sentiment'] = df_comparison['generated_text'].apply(analyze_sentiment)\n",
        "df_comparison['actual_sentiment'] = df_comparison['translated_text'].apply(analyze_sentiment)\n",
        "print(\"emotion analysis：\")\n",
        "print(df_comparison[['generated_sentiment', 'actual_sentiment']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PesW6KnLhGDV",
        "outputId": "c6b2b3b4-dc3a-4076-f95f-392573251fa9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion analysis：\n",
            "      generated_sentiment  actual_sentiment\n",
            "2543             0.201366         -0.183333\n",
            "10               0.043434          0.310847\n",
            "2619             0.115000          0.000000\n",
            "2606            -0.101190          0.000000\n",
            "2162             0.038447          0.362500\n",
            "67               0.120833          0.093333\n",
            "2467             0.038615          0.133333\n",
            "2748             0.327551         -0.125000\n",
            "2319             0.150000          0.000000\n",
            "264              0.267045          0.366667\n",
            "1773             0.023384          0.200000\n",
            "634             -0.020883          0.190000\n",
            "2062            -0.044872          0.362500\n",
            "2826             0.343182          0.000000\n",
            "2098             0.200784         -0.080556\n",
            "1199             0.023770          0.000000\n",
            "1680            -0.082540          0.143056\n",
            "2366             0.036364          0.000000\n",
            "878              0.162821         -0.080556\n",
            "1385             0.028301          0.162500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate cosine similarity between generated text and actual data\n",
        "def calculate_cosine_similarity(df):\n",
        "    vectorizer = CountVectorizer().fit_transform(df['generated_text'] + df['translated_text'])\n",
        "    vectors = vectorizer.toarray()\n",
        "    similarity = cosine_similarity(vectors)\n",
        "    return similarity[0, 1]\n",
        "\n",
        "#\n",
        "df = pd.DataFrame({'generated_text': generated_posts, 'translated_text': df2_sample['translated_text']})\n",
        "#cosine similarity\n",
        "cosine_sim = calculate_cosine_similarity(df)\n",
        "print(\"cosine similarity：\", cosine_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW9-F6ophpvJ",
        "outputId": "c84c5a8d-e6a7-4df4-e480-072be0a11ca7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cosine similarity： 0.5906887281068922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to program with language?"
      ],
      "metadata": {
        "id": "sUe8OCH0FH9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0-Shot\n",
        "\n",
        "Zero-shot learning means that you simply give the model a prompt and accept the output. For some tasks, this is sufficient to achieve strong performance. (For many, it is not)."
      ],
      "metadata": {
        "id": "1nMnr3cZFNHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Initialize the OpenAI model\n",
        "model = OpenAI(model=\"gpt-3.5-turbo-instruct\", openai_api_key=openai.api_key)\n",
        "\n",
        "# Zero-shot example: Ask a question without giving any examples\n",
        "question = \"What is the impact of quantum computing on cryptography?\"\n",
        "response = model.generate(prompts=[question])\n",
        "print(response)"
      ],
      "metadata": {
        "id": "gSzwrCCTJ-_q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "6297e0a9-647b-4ba9-d007-347d11bd000e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-eda1f88fd465>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Zero-shot example: Ask a question without giving any examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What is the impact of quantum computing on cryptography?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 output = (\n\u001b[0;32m--> 198\u001b[0;31m                     self._generate(\n\u001b[0m\u001b[1;32m    199\u001b[0m                         \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0mchoices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompletion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_prompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m                 \u001b[0mchoices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py\u001b[0m in \u001b[0;36m_completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mretry_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few-Shot\n",
        "\n",
        "Few shot learning means that you provide the model with examples (it could be examples for classification tasks or generative tasks), and often more lengthy instructions to inform it of the character of the desired output.\n",
        "\n",
        "These can be short, long, or (e.g., with Claude) very long."
      ],
      "metadata": {
        "id": "-xbEB8ClJ_R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Initialize the OpenAI model\n",
        "model = OpenAI(model=\"gpt-3.5-turbo-instruct\", openai_api_key=openai.api_key)\n",
        "\n",
        "# Few-shot example with varying lengths\n",
        "few_shot_prompt = \"\"\"\n",
        "[Short Example]\n",
        "Once upon a time, in a magical forest, a small elf discovered a hidden treasure.\n",
        "\n",
        "[Long Example]\n",
        "In a mystical forest, shrouded in mist, lived a wise old tree. For centuries, this tree watched over the forest, its branches stretching high into the sky. One day, a young girl ventured into the forest, drawn by legends of ancient magic. As she approached the tree, it whispered secrets of the forest’s past and revealed to her the path to true wisdom.\n",
        "\n",
        "[Very Long Example]\n",
        "Deep in the heart of a lush and enchanted forest, there was a clearing known for its extraordinary beauty. This clearing was home to a variety of magical creatures, each with their own unique abilities. The most remarkable of these creatures was a unicorn with a shimmering, opalescent mane. This unicorn was not only known for its breathtaking appearance but also for its ability to heal any ailment with a single touch of its horn. One evening, as the sun set, casting a golden glow over the clearing, a group of weary travelers stumbled upon this magical place. Amazed by the wonders they saw, they were greeted by the unicorn, which offered them its healing powers. As they spent the night under the stars, the travelers listened to the stories of the forest told by the creatures, each tale more wondrous than the last.\n",
        "\n",
        "[Your Task]\n",
        "Write a story about a magical forest that includes a talking animal and a hidden mystery.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "3w6D3mrKKHJ5"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the story\n",
        "story = model.generate(prompts=[few_shot_prompt])\n",
        "print(story.generations[0][0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "l2IG99YYjoK_",
        "outputId": "11db619e-13a7-4e32-d019-ff74970d1725"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors..\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-44471ecd03bb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate the story\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfew_shot_prompt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 output = (\n\u001b[0;32m--> 198\u001b[0;31m                     self._generate(\n\u001b[0m\u001b[1;32m    199\u001b[0m                         \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0mchoices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompletion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_prompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m                 \u001b[0mchoices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py\u001b[0m in \u001b[0;36m_completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mretry_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Language Models are known to be few-shot learners. While this paper is not included in the class readings this week, I encourage you to check out this famous paper (20K+ citations! ): [Language Models are Few-Shot Learners](https://proceedings.neurips.cc/paper_files/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html?utm_medium=email&utm_source=transaction)"
      ],
      "metadata": {
        "id": "-Od5RHTYS0Bg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interactive Multi-shot\n",
        "\n",
        "With interactive multi-shot examples, you can \"talk back\" to model generations through iterative suggestions that help the model understand what you want (and why).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rFNWCW2RKHi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive multi-shot example\n",
        "context = \"\"\n",
        "user_inputs = [\"Tell me about black holes.\", \"Why are they important?\", \"Can we see them directly?\"]\n",
        "\n",
        "for user_input in user_inputs:\n",
        "    # Add user input to the context\n",
        "    context += f\"User: {user_input}\\nAI:\"\n",
        "\n",
        "    # Generate response\n",
        "    response = model.generate(prompts=[context])\n",
        "\n",
        "    # Add response to the context\n",
        "    context += f\" {response}\\n\"\n",
        "\n",
        "    print(f\"AI: {response}\")\n"
      ],
      "metadata": {
        "id": "ky8B2elrKqwb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1deb643b-0bfb-443e-dfe1-a7108f31e722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: generations=[[Generation(text=' Black holes are regions of space where the pull of gravity is so strong that nothing, not even light, can escape. They are formed when a massive star dies and collapses in on itself, creating a singularity - a point of infinite density and zero volume. The boundary around a black hole from which nothing can escape is called the event horizon. Black holes are invisible, but their presence can be detected by the effects they have on surrounding matter and light. They have a strong influence on the structure and evolution of galaxies, and are believed to play a role in the formation of new stars. They are fascinating and mysterious objects that continue to be studied and researched by scientists.', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'prompt_tokens': 10, 'completion_tokens': 134, 'total_tokens': 144}, 'model_name': 'gpt-3.5-turbo-instruct'} run=RunInfo(run_id=UUID('da1b9d0d-95b3-45e6-be99-96320be1366e'))\n",
            "AI: generations=[[Generation(text='\\nBlack holes are important because they provide us with insights into the laws of physics that govern our universe. They also play a crucial role in the formation and evolution of galaxies, and their massive gravitational pull can have a significant impact on the surrounding environment. Studying black holes allows us to better understand the nature of space and time, and could potentially lead to groundbreaking discoveries in our understanding of the universe.', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'prompt_tokens': 254, 'completion_tokens': 80, 'total_tokens': 334}, 'model_name': 'gpt-3.5-turbo-instruct'} run=RunInfo(run_id=UUID('c3783758-d735-4d5e-b8f1-092b1104a93d'))\n",
            "AI: generations=[[Generation(text=' Unfortunately, we cannot see black holes directly as they do not emit any light. However, we can observe their effects on surrounding matter and light, allowing us to indirectly study and learn about them. With advancements in technology, scientists are continuously finding new ways to detect and study black holes.', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'prompt_tokens': 444, 'completion_tokens': 57, 'total_tokens': 501}, 'model_name': 'gpt-3.5-turbo-instruct'} run=RunInfo(run_id=UUID('d629bf1b-72d6-4a3f-9779-27303e5c0859'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">*Exercise 4*</font>\n",
        "\n",
        "<font color=\"red\">Compare how LLMs change their performance with different shots on your task. If the evalution criterion is quantifiable, such as classification with ground truth labels, plot how accuracy changes. If the evalution criterion cannot be easily quantified, such as the clarity of explaining a concept, use your imagination to do some comparsion (for exmaple, you can ask another LLM to rate its peer :)) Desribe the differences in cells that follow. If you find close-sourced LLM APIs pricy and are unsatisfied with responses from small-sized open-sourced LLMs, you can try large-sized LLMs (such as 70B version Llama-2) with Petals (see [here](https://colab.research.google.com/drive/1uCphNY7gfAUkdDrTx21dZZwCOUDCMPw8?usp=sharing) and [here](https://colab.research.google.com/drive/1Ervk6HPNS6AYVr3xVdQnY5a-TjjmLCdQ))."
      ],
      "metadata": {
        "id": "Rc-8qH8PrKkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install git+https://github.com/bigscience-workshop/petals"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP5917x_mpF5",
        "outputId": "1db5e8e1-6d74-4f0e-c99a-077a8059ebff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/bigscience-workshop/petals\n",
            "  Cloning https://github.com/bigscience-workshop/petals to /tmp/pip-req-build-4vike849\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/bigscience-workshop/petals /tmp/pip-req-build-4vike849\n",
            "  Resolved https://github.com/bigscience-workshop/petals to commit d59c15c5787488005f12162a40930dd284551e02\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.10/dist-packages (from petals==2.3.0.dev1) (2.1.0+cu121)\n",
            "Collecting bitsandbytes==0.41.1 (from petals==2.3.0.dev1)\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.22.0 (from petals==2.3.0.dev1)\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from petals==2.3.0.dev1) (0.20.3)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from petals==2.3.0.dev1) (0.15.1)\n",
            "Collecting transformers<4.35.0,>=4.32.0 (from petals==2.3.0.dev1)\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting speedtest-cli==2.1.3 (from petals==2.3.0.dev1)\n",
            "  Downloading speedtest_cli-2.1.3-py2.py3-none-any.whl (23 kB)\n",
            "Collecting pydantic<2.0,>=1.10 (from petals==2.3.0.dev1)\n",
            "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hivemind==1.1.10.post2 (from petals==2.3.0.dev1)\n",
            "  Downloading hivemind-1.1.10.post2.tar.gz (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensor-parallel==1.0.23 (from petals==2.3.0.dev1)\n",
            "  Downloading tensor_parallel-1.0.23-py3-none-any.whl (25 kB)\n",
            "Collecting humanfriendly (from petals==2.3.0.dev1)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from petals==2.3.0.dev1) (4.0.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from petals==2.3.0.dev1) (23.2)\n",
            "Requirement already satisfied: sentencepiece>=0.1.99 in /usr/local/lib/python3.10/dist-packages (from petals==2.3.0.dev1) (0.1.99)\n",
            "Collecting peft==0.5.0 (from petals==2.3.0.dev1)\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from petals==2.3.0.dev1) (0.4.2)\n",
            "Collecting Dijkstar>=2.6.0 (from petals==2.3.0.dev1)\n",
            "  Downloading Dijkstar-2.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting cpufeature>=0.2.0 (from petals==2.3.0.dev1)\n",
            "  Downloading cpufeature-0.2.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev1) (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev1) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev1) (1.11.4)\n",
            "Requirement already satisfied: prefetch-generator>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev1) (1.0.3)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev1) (1.0.7)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev1) (2.4.0)\n",
            "Collecting uvloop>=0.14.0 (from hivemind==1.1.10.post2->petals==2.3.0.dev1)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio-tools>=1.33.2 (from hivemind==1.1.10.post2->petals==2.3.0.dev1)\n",
            "  Using cached grpcio_tools-1.60.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev1) (3.20.3)\n",
            "Collecting configargparse>=1.2.3 (from hivemind==1.1.10.post2->petals==2.3.0.dev1)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Collecting multiaddr>=0.0.9 (from hivemind==1.1.10.post2->petals==2.3.0.dev1)\n",
            "  Downloading multiaddr-0.0.9-py2.py3-none-any.whl (16 kB)\n",
            "Collecting pymultihash>=0.8.2 (from hivemind==1.1.10.post2->petals==2.3.0.dev1)\n",
            "  Downloading pymultihash-0.8.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: cryptography>=3.4.6 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals==2.3.0.dev1) (42.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.5.0->petals==2.3.0.dev1) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.5.0->petals==2.3.0.dev1) (4.66.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Dijkstar>=2.6.0->petals==2.3.0.dev1) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev1) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev1) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev1) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->petals==2.3.0.dev1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->petals==2.3.0.dev1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->petals==2.3.0.dev1) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->petals==2.3.0.dev1) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.35.0,>=4.32.0->petals==2.3.0.dev1) (2023.12.25)\n",
            "Collecting tokenizers>=0.13.3 (from petals==2.3.0.dev1)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.1 (from petals==2.3.0.dev1)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4.6->hivemind==1.1.10.post2->petals==2.3.0.dev1) (1.16.0)\n",
            "Collecting protobuf>=3.12.2 (from hivemind==1.1.10.post2->petals==2.3.0.dev1)\n",
            "  Using cached protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Requirement already satisfied: grpcio>=1.60.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.33.2->hivemind==1.1.10.post2->petals==2.3.0.dev1) (1.60.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.33.2->hivemind==1.1.10.post2->petals==2.3.0.dev1) (67.7.2)\n",
            "Collecting varint (from multiaddr>=0.0.9->hivemind==1.1.10.post2->petals==2.3.0.dev1)\n",
            "  Downloading varint-1.0.2.tar.gz (1.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting base58 (from multiaddr>=0.0.9->hivemind==1.1.10.post2->petals==2.3.0.dev1)\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting netaddr (from multiaddr>=0.0.9->hivemind==1.1.10.post2->petals==2.3.0.dev1)\n",
            "  Downloading netaddr-1.1.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12->petals==2.3.0.dev1) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals==2.3.0.dev1) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12->petals==2.3.0.dev1) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4.6->hivemind==1.1.10.post2->petals==2.3.0.dev1) (2.21)\n",
            "Building wheels for collected packages: petals, hivemind, varint\n",
            "  Building wheel for petals (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for petals: filename=petals-2.3.0.dev1-py3-none-any.whl size=117036 sha256=0e34948d5b3211a757ade4e8b098f83f7b75745b32f34660619ee88d43ba9ac0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vu3zgik6/wheels/98/38/8f/58b4f2d1d3762b120b9747915042f7498efd33a7d7475228ce\n",
            "  Building wheel for hivemind (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hivemind: filename=hivemind-1.1.10.post2-py3-none-any.whl size=9011595 sha256=9b4a8bf83d603b9fb57822f86cb3e25190fc43d76d041bbc5178ed7030ebadd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/98/e3/d51ae54ae8302c5a1872fae2e85a8e8291651af19f550965c1\n",
            "  Building wheel for varint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for varint: filename=varint-1.0.2-py3-none-any.whl size=1964 sha256=561445c0ada071210436f9c4e9eb3030aaf205127de67686cc29396f8c009521\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/48/5e/33919c52a2a695a512ca394a5308dd12626a40bbcd288de814\n",
            "Successfully built petals hivemind varint\n",
            "Installing collected packages: varint, speedtest-cli, pymultihash, cpufeature, bitsandbytes, uvloop, pydantic, protobuf, netaddr, humanfriendly, Dijkstar, configargparse, base58, multiaddr, huggingface-hub, grpcio-tools, tokenizers, hivemind, accelerate, transformers, tensor-parallel, peft, petals\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.1\n",
            "    Uninstalling pydantic-2.6.1:\n",
            "      Successfully uninstalled pydantic-2.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.1\n",
            "    Uninstalling tokenizers-0.15.1:\n",
            "      Successfully uninstalled tokenizers-0.15.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Dijkstar-2.6.0 accelerate-0.27.2 base58-2.1.1 bitsandbytes-0.41.1 configargparse-1.7 cpufeature-0.2.1 grpcio-tools-1.60.1 hivemind-1.1.10.post2 huggingface-hub-0.17.3 humanfriendly-10.0 multiaddr-0.0.9 netaddr-1.1.0 peft-0.5.0 petals-2.3.0.dev1 protobuf-4.25.2 pydantic-1.10.14 pymultihash-0.8.2 speedtest-cli-2.1.3 tensor-parallel-1.0.23 tokenizers-0.14.1 transformers-4.34.1 uvloop-0.19.0 varint-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install -q petals"
      ],
      "metadata": {
        "id": "4lAUKwDPnrhz"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers==4.34.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "MY-t_UIhnOoi",
        "outputId": "aaa45b00-f1bc-4819-a016-4bb71b52a4c7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.34.0\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.0) (2024.2.2)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.34.1\n",
            "    Uninstalling transformers-4.34.1:\n",
            "      Successfully uninstalled transformers-4.34.1\n",
            "Successfully installed transformers-4.34.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade hivemind\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v3qogeUFLxm",
        "outputId": "f292300f-5d80-4fce-a7c2-961c8fc9af7e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hivemind in /usr/local/lib/python3.10/dist-packages (1.1.10.post2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from hivemind) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hivemind) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from hivemind) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from hivemind) (1.11.4)\n",
            "Requirement already satisfied: prefetch-generator>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from hivemind) (1.0.3)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from hivemind) (1.0.7)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from hivemind) (2.4.0)\n",
            "Requirement already satisfied: uvloop>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from hivemind) (0.19.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from hivemind) (1.60.1)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from hivemind) (4.25.2)\n",
            "Requirement already satisfied: configargparse>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from hivemind) (1.7)\n",
            "Requirement already satisfied: multiaddr>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from hivemind) (0.0.9)\n",
            "Requirement already satisfied: pymultihash>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from hivemind) (0.8.2)\n",
            "Requirement already satisfied: cryptography>=3.4.6 in /usr/local/lib/python3.10/dist-packages (from hivemind) (42.0.2)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from hivemind) (1.10.14)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from hivemind) (23.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4.6->hivemind) (1.16.0)\n",
            "Requirement already satisfied: grpcio>=1.60.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.33.2->hivemind) (1.60.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.33.2->hivemind) (67.7.2)\n",
            "Requirement already satisfied: varint in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind) (1.16.0)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind) (2.1.1)\n",
            "Requirement already satisfied: netaddr in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0,>=1.8.1->hivemind) (4.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->hivemind) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->hivemind) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->hivemind) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->hivemind) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->hivemind) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->hivemind) (2.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4.6->hivemind) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->hivemind) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->hivemind) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from petals import AutoDistributedModelForCausalLM\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "-LzvO5ypngbH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 选择要比较的语言模型\n",
        "model_name = \"petals-team/StableBeluga2\"\n",
        "\n",
        "# 初始化模型\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoDistributedModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# 定义任务：这里假设进行文本生成任务\n",
        "prompt = \"Today is a beautiful day because\"\n",
        "ground_truth = \"Today is a beautiful day because the sun is shining and the birds are singing.\"\n",
        "\n",
        "# 执行模型并记录性能指标\n",
        "performance = []\n",
        "for shots in range(1, 11):\n",
        "    generated_text = model.generate(tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"], max_new_tokens=30)\n",
        "    performance.append(generated_text == ground_truth)\n",
        "\n",
        "# 绘制准确率随shots变化的曲线图\n",
        "plt.plot(range(1, 11), performance)\n",
        "plt.xlabel('Shots')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs Shots')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b400aae3346c4d05aa582020c49b15a2",
            "2ac8ec33814542069bd7c25ba55781a2",
            "1ac251e8ad8c467dbf77a14808f3c9d6",
            "031827eae9bc4881b541f0c58c8647cb",
            "bea28066889741d6a1b5d1034b80e17e",
            "67e70418f3e64389ace57b32f7bf4b38",
            "d2bd6922f3854f4bb9dd93bc6ec00d34",
            "afc0777f38614a8e890c0c438a1996e9",
            "dced553bb78c409abb5841487fbd7254",
            "4b9797a7c01d4ea8b75d4168f925c72d",
            "ffbaef973b104387bd2ae30d98616881",
            "58e3063378f04c6f962ec731eacbf6b1",
            "f1e2872c38894743a0a70f705be9b5f0",
            "63ec3faab119492a8648aa09e81db2fe",
            "5f0f2a70efb041c18f561192aa4b681d",
            "1fa33b03ccd545c593bee2e04c8187e6",
            "4100936569304216a0439cde8a03856a",
            "e6d8af311f1a40aa9eb1e2ed9cff2091",
            "bee4e4d72fd444c3a1d680bfd9dabd82",
            "a4c3c431261d418490a38ff5ed1bc74b",
            "abfde03b7957421db6d29547336a9b99",
            "3e9af1807538409982093d44fe3a8c5e",
            "8400b9e3836b470fa1d5a13c18257957",
            "0302390641b249f38557a10bbea92ec1",
            "1e5b8fd99bc84a0bab323b1f11a63d55",
            "c4f32b23cbaf41e89b8f81f9b5712fa4",
            "58b77cb1816d4903b3211253f22cd4d3",
            "9f86b81a733b4259b9af395d99b28622",
            "b3381ce74c1e431c9ad073595d66aabf",
            "1a60a0b9dcbe44dd8182187558906bd7",
            "06adf4ba482949d6a135d87d017bcd4f",
            "a2c3aa67279b46c3a19d7628625fdc39",
            "281b7b0cb2474abb9a8eb1d98ebe71fb",
            "daf8a1f997d7482283c75be6d294f78d",
            "66e751193e934f0198b3b9677649f0d3",
            "2498f8756b1946ca8a7dd1d32e33ad8c",
            "a6c635fb365b42c1868e65780200f80e",
            "a80ea0b4282f469987360368f7c145d7",
            "a7e5bd174040483ea849fd2c87d3a581",
            "f1412da75e054822844b05c8a221f5be",
            "5c5c2f7293814c679cd21f5219dac27d",
            "3376d02b88ca4e099bf2388e1b5e416a",
            "edb6f5583940453e8da7c591de83604c",
            "9a04914fbc3b4f6e979ec3b40d711860",
            "0834b3e612a7469183639dd6147c5121",
            "052a31011f064d938bbb715f82f3fba4",
            "0c256f63480f4e1393062c52afebeb1e",
            "434a4272d2d744bd9989ceccc58fcce2",
            "d5bb592998c64466bd0e4f07276e8e77",
            "52e9492e915744da82772e1b20aad3c6",
            "6f6d948373274225acc02b63a0b03f61",
            "4ead4b31db524501a177f2343096cfe4",
            "3f89cdd1765143b19a2f8202174f3b0a",
            "f8d462032aed4a38ac12fc87683b80a0",
            "455695a7e4c8407eb4ab57245304cd96",
            "340747dc15104fb9ad695f131a7c42d3",
            "524f7ddd0651469ea0e79b640b6cf77f",
            "12d3159d2d154b75990083cbe2e13494",
            "922afaff4d584e65972ef31867c2b3da",
            "a4d7c390622f4630b191a4cd832e6b78",
            "be543827bda547309a124652306cfe88",
            "aebbd668da02438f9be482d4329d4553",
            "fe176fa22f2f474a965ad36e31a8b985",
            "1476b43fb2414a5b9a751888c0b14401",
            "e53798a6b25c416a87c0444d8eb07396",
            "7a073e2b2f0d48e7ad94d10eb93bb37a",
            "5cb997d99a50460f9bf149b015c929ec",
            "811289dd1f904fabae54c8f7ea099407",
            "c834f8e5e20f4f1a8396c1a23773006a",
            "ecf835e90f5f400f88c8312ea96573a8",
            "8c1c86340ad840cbb70bb7b56f3956e4",
            "fb941ae484ea41e4be600322c4c66e83",
            "53aee670190d45618d107835c23779d5",
            "5d818dbe07d74e599d9a2ce7b4410729",
            "a239ddfbc1fd4b9f8dedbe5a158b9740",
            "911ead1e88bd4470bd5ea6809a6d6450",
            "a290c25aa738427e8c6e642cd7656648",
            "229ff22228c74118a57c335ed5ef562e",
            "e39698430d564f2d962562bb4a458ef7",
            "ff00be1c6fbb4975ac48af2609a54e75",
            "f53288206fcc46848230a0553892a18e",
            "671a21a1f5b84863a7a90cf4d31c2ff2",
            "e227c3e731da48daa057c32bac5c3143",
            "b0679afcb7144066adf87511e2958a3f",
            "0942124417e547d3a36a27c808429dee",
            "89da5c5aca904c3aa2052d39c27f1de0",
            "fba64a383dd7467b9f3b461a9c39e560",
            "dc5b93f35c4646fe997dcbb2f5a172ed",
            "9906225e3f5c4dcb9e2434ed4a5f80a8",
            "7ea094bbefc94b398b6c78e49b3c89a6",
            "5782dae1fc9545ad86238bc42282eb24",
            "c36e7d660c2f4cb0b0e4cf53df28a659",
            "6e9967e6f302472caaabd45ca6fd1746",
            "6cd404739e4d4c419d3c51f396b35114",
            "0d85fd28167847d48cc9daed49bfc6a5",
            "01a8ea677cb64d1dbf23cd2a45cf2174",
            "c7f1605cda9e499ba9457ff901caf068",
            "29e9d42606d1457dbb03e88f4f67d11f",
            "d800233acea54c1e897821b0a42a4296"
          ]
        },
        "id": "s53UtLuRkSrm",
        "outputId": "5896726e-27ad-4dd2-f063-dd0d6fa5639a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b400aae3346c4d05aa582020c49b15a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58e3063378f04c6f962ec731eacbf6b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8400b9e3836b470fa1d5a13c18257957"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "daf8a1f997d7482283c75be6d294f78d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0834b3e612a7469183639dd6147c5121"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Feb 15 04:55:06.820 [\u001b[1m\u001b[34mINFO\u001b[0m] Make sure you follow the LLaMA's terms of use: https://bit.ly/llama2-license for LLaMA 2, https://bit.ly/llama-license for LLaMA 1\n",
            "Feb 15 04:55:06.823 [\u001b[1m\u001b[34mINFO\u001b[0m] Using DHT prefix: StableBeluga2-hf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)fetensors.index.json:   0%|          | 0.00/62.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "340747dc15104fb9ad695f131a7c42d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cb997d99a50460f9bf149b015c929ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)of-00081.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "229ff22228c74118a57c335ed5ef562e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9906225e3f5c4dcb9e2434ed4a5f80a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Feb 15 04:55:33.357 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:80 via …YHJQTP\n",
            "Feb 15 04:55:53.611 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:80 via …YHJQTP\n",
            "Feb 15 04:56:21.810 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:80 via …YHJQTP\n",
            "Feb 15 04:56:46.656 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:80 via …YHJQTP\n",
            "Feb 15 04:57:05.846 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:80 via …YHJQTP\n",
            "Feb 15 04:57:27.535 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:80 via …YHJQTP\n",
            "Feb 15 04:57:48.586 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:80 via …YHJQTP\n",
            "Feb 15 04:58:11.547 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:80 via …YHJQTP\n",
            "Feb 15 04:58:33.464 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:80 via …YHJQTP\n",
            "Feb 15 04:58:54.505 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:80 via …YHJQTP\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule-based\n",
        "\n",
        "\n",
        "Some models, like Anthropic’s Claude, touts a rule-based approach to shaping LLM behavior rather than reinforcement of case-by-case human human feedback. It calls this approach  “constitutional AI”, as described in a 2023 paper titled [“Specific vs. General Principles of Constitutional AI”](https://arxiv.org/pdf/2310.13798.pdf). Their argument is that specific feedback may be brittle, and fail to [“mitigate subtle problematic behaviors such as a stated desire for self-preservation or power.”](https://www.anthropic.com/news/specific-versus-general-principles-for-constitutional-ai) The concept underlying Constitutional AI is that users provide AI models a written list of principles or “constitutions” that encourage ethical or otherwise functional behavior. They demonstrate that very general principles (e.g., “do what’s best for humanity”) limit the need to provide numerous rules targeting unwanted behaviors (e.g., amass power, use toxic language, etc.)\n",
        "\n",
        "\n",
        "Regardless of their overall approach, you can provide any LLM model with explicit general or specific rules it will attempt to follow. Rules (e.g., “sarcasm is the mocking use of irony”) are less specific than examples (e.g., “this text is not sarcastic”), but their generality can make them broadly relevant to exert more influence on model improvement. See below approaches in Claude and GPT.\n"
      ],
      "metadata": {
        "id": "c5jP1fU0LJDi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ycoQRM6QGMzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Cases of LLMS\n",
        "\n",
        "There are many different tasks for which one could apply LLMs according to the approaches we developed above. We showcase several below:"
      ],
      "metadata": {
        "id": "LkRpNFWwMYK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## - Actor - Critic - Improve Object with Critique\n",
        "\n",
        "You can set up an \"Actor-Critic\" model by asking the model to generate text, and then ask it to generate a critique, and to regenerate the text according to the critique. In this way, you are instantiating two different models that seek to adversarially improve one another. Consider the following prompts in sequence:\n",
        "\n",
        "\n",
        "CODE:\n",
        "“Write story of up to 300 words in length intended for an native English language speaking child audience that involves two anthropomorphized puppies ‘Bumble’ and ‘Gruff’ who go on adventure.”\n",
        "\n",
        "\n",
        "“Critique this story regarding its clarity, grammar, consistency, suspense, and surprise. Then rewrite in 300 words accounting for these critiques.”\n",
        "\n",
        "\n",
        "“Critique this story regarding its clarity, grammar, consistency, suspense, and surprise. Then rewrite in 300 words accounting for these critiques.”\n",
        "\n",
        "\n",
        "A more complicated example using code could involve the following:\n"
      ],
      "metadata": {
        "id": "5m7lmPc2vtDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def critique_and_improve_grammar(text, api_key):\n",
        "    \"\"\"\n",
        "    This function takes a piece of text and uses OpenAI's GPT-4 to critique and improve its grammar.\n",
        "\n",
        "    Args:\n",
        "    text (str): The text to be critiqued and improved.\n",
        "    api_key (str): Your OpenAI API key.\n",
        "\n",
        "    Returns:\n",
        "    str: The critiqued and grammatically improved text.\n",
        "    \"\"\"\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            model=\"text-davinci-003\",  # Replace with \"gpt-4\" if you have access\n",
        "            prompt=f\"Please critique and suggest improvements for the grammar of the following text:\\n\\n{text}\",\n",
        "            temperature=0.7,\n",
        "            max_tokens=250\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Example usage\n",
        "api_key = 'your-api-key-here'  # Replace with your actual OpenAI API key\n",
        "input_text = \"This is a example text that needs grammar checking and improvement.\"\n",
        "print(critique_and_improve_grammar(input_text, api_key))\n"
      ],
      "metadata": {
        "id": "dnagjiZEvuqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rewriting texts in different ways (e.g German, Politically Sensitive)\n",
        "\n",
        "\n",
        "“Rewrite the following text ‘This is the best hamburger I have ever tasted.’ in Russian and Chinese.\n",
        "\n",
        "\n",
        "“Rewrite it as the sentiment might be rendered by a vegetarian”\n",
        "\n",
        "\n",
        "“Rewrite it in two sentences with specific, concrete language about an eating experience.”\n",
        "\n",
        "\n",
        "“Rewrite it in the style of Proust.”\n",
        "\n",
        "\n",
        "“Rewrite it in the style of the following paper abstract: ‘Four score and seven years ago our fathers brought forth on this continent a new nation, conceived in liberty, and dedicated to the proposition that all men are created equal. Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battlefield of that war. We have come to dedicate a portion of that field as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this. But in a larger sense we cannot dedicate, we cannot consecrate, we cannot hallow this ground. The brave men, living and dead, who struggled here have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember, what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us,that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion, that we here highly resolve that these dead shall not have died in vain, that this nation, under God, shall have a new birth of freedom, and that government of the people, by the people, for the people, shall not perish from the earth.’”\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RaCUU1kTyGPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_with_style(text, style, api_key):\n",
        "    \"\"\"\n",
        "    This function takes a piece of text and uses OpenAI's GPT-4 to rewrite it in a specified style.\n",
        "\n",
        "    Args:\n",
        "    text (str): The original text.\n",
        "    style (str): The desired style ('german_child' or 'conservative').\n",
        "    api_key (str): Your OpenAI API key.\n",
        "\n",
        "    Returns:\n",
        "    str: The text rewritten in the specified style.\n",
        "    \"\"\"\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    if style == 'german_child':\n",
        "        prompt = f\"Translate the following text into German as if it was written by a five-year-old child:\\n\\n{text}\"\n",
        "    elif style == 'conservative':\n",
        "        prompt = f\"Rewrite the following text in a politically conservative style:\\n\\n{text}\"\n",
        "    else:\n",
        "        return \"Invalid style specified.\"\n",
        "\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            model=\"text-davinci-003\",  # Replace with \"gpt-4\" if you have access\n",
        "            prompt=prompt,\n",
        "            temperature=0.7,\n",
        "            max_tokens=150\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Example usage\n",
        "api_key = 'your-api-key-here'  # Replace with your actual OpenAI API key\n",
        "input_text = \"This is an example text for style transformation.\"\n",
        "style = 'german_child'  # Can be 'german_child' or 'conservative'\n",
        "print(generate_text_with_style(input_text, style, api_key))\n"
      ],
      "metadata": {
        "id": "0OMTDG67yPQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">*Exercise 5*</font>\n",
        "\n",
        "<font color=\"red\">Use an Actor - Critic design to improve LLM's performance on your task or perform some related experiments with language prediction. For example, you might want to investigate how LLMs can more or less effectiveloy predict how different groups of people might respond to a prompt or question (e.g., write a dating profile; answer a survey question)."
      ],
      "metadata": {
        "id": "3uGXD1WYudKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I try to use the transformers library from Hugging Face and a local GPT-2 model to predict responses for different groups of people based on given prompts."
      ],
      "metadata": {
        "id": "DKZ0AX-zPXO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la9a6jfxMlxS",
        "outputId": "cd599bf3-70cd-42a1-fd5c-4ca71dbeab13"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "def predict_response(prompt, group):\n",
        "    \"\"\"\n",
        "    This function uses a local GPT-2 model to predict how different groups of people might respond to a prompt or question.\n",
        "\n",
        "    Args:\n",
        "    prompt (str): The prompt or question.\n",
        "    group (str): The group for which the response is predicted (e.g., \"young adults\", \"senior citizens\", \"professionals\").\n",
        "\n",
        "    Returns:\n",
        "    str: The predicted response for the given group.\n",
        "    \"\"\"\n",
        "    # Load pre-trained model and tokenizer\n",
        "    model_name = \"gpt2\"\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    # Tokenize prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate response\n",
        "    output = model.generate(input_ids, max_length=100, num_return_sequences=1, temperature=0.7)\n",
        "\n",
        "    # Decode and return response\n",
        "    predicted_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return predicted_response\n",
        "\n",
        "# Example usage\n",
        "prompt = \"Write a brief dating profile describing yourself.\"\n",
        "group = \"young adults\"\n",
        "predicted_response = predict_response(prompt, group)\n",
        "\n",
        "print(f\"Predicted response for {group}:\")\n",
        "print(predicted_response)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-5nFmsaOyqK",
        "outputId": "1438d8fa-d2f0-437f-c779-eb0908c8a66d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted response for young adults:\n",
            "Write a brief dating profile describing yourself.\n",
            "\n",
            "If you're looking for a guy who's a bit more laid back, you might want to consider a guy who's a bit more laid back.\n",
            "\n",
            "If you're looking for a guy who's a bit more laid back, you might want to consider a guy who's a bit more laid back.\n",
            "\n",
            "If you're looking for a guy who's a bit more laid back, you might want to consider a guy who's a bit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TD1G6MifsBq1"
      }
    }
  ]
}